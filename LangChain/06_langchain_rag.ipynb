{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "06badf0b",
   "metadata": {},
   "source": [
    "### Simple RAG using Langchain and ChromaDB\n",
    "- Query ‚Üí Embed ‚Üí Search Vector DB ‚Üí Retrieve Docs ‚Üí LLM (with context) ‚Üí Answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5f141241",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import WikipediaLoader\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain_huggingface import HuggingFaceEmbeddings\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "9ee5bf86",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yashsarode/Downloads/Personal Projects/Python/LangGraph-personal/.venv/lib/python3.13/site-packages/wikipedia/wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"html.parser\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file /Users/yashsarode/Downloads/Personal Projects/Python/LangGraph-personal/.venv/lib/python3.13/site-packages/wikipedia/wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"html.parser\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Loaded 9 Wikipedia pages\n",
      "\n",
      "First document preview:\n",
      "In deep learning, the transformer is an artificial neural network architecture based on the multi-head attention mechanism, in which text is converted to numerical representations called tokens, and e...\n"
     ]
    }
   ],
   "source": [
    "# Documents are loaded from Wikipedia\n",
    "loader = WikipediaLoader(query=\"Transformer (deep learning)\", load_max_docs=10)\n",
    "documents = loader.load()\n",
    "print(f\" Loaded {len(documents)} Wikipedia pages\")\n",
    "print(f\"\\nFirst document preview:\")\n",
    "print(documents[0].page_content[:200] + \"...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "81179a4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Split into 47 chunks\n",
      "\n",
      "First chunk preview:\n",
      "In deep learning, the transformer is an artificial neural network architecture based on the multi-head attention mechanism, in which text is converted to numerical representations called tokens, and e...\n"
     ]
    }
   ],
   "source": [
    "# Document is split into chunks of 1000 characters, with 200 characters overlap\n",
    "# Why chunk?\n",
    "        # - Embeddings work better on focused text\n",
    "        # - Retrieval is more precise\n",
    "        # - Fits in LLM context window\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)\n",
    "docs = text_splitter.split_documents(documents)\n",
    "print(f\" Split into {len(docs)} chunks\")\n",
    "print(f\"\\nFirst chunk preview:\")\n",
    "print(docs[0].page_content[:200] + \"...\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "76d02014",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.010038163512945175, -0.010613719001412392, -0.007397179026156664, 0.034642405807971954, -0.04844551533460617, 0.0017753464635461569, 0.03124556504189968, -0.0011594544630497694, -0.042442891746759415, -0.05231810733675957]\n"
     ]
    }
   ],
   "source": [
    "# Convert documents to embeddings\n",
    "# Why HuggingFace embeddings?\n",
    "#         - Free, no API calls\n",
    "#         - Runs locally (privacy + speed)\n",
    "#         - Good quality for most use cases\n",
    "embeddings = HuggingFaceEmbeddings(\n",
    "    model_name=\"sentence-transformers/all-mpnet-base-v2\",\n",
    "    model_kwargs={\"device\": \"cpu\"},\n",
    "    encode_kwargs={'normalize_embeddings': True}\n",
    ")\n",
    "\n",
    "# Embed the documents\n",
    "vector_1 = embeddings.embed_query(docs[0].page_content)\n",
    "vector_2 = embeddings.embed_query(docs[1].page_content)\n",
    "print(vector_1[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1187168a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new vector store from documents.\n",
    "        \n",
    "# Process:\n",
    "# 1. Each document is embedded (text ‚Üí vector)\n",
    "# 2. Vectors are indexed for fast search\n",
    "# 3. Persisted to disk for reuse\n",
    "from langchain_chroma import Chroma\n",
    "\n",
    "vector_store = Chroma(\n",
    "    collection_name=\"simple_rag\",\n",
    "    embedding_function=embeddings,\n",
    "    persist_directory=\"./chroma_db\",  # Where to save data locally, remove if not necessary\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "62ed50a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['9ed268d3-6e62-4bfb-a94d-394553689db6',\n",
       " '74bf96e5-2699-4b89-b3d1-a34a68d19337',\n",
       " 'a6785169-4cf0-4d68-9e2f-425c0192fae5',\n",
       " 'ec94d334-b8f9-40f2-86df-03379f9f7fa2',\n",
       " 'd36d1dc2-eb15-4fc0-9cb4-53a871e22638',\n",
       " '4434912e-5efd-4062-9f17-1c179abaff88',\n",
       " '1f071331-50ed-461a-ac3d-310c71f46d36',\n",
       " 'c56a069c-c581-4f30-81d9-45e40f9e30bf',\n",
       " 'bee45508-7b73-41be-9542-0741201193b3',\n",
       " '40a0a195-4440-408b-8147-f83fec19b6ba',\n",
       " '347b2dde-3bbd-43b2-bf43-24cf311b719e',\n",
       " '1589a3e3-a0b9-4cd3-9333-45fd33acb745',\n",
       " 'f1f8bb3b-5add-4eb3-a9ab-838e0e9d3392',\n",
       " '22bf9e8e-b069-4bab-9b98-231235b931fa',\n",
       " '05b49edb-01e2-4ba6-a7bf-9736998f4ff3',\n",
       " '7e62f641-2e97-49bb-8789-79f0b80042b9',\n",
       " 'de73c7da-3a57-431c-b35d-8be115db9978',\n",
       " '8650ff99-85a4-4bbf-a165-213a74e53da5',\n",
       " '4b2cc08b-e87e-432e-a127-46c6d6f1043f',\n",
       " 'caf14c86-79dd-4a7f-b81e-df6f2fbcd241',\n",
       " '449282dc-bc01-4964-a216-35655612c1a1',\n",
       " '8cb1df8c-daba-4f2d-8e65-7b7d048ea8d2',\n",
       " '7c784813-e456-4e0c-8c48-dc31dd7af803',\n",
       " '0272c611-4581-4ce6-b125-176e4a46c0d9',\n",
       " 'ba5be133-eacc-4e41-9e2a-2e230da57436',\n",
       " 'f6203b24-284b-4580-b378-54c226a831b4',\n",
       " '644308e9-0e2a-4695-9e33-5a7be6b8a58c',\n",
       " '07c8d54a-adfc-44e7-b1a7-f16be1fee7d4',\n",
       " '377047fb-9b4b-4b00-9ef9-378abf869c28',\n",
       " '8c83a5df-1b17-42be-96e6-69b35d4e7f06',\n",
       " '9133fc3e-ea9a-47c9-896b-414fd06337e6',\n",
       " '1f5e794c-8c27-4b2c-9a0c-2f4bb69f0cdc',\n",
       " '562acaaf-0188-48fe-a328-11623e676055',\n",
       " 'a5cd6a56-e6a5-4880-a30a-dd174f86e09b',\n",
       " '2f3a2714-f232-40fd-a121-8c1eed889ec9',\n",
       " 'fbc0c3a6-b4f7-4c32-8b31-9238ed6f674a',\n",
       " '3d2ff3e1-1fa1-4301-badb-d82dfa01d41c',\n",
       " '48a458c1-9dd9-4810-a874-62f7b09b5c98',\n",
       " '2611d06a-312e-4c6c-b6bf-3b84b0df4150',\n",
       " 'a0232e62-c16b-4c46-ba7f-e5e7ee2b3b5e',\n",
       " '787d20f6-d389-492a-9d80-2ef6cb7eb24f',\n",
       " '94948e7f-74c5-45b6-99d2-dbfff662b363',\n",
       " '49412b5a-67a1-48cc-b683-5bbbf2e4c4fc',\n",
       " 'f25adfdb-509e-4052-8e22-a15b8c485e93',\n",
       " '8ff0f5f5-31bc-48ca-bb8e-7c48c47c5572',\n",
       " '5ff3f7d1-27f7-4025-a7d6-c72925c8d3d7',\n",
       " '38f55579-85f3-4809-b8f9-70130d655323']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vector_store.add_documents(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "8a3f5709",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Document(id='74bf96e5-2699-4b89-b3d1-a34a68d19337', metadata={'source': 'https://en.wikipedia.org/wiki/Transformer_(deep_learning)', 'title': 'Transformer (deep learning)', 'summary': 'In deep learning, the transformer is an artificial neural network architecture based on the multi-head attention mechanism, in which text is converted to numerical representations called tokens, and each token is converted into a vector via lookup from a word embedding table. At each layer, each token is then contextualized within the scope of the context window with other (unmasked) tokens via a parallel multi-head attention mechanism, allowing the signal for key tokens to be amplified and less important tokens to be diminished. \\nTransformers have the advantage of having no recurrent units, therefore requiring less training time than earlier recurrent neural architectures (RNNs) such as long short-term memory (LSTM). Later variations have been widely adopted for training large language models (LLMs) on large (language) datasets.\\n\\nThe modern version of the transformer was proposed in the 2017 paper \"Attention Is All You Need\" by researchers at Google. The predecessors of transformers were developed as an improvement over previous architectures for machine translation, but have found many applications since. They are used in large-scale natural language processing, computer vision (vision transformers), reinforcement learning, audio, multimodal learning, robotics, and even playing chess. It has also led to the development of pre-trained systems, such as generative pre-trained transformers (GPTs) and BERT (bidirectional encoder representations from transformers).\\n\\n'}, page_content='The modern version of the transformer was proposed in the 2017 paper \"Attention Is All You Need\" by researchers at Google. The predecessors of transformers were developed as an improvement over previous architectures for machine translation, but have found many applications since. They are used in large-scale natural language processing, computer vision (vision transformers), reinforcement learning, audio, multimodal learning, robotics, and even playing chess. It has also led to the development of pre-trained systems, such as generative pre-trained transformers (GPTs) and BERT (bidirectional encoder representations from transformers).\\n\\n\\n== History =='), Document(id='d36d1dc2-eb15-4fc0-9cb4-53a871e22638', metadata={'title': 'Transformer (deep learning)', 'source': 'https://en.wikipedia.org/wiki/Transformer_(deep_learning)', 'summary': 'In deep learning, the transformer is an artificial neural network architecture based on the multi-head attention mechanism, in which text is converted to numerical representations called tokens, and each token is converted into a vector via lookup from a word embedding table. At each layer, each token is then contextualized within the scope of the context window with other (unmasked) tokens via a parallel multi-head attention mechanism, allowing the signal for key tokens to be amplified and less important tokens to be diminished. \\nTransformers have the advantage of having no recurrent units, therefore requiring less training time than earlier recurrent neural architectures (RNNs) such as long short-term memory (LSTM). Later variations have been widely adopted for training large language models (LLMs) on large (language) datasets.\\n\\nThe modern version of the transformer was proposed in the 2017 paper \"Attention Is All You Need\" by researchers at Google. The predecessors of transformers were developed as an improvement over previous architectures for machine translation, but have found many applications since. They are used in large-scale natural language processing, computer vision (vision transformers), reinforcement learning, audio, multimodal learning, robotics, and even playing chess. It has also led to the development of pre-trained systems, such as generative pre-trained transformers (GPTs) and BERT (bidirectional encoder representations from transformers).\\n\\n'}, page_content='Modern transformers overcome this problem, but unlike RNNs, they require computation time that is quadratic in the size of the context window. The linearly scaling fast weight controller (1992) learns to compute a weight matrix for further processing depending on the input. One of its two networks has \"fast weights\" or \"dynamic links\" (1981). A slow neural network learns by gradient descent to generate keys and values for computing the weight changes of the fast neural network which computes answers to queries. This was later shown to be equivalent to the unnormalized linear transformer.'), Document(id='9ed268d3-6e62-4bfb-a94d-394553689db6', metadata={'source': 'https://en.wikipedia.org/wiki/Transformer_(deep_learning)', 'summary': 'In deep learning, the transformer is an artificial neural network architecture based on the multi-head attention mechanism, in which text is converted to numerical representations called tokens, and each token is converted into a vector via lookup from a word embedding table. At each layer, each token is then contextualized within the scope of the context window with other (unmasked) tokens via a parallel multi-head attention mechanism, allowing the signal for key tokens to be amplified and less important tokens to be diminished. \\nTransformers have the advantage of having no recurrent units, therefore requiring less training time than earlier recurrent neural architectures (RNNs) such as long short-term memory (LSTM). Later variations have been widely adopted for training large language models (LLMs) on large (language) datasets.\\n\\nThe modern version of the transformer was proposed in the 2017 paper \"Attention Is All You Need\" by researchers at Google. The predecessors of transformers were developed as an improvement over previous architectures for machine translation, but have found many applications since. They are used in large-scale natural language processing, computer vision (vision transformers), reinforcement learning, audio, multimodal learning, robotics, and even playing chess. It has also led to the development of pre-trained systems, such as generative pre-trained transformers (GPTs) and BERT (bidirectional encoder representations from transformers).\\n\\n', 'title': 'Transformer (deep learning)'}, page_content='In deep learning, the transformer is an artificial neural network architecture based on the multi-head attention mechanism, in which text is converted to numerical representations called tokens, and each token is converted into a vector via lookup from a word embedding table. At each layer, each token is then contextualized within the scope of the context window with other (unmasked) tokens via a parallel multi-head attention mechanism, allowing the signal for key tokens to be amplified and less important tokens to be diminished. \\nTransformers have the advantage of having no recurrent units, therefore requiring less training time than earlier recurrent neural architectures (RNNs) such as long short-term memory (LSTM). Later variations have been widely adopted for training large language models (LLMs) on large (language) datasets.'), Document(id='2611d06a-312e-4c6c-b6bf-3b84b0df4150', metadata={'title': 'Generative pre-trained transformer', 'summary': 'A generative pre-trained transformer (GPT) is a type of large language model (LLM) that is widely used in generative AI chatbots. GPTs are based on a deep learning architecture called the transformer. They are pre-trained on large datasets of unlabeled content, and able to generate novel content.\\nOpenAI was the first to apply generative pre-training to the transformer architecture, introducing the GPT-1 model in 2018. The company has since released many bigger GPT models. The popular chatbot ChatGPT, released in late 2022 (using GPT-3.5), was followed by many competitor chatbots using their own generative pre-trained transformers to generate text, such as Gemini, DeepSeek or Claude.\\nGPTs are primarily used to generate text, but can be trained to generate other kinds of data. For example, GPT-4o can process and generate text, images and audio. To improve performance on complex tasks, some GPTs, such as OpenAI o3, allocate more computation time analyzing the problem before generating an output, and are called reasoning models. In 2025, GPT-5 was released with a router that automatically selects whether to use a faster model or slower reasoning model based on task.', 'source': 'https://en.wikipedia.org/wiki/Generative_pre-trained_transformer'}, page_content='The transformer architecture for deep learning is the core technology of a GPT. Developed by researchers at Google, it was introduced in the paper \"Attention Is All You Need\", which was published on June 12, 2017. The transformer architecture solved many of the performance issues that were associated with older recurrent neural network (RNN) designs for natural language processing (NLP). The architecture\\'s use of an attention mechanism allows models to process entire sequences of text at once, enabling the training of much larger and more sophisticated models. Since 2017, numerous transformer-based NLP systems have been available that are capable of processing, mining, organizing, connecting, contrasting, and summarizing texts as well as correctly answering questions from textual input.')]\n"
     ]
    }
   ],
   "source": [
    "query = \"What advantage does the transformer model have over the RNN/LSTM model?\"\n",
    "results = vector_store.similarity_search(\n",
    "    query, k=4\n",
    ")\n",
    "\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "7326751a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query: What advantage does the transformer model have over the RNN/LSTM model?\n",
      "Retrieved 4 documents\n",
      "Document 1:\n",
      "The modern version of the transformer was proposed in the 2017 paper \"Attention Is All You Need\" by researchers at Google. The predecessors of transformers were developed as an improvement over previo...\n",
      "\n",
      "\n",
      "Document 2:\n",
      "Modern transformers overcome this problem, but unlike RNNs, they require computation time that is quadratic in the size of the context window. The linearly scaling fast weight controller (1992) learns...\n",
      "\n",
      "\n",
      "Document 3:\n",
      "In deep learning, the transformer is an artificial neural network architecture based on the multi-head attention mechanism, in which text is converted to numerical representations called tokens, and e...\n",
      "\n",
      "\n",
      "Document 4:\n",
      "The transformer architecture for deep learning is the core technology of a GPT. Developed by researchers at Google, it was introduced in the paper \"Attention Is All You Need\", which was published on J...\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(f\"Query: {query}\")\n",
    "print(f\"Retrieved {len(results)} documents\")\n",
    "\n",
    "for i,r in enumerate(results):\n",
    "    print(f\"Document {i+1}:\")\n",
    "    print(r.page_content[:200] + \"...\")\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "842879a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìä Search results with scores:\n",
      "1. Score: 0.7498 | Source: https://en.wikipedia.org/wiki/Transformer_(deep_learning)\n",
      "   Preview: The modern version of the transformer was proposed in the 2017 paper \"Attention Is All You Need\" by ...\n",
      "\n",
      "2. Score: 0.9087 | Source: https://en.wikipedia.org/wiki/Transformer_(deep_learning)\n",
      "   Preview: Modern transformers overcome this problem, but unlike RNNs, they require computation time that is qu...\n",
      "\n",
      "3. Score: 0.9444 | Source: https://en.wikipedia.org/wiki/Transformer_(deep_learning)\n",
      "   Preview: In deep learning, the transformer is an artificial neural network architecture based on the multi-he...\n",
      "\n",
      "4. Score: 0.9529 | Source: https://en.wikipedia.org/wiki/Generative_pre-trained_transformer\n",
      "   Preview: The transformer architecture for deep learning is the core technology of a GPT. Developed by researc...\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.documents.base import Document\n",
    "\n",
    "\n",
    "results= vector_store.similarity_search_with_score(query, k=4)\n",
    "        \n",
    "print(f\"\\nüìä Search results with scores:\")\n",
    "for i, (doc, score) in enumerate[tuple[Document, float]](results, 1):\n",
    "    print(f\"{i}. Score: {score:.4f} | Source: {doc.metadata.get('source', 'Unknown')}\")\n",
    "    print(f\"   Preview: {doc.page_content[:100]}...\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fb9f3ec",
   "metadata": {},
   "source": [
    "### Runnable: @chain vs as_retriever()\n",
    "- Runnable: a standard abstraction that represents a single unit of work (transforming input ‚Üí output), with support for sync, async, batching, streaming, tracing/debugging, composition, etc.\n",
    "- The @chain decorator converts a normal Python function into a Runnable\n",
    "- @chain gives you a ‚Äúchainable, runnable function‚Äù ‚Äî you can treat it as part of a larger workflow, or call it on inputs (single or batch), just like built-in Runnables (retrievers, LLM wrappers, etc.)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a23b4082",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[Document(id='74bf96e5-2699-4b89-b3d1-a34a68d19337', metadata={'source': 'https://en.wikipedia.org/wiki/Transformer_(deep_learning)', 'title': 'Transformer (deep learning)', 'summary': 'In deep learning, the transformer is an artificial neural network architecture based on the multi-head attention mechanism, in which text is converted to numerical representations called tokens, and each token is converted into a vector via lookup from a word embedding table. At each layer, each token is then contextualized within the scope of the context window with other (unmasked) tokens via a parallel multi-head attention mechanism, allowing the signal for key tokens to be amplified and less important tokens to be diminished. \\nTransformers have the advantage of having no recurrent units, therefore requiring less training time than earlier recurrent neural architectures (RNNs) such as long short-term memory (LSTM). Later variations have been widely adopted for training large language models (LLMs) on large (language) datasets.\\n\\nThe modern version of the transformer was proposed in the 2017 paper \"Attention Is All You Need\" by researchers at Google. The predecessors of transformers were developed as an improvement over previous architectures for machine translation, but have found many applications since. They are used in large-scale natural language processing, computer vision (vision transformers), reinforcement learning, audio, multimodal learning, robotics, and even playing chess. It has also led to the development of pre-trained systems, such as generative pre-trained transformers (GPTs) and BERT (bidirectional encoder representations from transformers).\\n\\n'}, page_content='The modern version of the transformer was proposed in the 2017 paper \"Attention Is All You Need\" by researchers at Google. The predecessors of transformers were developed as an improvement over previous architectures for machine translation, but have found many applications since. They are used in large-scale natural language processing, computer vision (vision transformers), reinforcement learning, audio, multimodal learning, robotics, and even playing chess. It has also led to the development of pre-trained systems, such as generative pre-trained transformers (GPTs) and BERT (bidirectional encoder representations from transformers).\\n\\n\\n== History =='),\n",
       "  Document(id='d36d1dc2-eb15-4fc0-9cb4-53a871e22638', metadata={'title': 'Transformer (deep learning)', 'summary': 'In deep learning, the transformer is an artificial neural network architecture based on the multi-head attention mechanism, in which text is converted to numerical representations called tokens, and each token is converted into a vector via lookup from a word embedding table. At each layer, each token is then contextualized within the scope of the context window with other (unmasked) tokens via a parallel multi-head attention mechanism, allowing the signal for key tokens to be amplified and less important tokens to be diminished. \\nTransformers have the advantage of having no recurrent units, therefore requiring less training time than earlier recurrent neural architectures (RNNs) such as long short-term memory (LSTM). Later variations have been widely adopted for training large language models (LLMs) on large (language) datasets.\\n\\nThe modern version of the transformer was proposed in the 2017 paper \"Attention Is All You Need\" by researchers at Google. The predecessors of transformers were developed as an improvement over previous architectures for machine translation, but have found many applications since. They are used in large-scale natural language processing, computer vision (vision transformers), reinforcement learning, audio, multimodal learning, robotics, and even playing chess. It has also led to the development of pre-trained systems, such as generative pre-trained transformers (GPTs) and BERT (bidirectional encoder representations from transformers).\\n\\n', 'source': 'https://en.wikipedia.org/wiki/Transformer_(deep_learning)'}, page_content='Modern transformers overcome this problem, but unlike RNNs, they require computation time that is quadratic in the size of the context window. The linearly scaling fast weight controller (1992) learns to compute a weight matrix for further processing depending on the input. One of its two networks has \"fast weights\" or \"dynamic links\" (1981). A slow neural network learns by gradient descent to generate keys and values for computing the weight changes of the fast neural network which computes answers to queries. This was later shown to be equivalent to the unnormalized linear transformer.'),\n",
       "  Document(id='9ed268d3-6e62-4bfb-a94d-394553689db6', metadata={'title': 'Transformer (deep learning)', 'summary': 'In deep learning, the transformer is an artificial neural network architecture based on the multi-head attention mechanism, in which text is converted to numerical representations called tokens, and each token is converted into a vector via lookup from a word embedding table. At each layer, each token is then contextualized within the scope of the context window with other (unmasked) tokens via a parallel multi-head attention mechanism, allowing the signal for key tokens to be amplified and less important tokens to be diminished. \\nTransformers have the advantage of having no recurrent units, therefore requiring less training time than earlier recurrent neural architectures (RNNs) such as long short-term memory (LSTM). Later variations have been widely adopted for training large language models (LLMs) on large (language) datasets.\\n\\nThe modern version of the transformer was proposed in the 2017 paper \"Attention Is All You Need\" by researchers at Google. The predecessors of transformers were developed as an improvement over previous architectures for machine translation, but have found many applications since. They are used in large-scale natural language processing, computer vision (vision transformers), reinforcement learning, audio, multimodal learning, robotics, and even playing chess. It has also led to the development of pre-trained systems, such as generative pre-trained transformers (GPTs) and BERT (bidirectional encoder representations from transformers).\\n\\n', 'source': 'https://en.wikipedia.org/wiki/Transformer_(deep_learning)'}, page_content='In deep learning, the transformer is an artificial neural network architecture based on the multi-head attention mechanism, in which text is converted to numerical representations called tokens, and each token is converted into a vector via lookup from a word embedding table. At each layer, each token is then contextualized within the scope of the context window with other (unmasked) tokens via a parallel multi-head attention mechanism, allowing the signal for key tokens to be amplified and less important tokens to be diminished. \\nTransformers have the advantage of having no recurrent units, therefore requiring less training time than earlier recurrent neural architectures (RNNs) such as long short-term memory (LSTM). Later variations have been widely adopted for training large language models (LLMs) on large (language) datasets.')],\n",
       " [Document(id='1f071331-50ed-461a-ac3d-310c71f46d36', metadata={'title': 'Attention (machine learning)', 'summary': 'In machine learning, attention is a method that determines the importance of each component in a sequence relative to the other components in that sequence. In natural language processing, importance is represented by \"soft\" weights assigned to each word in a sentence. More generally, attention encodes vectors called token embeddings across a fixed-width sequence that can range from tens to millions of tokens in size.\\nUnlike \"hard\" weights, which are computed during the backwards training pass, \"soft\" weights exist only in the forward pass and therefore change with every step of the input. Earlier designs implemented the attention mechanism in a serial recurrent neural network (RNN) language translation system, but a more recent design, namely the transformer, removed the slower sequential RNN and relied more heavily on the faster parallel attention scheme.\\nInspired by ideas about attention in humans, the attention mechanism was developed to address the weaknesses of using information from the hidden layers of recurrent neural networks. Recurrent neural networks favor more recent information contained in words at the end of a sentence, while information earlier in the sentence tends to be attenuated. Attention allows a token equal access to any part of a sentence directly, rather than only through the previous state.', 'source': 'https://en.wikipedia.org/wiki/Attention_(machine_learning)'}, page_content='In machine learning, attention is a method that determines the importance of each component in a sequence relative to the other components in that sequence. In natural language processing, importance is represented by \"soft\" weights assigned to each word in a sentence. More generally, attention encodes vectors called token embeddings across a fixed-width sequence that can range from tens to millions of tokens in size.\\nUnlike \"hard\" weights, which are computed during the backwards training pass, \"soft\" weights exist only in the forward pass and therefore change with every step of the input. Earlier designs implemented the attention mechanism in a serial recurrent neural network (RNN) language translation system, but a more recent design, namely the transformer, removed the slower sequential RNN and relied more heavily on the faster parallel attention scheme.'),\n",
       "  Document(id='bee45508-7b73-41be-9542-0741201193b3', metadata={'title': 'Attention (machine learning)', 'summary': 'In machine learning, attention is a method that determines the importance of each component in a sequence relative to the other components in that sequence. In natural language processing, importance is represented by \"soft\" weights assigned to each word in a sentence. More generally, attention encodes vectors called token embeddings across a fixed-width sequence that can range from tens to millions of tokens in size.\\nUnlike \"hard\" weights, which are computed during the backwards training pass, \"soft\" weights exist only in the forward pass and therefore change with every step of the input. Earlier designs implemented the attention mechanism in a serial recurrent neural network (RNN) language translation system, but a more recent design, namely the transformer, removed the slower sequential RNN and relied more heavily on the faster parallel attention scheme.\\nInspired by ideas about attention in humans, the attention mechanism was developed to address the weaknesses of using information from the hidden layers of recurrent neural networks. Recurrent neural networks favor more recent information contained in words at the end of a sentence, while information earlier in the sentence tends to be attenuated. Attention allows a token equal access to any part of a sentence directly, rather than only through the previous state.', 'source': 'https://en.wikipedia.org/wiki/Attention_(machine_learning)'}, page_content='== History ==\\n\\nAdditional surveys of the attention mechanism in deep learning are provided by Niu et al. and Soydaner.\\nThe major breakthrough came with self-attention, where each element in the input sequence attends to all others, enabling the model to capture global dependencies. This idea was central to the Transformer architecture, which replaced recurrence with attention mechanisms. As a result, Transformers became the foundation for models like BERT, T5 and generative pre-trained transformers (GPT).\\n\\n\\n== Overview ==\\n\\nThe modern era of machine attention was revitalized by grafting an attention mechanism (Fig 1.  orange) to an Encoder-Decoder.\\n\\nFigure 2 shows the internal step-by-step operation of the attention block (A) in Fig 1.'),\n",
       "  Document(id='347b2dde-3bbd-43b2-bf43-24cf311b719e', metadata={'title': 'Attention (machine learning)', 'summary': 'In machine learning, attention is a method that determines the importance of each component in a sequence relative to the other components in that sequence. In natural language processing, importance is represented by \"soft\" weights assigned to each word in a sentence. More generally, attention encodes vectors called token embeddings across a fixed-width sequence that can range from tens to millions of tokens in size.\\nUnlike \"hard\" weights, which are computed during the backwards training pass, \"soft\" weights exist only in the forward pass and therefore change with every step of the input. Earlier designs implemented the attention mechanism in a serial recurrent neural network (RNN) language translation system, but a more recent design, namely the transformer, removed the slower sequential RNN and relied more heavily on the faster parallel attention scheme.\\nInspired by ideas about attention in humans, the attention mechanism was developed to address the weaknesses of using information from the hidden layers of recurrent neural networks. Recurrent neural networks favor more recent information contained in words at the end of a sentence, while information earlier in the sentence tends to be attenuated. Attention allows a token equal access to any part of a sentence directly, rather than only through the previous state.', 'source': 'https://en.wikipedia.org/wiki/Attention_(machine_learning)'}, page_content='Sometimes, alignment can be multiple-to-multiple. For example, the English phrase look it up corresponds to cherchez-le. Thus, \"soft\" attention weights work better than \"hard\" attention weights (setting one attention weight to 1, and the others to 0), as we would like the model to make a context vector consisting of a weighted sum of the hidden vectors, rather than \"the best one\", as there may not be a best hidden vector.\\n\\n\\n== Variants ==\\n\\nMany variants of attention implement soft weights, such as\\n\\nfast weight programmers, or fast weight controllers (1992). A \"slow\" neural network outputs the \"fast\" weights of another neural network through outer products. The slow network learns by gradient descent. It was later renamed as \"linearized self-attention\".\\nBahdanau-style attention, also referred to as additive attention,\\nLuong-style attention, which is known as multiplicative attention,\\nEarly attention mechanisms similar t')]]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# a retriever interface for use in chains.\n",
    "# Retriever is LangChain's abstraction for \"anything that retrieves documents\".\n",
    "# This makes your RAG chain modular - you can swap retrievers easily.\n",
    "from typing import List\n",
    "\n",
    "from langchain_core.documents import Document\n",
    "from langchain_core.runnables import chain\n",
    "\n",
    "@chain\n",
    "def retrieverFn(query: str) -> List[Document]:\n",
    "    return vector_store.similarity_search(query, k=3)\n",
    "\n",
    "\n",
    "retrieverFn.batch(\n",
    "    [\n",
    "        query,\n",
    "        \"What is Parallelizing attention?\",\n",
    "    ],\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9174537e",
   "metadata": {},
   "source": [
    "### What is as_retriever() ?\n",
    "- as_retriever() is a convenience method on a vector store that returns a Retriever object (specifically a VectorStoreRetriever) ‚Äî a class specialized for retrieval tasks.\n",
    "- as_retriever() is about creating a retriever adapter over your vector store, exposing standardized methods to retrieve documents given a query, optionally with retrieval params.\n",
    "\n",
    "### How do they work together?\n",
    "- as_retriever() deals with what you want to do: ‚Äúretrieve relevant docs from vector store.‚Äù\n",
    "- @chain deals with how you integrate logic (possibly including the retriever) into a larger, composable, traceable pipeline.\n",
    "- A common pattern is to call a retriever (via .get_relevant_documents() or .similarity_search()) inside a function decorated with @chain ‚Äî exactly like your snippet. Then you can pipe that custom chain further (e.g. pass retrieved docs into prompt ‚Üí LLM ‚Üí parser), and everything remains a Runnable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "42195e76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[Document(id='9ed268d3-6e62-4bfb-a94d-394553689db6', metadata={'title': 'Transformer (deep learning)', 'summary': 'In deep learning, the transformer is an artificial neural network architecture based on the multi-head attention mechanism, in which text is converted to numerical representations called tokens, and each token is converted into a vector via lookup from a word embedding table. At each layer, each token is then contextualized within the scope of the context window with other (unmasked) tokens via a parallel multi-head attention mechanism, allowing the signal for key tokens to be amplified and less important tokens to be diminished. \\nTransformers have the advantage of having no recurrent units, therefore requiring less training time than earlier recurrent neural architectures (RNNs) such as long short-term memory (LSTM). Later variations have been widely adopted for training large language models (LLMs) on large (language) datasets.\\n\\nThe modern version of the transformer was proposed in the 2017 paper \"Attention Is All You Need\" by researchers at Google. The predecessors of transformers were developed as an improvement over previous architectures for machine translation, but have found many applications since. They are used in large-scale natural language processing, computer vision (vision transformers), reinforcement learning, audio, multimodal learning, robotics, and even playing chess. It has also led to the development of pre-trained systems, such as generative pre-trained transformers (GPTs) and BERT (bidirectional encoder representations from transformers).\\n\\n', 'source': 'https://en.wikipedia.org/wiki/Transformer_(deep_learning)'}, page_content='In deep learning, the transformer is an artificial neural network architecture based on the multi-head attention mechanism, in which text is converted to numerical representations called tokens, and each token is converted into a vector via lookup from a word embedding table. At each layer, each token is then contextualized within the scope of the context window with other (unmasked) tokens via a parallel multi-head attention mechanism, allowing the signal for key tokens to be amplified and less important tokens to be diminished. \\nTransformers have the advantage of having no recurrent units, therefore requiring less training time than earlier recurrent neural architectures (RNNs) such as long short-term memory (LSTM). Later variations have been widely adopted for training large language models (LLMs) on large (language) datasets.'),\n",
       " Document(id='ec94d334-b8f9-40f2-86df-03379f9f7fa2', metadata={'source': 'https://en.wikipedia.org/wiki/Transformer_(deep_learning)', 'title': 'Transformer (deep learning)', 'summary': 'In deep learning, the transformer is an artificial neural network architecture based on the multi-head attention mechanism, in which text is converted to numerical representations called tokens, and each token is converted into a vector via lookup from a word embedding table. At each layer, each token is then contextualized within the scope of the context window with other (unmasked) tokens via a parallel multi-head attention mechanism, allowing the signal for key tokens to be amplified and less important tokens to be diminished. \\nTransformers have the advantage of having no recurrent units, therefore requiring less training time than earlier recurrent neural architectures (RNNs) such as long short-term memory (LSTM). Later variations have been widely adopted for training large language models (LLMs) on large (language) datasets.\\n\\nThe modern version of the transformer was proposed in the 2017 paper \"Attention Is All You Need\" by researchers at Google. The predecessors of transformers were developed as an improvement over previous architectures for machine translation, but have found many applications since. They are used in large-scale natural language processing, computer vision (vision transformers), reinforcement learning, audio, multimodal learning, robotics, and even playing chess. It has also led to the development of pre-trained systems, such as generative pre-trained transformers (GPTs) and BERT (bidirectional encoder representations from transformers).\\n\\n'}, page_content='A key breakthrough was LSTM (1995), an RNN which used various innovations to overcome the vanishing gradient problem, allowing efficient learning of long-sequence modelling. One key innovation was the use of an attention mechanism which used neurons that multiply the outputs of other neurons, so-called multiplicative units. Neural networks using multiplicative units were later called sigma-pi networks or higher-order networks. LSTM became the standard architecture for long sequence modelling until the 2017 publication of transformers. However, LSTM still used sequential processing, like most other RNNs. Specifically, RNNs operate one token at a time from first to last; they cannot operate in parallel over all tokens in a sequence.'),\n",
       " Document(id='4434912e-5efd-4062-9f17-1c179abaff88', metadata={'title': 'Transformer (deep learning)', 'source': 'https://en.wikipedia.org/wiki/Transformer_(deep_learning)', 'summary': 'In deep learning, the transformer is an artificial neural network architecture based on the multi-head attention mechanism, in which text is converted to numerical representations called tokens, and each token is converted into a vector via lookup from a word embedding table. At each layer, each token is then contextualized within the scope of the context window with other (unmasked) tokens via a parallel multi-head attention mechanism, allowing the signal for key tokens to be amplified and less important tokens to be diminished. \\nTransformers have the advantage of having no recurrent units, therefore requiring less training time than earlier recurrent neural architectures (RNNs) such as long short-term memory (LSTM). Later variations have been widely adopted for training large language models (LLMs) on large (language) datasets.\\n\\nThe modern version of the transformer was proposed in the 2017 paper \"Attention Is All You Need\" by researchers at Google. The predecessors of transformers were developed as an improvement over previous architectures for machine translation, but have found many applications since. They are used in large-scale natural language processing, computer vision (vision transformers), reinforcement learning, audio, multimodal learning, robotics, and even playing chess. It has also led to the development of pre-trained systems, such as generative pre-trained transformers (GPTs) and BERT (bidirectional encoder representations from transformers).\\n\\n'}, page_content='=== Attention with seq2seq ===\\n\\nThe idea of encoder‚Äìdecoder sequence transduction had been developed in the early 2010s; commonly cited as the originators that produced seq2seq are two concurrently published papers from 2014.\\nA 380M-parameter model for machine translation uses two long short-term memories (LSTM). Its architecture consists of two parts. The encoder is an LSTM that takes in a sequence of tokens and turns it into a vector. The decoder is another LSTM that converts the vector into a sequence of tokens. Similarly, another 130M-parameter model used gated recurrent units (GRU) instead of LSTM. Later research showed that GRUs are neither better nor worse than LSTMs for seq2seq.\\nThese early seq2se')]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retriever = vector_store.as_retriever(\n",
    "    search_type=\"similarity\", search_kwargs={\"k\": 3}\n",
    ")\n",
    "search_docs = retriever.batch([\n",
    "        query,\n",
    "        \"What is Parallelizing attention?\",\n",
    "    ], filter={\"title\": \"Transformer (deep learning)\"})\n",
    "\n",
    "print(len(search_docs))\n",
    "search_docs[0]\n",
    "search_docs[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47eb3eab",
   "metadata": {},
   "source": [
    "### Create a tool that makes a vector search \n",
    "This tool will be given to an LLM via an agent. i.e create_agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "87bbc567",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.tools import tool\n",
    "\n",
    "@tool(response_format=\"content_and_artifact\")\n",
    "def retrieve_context(query: str):\n",
    "    \"\"\"Retrieve information to help answer a query.\"\"\"\n",
    "    retrieved_docs = vector_store.similarity_search(query, k=3)\n",
    "    serialized = \"\\n\\n\".join(\n",
    "        (f\"Source: {doc.metadata}\\nContent: {doc.page_content}\")\n",
    "        for doc in retrieved_docs\n",
    "    )\n",
    "    return serialized, retrieved_docs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45873262",
   "metadata": {},
   "source": [
    "### Load and initialise LLM to be used in the agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "01a9ecf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "os.environ[\"GROQ_API_KEY\"]=os.getenv(\"GROQ_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b18b870d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_groq import ChatGroq\n",
    "\n",
    "llm = ChatGroq(\n",
    "    model=\"llama-3.3-70b-versatile\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4163c903",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"J'adore la programmation.\", additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 9, 'prompt_tokens': 55, 'total_tokens': 64, 'completion_time': 0.027728082, 'completion_tokens_details': None, 'prompt_time': 0.001947106, 'prompt_tokens_details': None, 'queue_time': 0.058577383, 'total_time': 0.029675188}, 'model_name': 'llama-3.3-70b-versatile', 'system_fingerprint': 'fp_c06d5113ec', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None, 'model_provider': 'groq'}, id='lc_run--979d3217-86c6-44fd-bb61-542c0a2fb6ff-0', usage_metadata={'input_tokens': 55, 'output_tokens': 9, 'total_tokens': 64})"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "messages = [\n",
    "    (\n",
    "        \"system\",\n",
    "        \"You are a helpful assistant that translates English to French. Translate the user sentence.\",\n",
    "    ),\n",
    "    (\"human\", \"I love programming.\"),\n",
    "]\n",
    "ai_msg = llm.invoke(messages)\n",
    "ai_msg"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd775a72",
   "metadata": {},
   "source": [
    "### Define agent with tools and system prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "0c13603f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents import create_agent\n",
    "\n",
    "\n",
    "tools = [retrieve_context]\n",
    "# If desired, specify custom instructions\n",
    "prompt = (\n",
    "     \"You have access to a tool that retrieves context from a blog post. \"\n",
    "    \"Use the tool to help answer user queries.\"\n",
    ")\n",
    "agent = create_agent(llm, tools, system_prompt=prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2710b181",
   "metadata": {},
   "source": [
    "###  This agentic RAG formulation we allow the LLM to use its discretion in generating a tool call to help answer user queries.\n",
    "Drawbacks:\n",
    "- Two inference calls ‚Äì When a search is performed, it requires one call to generate the query and another to produce the final response.\n",
    "- Reduced control ‚Äì The LLM may skip searches when they are actually needed, or issue extra searches when unnecessary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c86caf42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "What was Elman network example and what year it was in? ?\n",
      "\n",
      "Once you get that answer, how it affected the RNNs.\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  retrieve_context (rwwwewjac)\n",
      " Call ID: rwwwewjac\n",
      "  Args:\n",
      "    query: Elman network example and year\n",
      "  retrieve_context (sh74g5px5)\n",
      " Call ID: sh74g5px5\n",
      "  Args:\n",
      "    query: Elman network impact on RNNs\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: retrieve_context\n",
      "\n",
      "Source: {'title': 'Attention (machine learning)', 'source': 'https://en.wikipedia.org/wiki/Attention_(machine_learning)', 'summary': 'In machine learning, attention is a method that determines the importance of each component in a sequence relative to the other components in that sequence. In natural language processing, importance is represented by \"soft\" weights assigned to each word in a sentence. More generally, attention encodes vectors called token embeddings across a fixed-width sequence that can range from tens to millions of tokens in size.\\nUnlike \"hard\" weights, which are computed during the backwards training pass, \"soft\" weights exist only in the forward pass and therefore change with every step of the input. Earlier designs implemented the attention mechanism in a serial recurrent neural network (RNN) language translation system, but a more recent design, namely the transformer, removed the slower sequential RNN and relied more heavily on the faster parallel attention scheme.\\nInspired by ideas about attention in humans, the attention mechanism was developed to address the weaknesses of using information from the hidden layers of recurrent neural networks. Recurrent neural networks favor more recent information contained in words at the end of a sentence, while information earlier in the sentence tends to be attenuated. Attention allows a token equal access to any part of a sentence directly, rather than only through the previous state.'}\n",
      "Content: Inspired by ideas about attention in humans, the attention mechanism was developed to address the weaknesses of using information from the hidden layers of recurrent neural networks. Recurrent neural networks favor more recent information contained in words at the end of a sentence, while information earlier in the sentence tends to be attenuated. Attention allows a token equal access to any part of a sentence directly, rather than only through the previous state.\n",
      "\n",
      "Source: {'source': 'https://en.wikipedia.org/wiki/Deep_learning', 'title': 'Deep learning', 'summary': 'In machine learning, deep learning focuses on utilizing multilayered neural networks to perform tasks such as classification, regression, and representation learning. The field takes inspiration from biological neuroscience and revolves around stacking artificial neurons into layers and \"training\" them to process data. The adjective \"deep\" refers to the use of multiple layers (ranging from three to several hundred or thousands) in the network. Methods used can be supervised, semi-supervised or unsupervised.\\nSome common deep learning network architectures include fully connected networks, deep belief networks, recurrent neural networks, convolutional neural networks, generative adversarial networks, transformers, and neural radiance fields. These architectures have been applied to fields including computer vision, speech recognition, natural language processing, machine translation, bioinformatics, drug design, medical image analysis, climate science, material inspection and board game programs, where they have produced results comparable to and in some cases surpassing human expert performance.\\nEarly forms of neural networks were inspired by information processing and distributed communication nodes in biological systems, particularly the human brain. However, current neural networks do not intend to model the brain function of organisms, and are generally seen as low-quality models for that purpose.\\n\\n'}\n",
      "Content: Some common deep learning network architectures include fully connected networks, deep belief networks, recurrent neural networks, convolutional neural networks, generative adversarial networks, transformers, and neural radiance fields. These architectures have been applied to fields including computer vision, speech recognition, natural language processing, machine translation, bioinformatics, drug design, medical image analysis, climate science, material inspection and board game programs, where they have produced results comparable to and in some cases surpassing human expert performance.\n",
      "Early forms of neural networks were inspired by information processing and distributed communication nodes in biological systems, particularly the human brain. However, current neural networks do not intend to model the brain function of organisms, and are generally seen as low-quality models for that purpose.\n",
      "\n",
      "Source: {'title': 'Transformer (deep learning)', 'source': 'https://en.wikipedia.org/wiki/Transformer_(deep_learning)', 'summary': 'In deep learning, the transformer is an artificial neural network architecture based on the multi-head attention mechanism, in which text is converted to numerical representations called tokens, and each token is converted into a vector via lookup from a word embedding table. At each layer, each token is then contextualized within the scope of the context window with other (unmasked) tokens via a parallel multi-head attention mechanism, allowing the signal for key tokens to be amplified and less important tokens to be diminished. \\nTransformers have the advantage of having no recurrent units, therefore requiring less training time than earlier recurrent neural architectures (RNNs) such as long short-term memory (LSTM). Later variations have been widely adopted for training large language models (LLMs) on large (language) datasets.\\n\\nThe modern version of the transformer was proposed in the 2017 paper \"Attention Is All You Need\" by researchers at Google. The predecessors of transformers were developed as an improvement over previous architectures for machine translation, but have found many applications since. They are used in large-scale natural language processing, computer vision (vision transformers), reinforcement learning, audio, multimodal learning, robotics, and even playing chess. It has also led to the development of pre-trained systems, such as generative pre-trained transformers (GPTs) and BERT (bidirectional encoder representations from transformers).\\n\\n'}\n",
      "Content: A key breakthrough was LSTM (1995), an RNN which used various innovations to overcome the vanishing gradient problem, allowing efficient learning of long-sequence modelling. One key innovation was the use of an attention mechanism which used neurons that multiply the outputs of other neurons, so-called multiplicative units. Neural networks using multiplicative units were later called sigma-pi networks or higher-order networks. LSTM became the standard architecture for long sequence modelling until the 2017 publication of transformers. However, LSTM still used sequential processing, like most other RNNs. Specifically, RNNs operate one token at a time from first to last; they cannot operate in parallel over all tokens in a sequence.\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "The Elman network example was introduced in 1990. It was an early example of a recurrent neural network (RNN) that was used for sequence modeling and generation. The Elman network was a simple RNN that used a feedback connection to capture temporal relationships in sequences. However, it suffered from the vanishing gradient problem, which made it difficult to train and limited its ability to model long-term dependencies.\n",
      "\n",
      "The Elman network affected the development of RNNs by highlighting the importance of addressing the vanishing gradient problem. This led to the development of more advanced RNN architectures, such as long short-term memory (LSTM) networks, which used various innovations to overcome the vanishing gradient problem. The Elman network also laid the foundation for the development of more complex RNN architectures, such as gated recurrent units (GRUs) and bidirectional RNNs.\n",
      "\n",
      "Overall, the Elman network was an important early example of an RNN, and its limitations and challenges helped to drive the development of more advanced RNN architectures that are still widely used today.\n"
     ]
    }
   ],
   "source": [
    "query = (\n",
    "    \"What was Elman network example and what year it was in? ?\\n\\n\"\n",
    "    \"Once you get that answer, how it affected the RNNs.\"\n",
    ")\n",
    "\n",
    "for event in agent.stream(\n",
    "    {\"messages\": [{\"role\": \"user\", \"content\": query}]},\n",
    "    stream_mode=\"values\",\n",
    "):\n",
    "    event[\"messages\"][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d0af6ad",
   "metadata": {},
   "source": [
    "### 2 step RAG chain that uses single LLM call per query.\n",
    "- @dynamic_prompt you are defining a function that, at runtime, builds a system prompt string based on the current request and agent state.\n",
    "\n",
    "- Why is it in middleware and used with create_agent?\n",
    "-> Middleware gives control over the agent lifecycle.\n",
    "The middleware abstraction in LangChain lets you hook into the agent‚Äôs lifecycle: before model call, after model call, wrap model call, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "3cadd7a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "What was Elman network example and what year it was in? ?\n",
      "\n",
      "Once you get that answer, how it affected the RNNs.\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "The Elman network example was a well-cited early example of sequence modelling and generation using plain recurrent neural networks (RNNs), and it was in the year 1990.\n",
      "\n",
      "The Elman network affected RNNs in that it demonstrated the potential of RNNs for sequence modelling, but it also highlighted the limitations of early RNNs. Specifically, the Elman network suffered from the vanishing-gradient problem, which made it difficult for the model to capture long-range dependencies in sequences. This meant that the information from one token could propagate arbitrarily far down the sequence in theory, but in practice, the model's state at the end of a long sentence would not have precise, extractable information about preceding tokens.\n",
      "\n",
      "This limitation of the Elman network and other early RNNs led to the development of new architectures, such as the LSTM (Long Short-Term Memory) network, which introduced innovations like multiplicative units and an attention mechanism to overcome the vanishing gradient problem. These advancements ultimately paved the way for more effective sequence modelling and generation using RNNs and later, transformers.\n"
     ]
    }
   ],
   "source": [
    "from langchain.agents.middleware import dynamic_prompt, ModelRequest\n",
    "\n",
    "@dynamic_prompt\n",
    "def prompt_with_context(request: ModelRequest) -> str:\n",
    "    \"\"\"Inject context into state messages.\"\"\"\n",
    "    last_query = request.state[\"messages\"][-1].text\n",
    "    retrieved_docs = vector_store.similarity_search(last_query)\n",
    "\n",
    "    docs_content = \"\\n\\n\".join(doc.page_content for doc in retrieved_docs)\n",
    "\n",
    "    system_message = (\n",
    "        \"You are a helpful assistant. Use the following context in your response:\"\n",
    "        f\"\\n\\n{docs_content}\"\n",
    "    )\n",
    "\n",
    "    return system_message\n",
    "\n",
    "\n",
    "agent = create_agent(llm, tools=[], middleware=[prompt_with_context])\n",
    "query = (\n",
    "    \"What was Elman network example and what year it was in? ?\\n\\n\"\n",
    "    \"Once you get that answer, how it affected the RNNs.\"\n",
    ")\n",
    "\n",
    "for event in agent.stream(\n",
    "    {\"messages\": [{\"role\": \"user\", \"content\": query}]},\n",
    "    stream_mode=\"values\",\n",
    "):\n",
    "    event[\"messages\"][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "449f6ed6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
