{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "52ce7bc4",
   "metadata": {},
   "source": [
    "## 01 – Tools and Tool Calling (Extending Models)\n",
    "\n",
    "**Key Concept**: Base LLMs can only generate text. Tools let them perform actions: call APIs, run calculations, fetch data, etc.\n",
    "\n",
    "**What this covers:**\n",
    "1. What tools are and why they matter\n",
    "2. Creating tools from Python functions\n",
    "3. Binding tools to models\n",
    "4. Manual tool-calling loop (foundation for agents)\n",
    "5. Building a reusable toolset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d85869ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yashsarode/Downloads/Personal Projects/Python/LangGraph-personal/.venv/lib/python3.13/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.messages import HumanMessage, AIMessage, ToolMessage\n",
    "from langchain_core.tools import tool\n",
    "from langchain_groq import ChatGroq\n",
    "\n",
    "# For type hints and structured inputs\n",
    "from typing import Annotated\n",
    "from pydantic import BaseModel, Field\n",
    "\n",
    "# Standard library\n",
    "import os\n",
    "from datetime import datetime\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e35711ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatGroq(\n",
    "    model=\"meta-llama/llama-4-maverick-17b-128e-instruct\", \n",
    "    temperature=0,  # Deterministic for consistent tool usage\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be6b739a",
   "metadata": {},
   "source": [
    "### What is a Tool?\n",
    "\n",
    "A **tool** in LangChain is:\n",
    "- A Python function with metadata (name, description, schema)\n",
    "- Something the LLM can \"call\" when it needs external capabilities\n",
    "- Executed in your Python runtime, not by the model\n",
    "\n",
    "**Why tools matter:**\n",
    "- LLMs can't do math reliably → Give them a calculator tool\n",
    "- LLMs can't access real-time data → Give them API tools\n",
    "- LLMs can't execute code → Give them interpreter tools\n",
    "\n",
    "The `@tool` decorator automatically converts functions into LangChain tools."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "edd13d80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tool name: calculator\n",
      "Tool description: Perform basic arithmetic operations. Use this when you need to calculate exact numerical results.\n",
      "\n",
      "Tool schema (what the model sees):\n",
      "{\n",
      "  \"description\": \"Perform basic arithmetic operations. Use this when you need to calculate exact numerical results.\",\n",
      "  \"properties\": {\n",
      "    \"operation\": {\n",
      "      \"description\": \"The math operation: 'add', 'subtract', 'multiply', 'divide'\",\n",
      "      \"title\": \"Operation\",\n",
      "      \"type\": \"string\"\n",
      "    },\n",
      "    \"a\": {\n",
      "      \"description\": \"First number\",\n",
      "      \"title\": \"A\",\n",
      "      \"type\": \"number\"\n",
      "    },\n",
      "    \"b\": {\n",
      "      \"description\": \"Second number\",\n",
      "      \"title\": \"B\",\n",
      "      \"type\": \"number\"\n",
      "    }\n",
      "  },\n",
      "  \"required\": [\n",
      "    \"operation\",\n",
      "    \"a\",\n",
      "    \"b\"\n",
      "  ],\n",
      "  \"title\": \"calculator\",\n",
      "  \"type\": \"object\"\n",
      "}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_v/fs86q2353gvdsjh19x_1fpdm0000gn/T/ipykernel_93074/3076482416.py:23: PydanticDeprecatedSince20: The `schema` method is deprecated; use `model_json_schema` instead. Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.12/migration/\n",
      "  print(json.dumps(calculator.args_schema.schema(), indent=2))\n"
     ]
    }
   ],
   "source": [
    "@tool\n",
    "def calculator(\n",
    "    operation: Annotated[str, \"The math operation: 'add', 'subtract', 'multiply', 'divide'\"],\n",
    "    a: Annotated[float, \"First number\"],\n",
    "    b: Annotated[float, \"Second number\"]\n",
    ") -> str:\n",
    "    \"\"\"Perform basic arithmetic operations. Use this when you need to calculate exact numerical results.\"\"\"\n",
    "    \n",
    "    operations = {\n",
    "        \"add\": a + b,\n",
    "        \"subtract\": a - b,\n",
    "        \"multiply\": a * b,\n",
    "        \"divide\": a / b if b != 0 else \"Error: Division by zero\"\n",
    "    }\n",
    "    \n",
    "    result = operations.get(operation.lower(), \"Error: Invalid operation\")\n",
    "    return f\"Result: {result}\"\n",
    "\n",
    "# what the tool looks like to the model\n",
    "print(f\"Tool name: {calculator.name}\")\n",
    "print(f\"Tool description: {calculator.description}\")\n",
    "print(f\"\\nTool schema (what the model sees):\")\n",
    "print(json.dumps(calculator.args_schema.schema(), indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "524fdeb2",
   "metadata": {},
   "source": [
    "### Tool Design Best Practices\n",
    "\n",
    "**1. Clear descriptions**: The LLM reads your docstring to decide when to use the tool  \n",
    "**2. Typed parameters**: Use type hints so the model knows what inputs are valid  \n",
    "**3. Return strings**: Models work best with string responses  \n",
    "**4. Keep them focused**: One tool = one clear responsibility  \n",
    "\n",
    "The `Annotated` type hints provide inline documentation that helps the model understand parameters.\n",
    "`Annotated[Type, metadata]` = \"This is of Type, AND here's extra information about it\n",
    "\n",
    "Without `Annotated`, the LLM only sees:\n",
    "```json\n",
    "{\n",
    "  \"operation\": \"string\",\n",
    "  \"a\": \"number\",\n",
    "  \"b\": \"number\"\n",
    "}\n",
    "```\n",
    "\n",
    "With Annotated, the LLM sees:\n",
    "```json\n",
    "{\n",
    "  \"operation\": {\n",
    "    \"type\": \"string\",\n",
    "    \"description\": \"The math operation: 'add', 'subtract', 'multiply', 'divide'\"\n",
    "  },\n",
    "  \"a\": {\n",
    "    \"type\": \"number\", \n",
    "    \"description\": \"First number\"\n",
    "  },\n",
    "  \"b\": {\n",
    "    \"type\": \"number\",\n",
    "    \"description\": \"Second number\"\n",
    "  }\n",
    "}\n",
    "```\n",
    "Structured Tools with Pydantic can also be used instead of Annotated\n",
    "\n",
    "```python\n",
    "from pydantic import BaseModel, Field\n",
    "from langchain_core.tools import tool\n",
    "\n",
    "class CalculatorInput(BaseModel):\n",
    "    \"\"\"Input schema for calculator tool.\"\"\"\n",
    "    operation: str = Field(\n",
    "        description=\"The math operation: 'add', 'subtract', 'multiply', 'divide'\"\n",
    "    )\n",
    "    a: float = Field(description=\"First number\")\n",
    "    b: float = Field(description=\"Second number\")\n",
    "\n",
    "@tool(args_schema=CalculatorInput)\n",
    "def calculator(operation: str, a: float, b: float) -> str:\n",
    "    \"\"\"Perform basic arithmetic operations.\"\"\"\n",
    "    # Implementation here\n",
    "    pass\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "96816853",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tool name: get_weather\n",
      "Tool description: Get current weather and optional forecast.\n",
      "\n",
      "Tool schema (what the model sees):\n",
      "{\n",
      "  \"description\": \"Input for weather queries.\",\n",
      "  \"properties\": {\n",
      "    \"location\": {\n",
      "      \"description\": \"City name or coordinates\",\n",
      "      \"title\": \"Location\",\n",
      "      \"type\": \"string\"\n",
      "    },\n",
      "    \"units\": {\n",
      "      \"default\": \"celsius\",\n",
      "      \"description\": \"Temperature unit preference\",\n",
      "      \"enum\": [\n",
      "        \"celsius\",\n",
      "        \"fahrenheit\"\n",
      "      ],\n",
      "      \"title\": \"Units\",\n",
      "      \"type\": \"string\"\n",
      "    },\n",
      "    \"include_forecast\": {\n",
      "      \"default\": false,\n",
      "      \"description\": \"Include 5-day forecast\",\n",
      "      \"title\": \"Include Forecast\",\n",
      "      \"type\": \"boolean\"\n",
      "    }\n",
      "  },\n",
      "  \"required\": [\n",
      "    \"location\"\n",
      "  ],\n",
      "  \"title\": \"WeatherInput\",\n",
      "  \"type\": \"object\"\n",
      "}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_v/fs86q2353gvdsjh19x_1fpdm0000gn/T/ipykernel_93074/3131039715.py:29: PydanticDeprecatedSince20: The `schema` method is deprecated; use `model_json_schema` instead. Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.12/migration/\n",
      "  print(json.dumps(get_weather.args_schema.schema(), indent=2))\n"
     ]
    }
   ],
   "source": [
    "from pydantic import BaseModel, Field\n",
    "from typing import Literal\n",
    "\n",
    "class WeatherInput(BaseModel):\n",
    "    \"\"\"Input for weather queries.\"\"\"\n",
    "    location: str = Field(description=\"City name or coordinates\")\n",
    "    units: Literal[\"celsius\", \"fahrenheit\"] = Field(\n",
    "        default=\"celsius\",\n",
    "        description=\"Temperature unit preference\"\n",
    "    )\n",
    "    include_forecast: bool = Field(\n",
    "        default=False,\n",
    "        description=\"Include 5-day forecast\"\n",
    "    )\n",
    "\n",
    "@tool(args_schema=WeatherInput)\n",
    "def get_weather(location: str, units: str = \"celsius\", include_forecast: bool = False) -> str:\n",
    "    \"\"\"Get current weather and optional forecast.\"\"\"\n",
    "    temp = 22 if units == \"celsius\" else 72\n",
    "    result = f\"Current weather in {location}: {temp} degrees {units[0].upper()}\"\n",
    "    if include_forecast:\n",
    "        result += \"\\nNext 5 days: Sunny\"\n",
    "    return result\n",
    "\n",
    "# what the tool looks like to the model\n",
    "print(f\"Tool name: {get_weather.name}\")\n",
    "print(f\"Tool description: {get_weather.description}\")\n",
    "print(f\"\\nTool schema (what the model sees):\")\n",
    "print(json.dumps(get_weather.args_schema.schema(), indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e683205f",
   "metadata": {},
   "source": [
    "### Binding Tools to Models\n",
    "\n",
    "Now comes the magic: we tell the model about our tools using `bind_tools()`.\n",
    "\n",
    "**What happens behind the scenes:**\n",
    "1. LangChain converts tool schemas to the format your model expects (OpenAI, Anthropic, etc.)\n",
    "2. The model can now \"see\" available tools in its context\n",
    "3. When needed, the model outputs a **tool call** instead of text\n",
    "\n",
    "**Important**: Not all models support tool calling. Check your model's capabilities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "090fe799",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Bound 2 tools to model\n",
      "Tools available: ['calculator', 'get_weather']\n"
     ]
    }
   ],
   "source": [
    "# Create our toolset\n",
    "tools = [calculator, get_weather]\n",
    "\n",
    "# Bind tools to the model\n",
    "# This doesn't execute anything yet - just tells the model tools exist\n",
    "llm_with_tools = llm.bind_tools(tools)\n",
    "\n",
    "print(f\"✓ Bound {len(tools)} tools to model\")\n",
    "print(f\"Tools available: {[t.name for t in tools]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11f70beb",
   "metadata": {},
   "source": [
    "### How Tool Calling Works\n",
    "\n",
    "**User asks a question** → Model decides:\n",
    "- **Option A**: Answer directly (no tools needed)\n",
    "- **Option B**: Call one or more tools, then synthesize final answer\n",
    "\n",
    "When the model chooses Option B, it returns an `AIMessage` with `tool_calls` instead of content."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "775afdd7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response type: AIMessage\n",
      "Content: The capital of France is Paris.\n",
      "Tool calls: []\n"
     ]
    }
   ],
   "source": [
    "# Question that doesn't need tools\n",
    "response = llm_with_tools.invoke([\n",
    "    HumanMessage(content=\"What is the capital of France?\")\n",
    "])\n",
    "\n",
    "print(\"Response type:\", type(response).__name__)\n",
    "print(\"Content:\", response.content)\n",
    "print(\"Tool calls:\", response.tool_calls)  # Should be empty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "78c6f070",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response type: AIMessage\n",
      "Content: \n",
      "\n",
      "Tool calls made:\n",
      "[\n",
      "  {\n",
      "    \"name\": \"calculator\",\n",
      "    \"args\": {\n",
      "      \"a\": 847,\n",
      "      \"b\": 923,\n",
      "      \"operation\": \"multiply\"\n",
      "    },\n",
      "    \"id\": \"b9nywn478\",\n",
      "    \"type\": \"tool_call\"\n",
      "  }\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "# Question requiring calculation\n",
    "response = llm_with_tools.invoke([\n",
    "    HumanMessage(content=\"What is 847 multiplied by 923?\")\n",
    "])\n",
    "\n",
    "print(\"Response type:\", type(response).__name__)\n",
    "print(\"Content:\", response.content)\n",
    "print(\"\\nTool calls made:\")\n",
    "print(json.dumps(response.tool_calls, indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93e61a05",
   "metadata": {},
   "source": [
    "### Manual Tool Execution Loop\n",
    "\n",
    "When the model returns a tool call, **we** need to:\n",
    "1. Execute the Python function\n",
    "2. Send the result back to the model\n",
    "3. Let the model generate the final answer\n",
    "\n",
    "This is what agents automate. But understanding this flow is crucial.\n",
    "\n",
    "**The loop:**\n",
    "```\n",
    "User Query → Model → Tool Call? → Execute Tool → Model → Final Answer\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d5616461",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_tool_calling_flow(user_query: str):\n",
    "    \"\"\"\n",
    "    Manual implementation of what agents do automatically.\n",
    "    This helps understand the mechanics before we abstract it away.\n",
    "    \"\"\"\n",
    "    \n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"USER: {user_query}\")\n",
    "    print('='*60)\n",
    "    \n",
    "    # Step 1: Send query to model\n",
    "    messages = [HumanMessage(content=user_query)]\n",
    "    response = llm_with_tools.invoke(messages)\n",
    "    \n",
    "    # Step 2: Check if model wants to call tools\n",
    "    if not response.tool_calls:\n",
    "        print(f\"\\nMODEL (Direct answer): {response.content}\")\n",
    "        return response.content\n",
    "    \n",
    "    # Step 3: Model called tools - execute them\n",
    "    print(f\"\\nMODEL: I need to call {len(response.tool_calls)} tool(s)...\")\n",
    "    messages.append(response)  # Add model's tool call to history\n",
    "    \n",
    "    # Create a mapping of tool names to actual functions\n",
    "    tool_map = {t.name: t for t in tools}\n",
    "    \n",
    "    for tool_call in response.tool_calls:\n",
    "        tool_name = tool_call[\"name\"]\n",
    "        tool_args = tool_call[\"args\"]\n",
    "        tool_id = tool_call[\"id\"]\n",
    "        \n",
    "        print(f\"\\n  → Calling: {tool_name}\")\n",
    "        print(f\"    Arguments: {tool_args}\")\n",
    "        \n",
    "        # Execute the tool\n",
    "        selected_tool = tool_map[tool_name]\n",
    "        tool_output = selected_tool.invoke(tool_args)\n",
    "        \n",
    "        print(f\"    Result: {tool_output}\")\n",
    "        \n",
    "        # Step 4: Add tool result to message history\n",
    "        messages.append(ToolMessage(\n",
    "            content=str(tool_output),\n",
    "            tool_call_id=tool_id,\n",
    "            name=tool_name\n",
    "        ))\n",
    "    \n",
    "    # Step 5: Send everything back to model for final answer\n",
    "    final_response = llm_with_tools.invoke(messages)\n",
    "    print(f\"\\nMODEL (Final answer): {final_response.content}\")\n",
    "    \n",
    "    return final_response.content\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "183c3213",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "USER: What is 15% of 2,450?\n",
      "============================================================\n",
      "\n",
      "MODEL: I need to call 1 tool(s)...\n",
      "\n",
      "  → Calling: calculator\n",
      "    Arguments: {'a': 2450, 'b': 0.15, 'operation': 'multiply'}\n",
      "    Result: Result: 367.5\n",
      "\n",
      "MODEL (Final answer): The result of 15% of 2,450 is 367.5.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'The result of 15% of 2,450 is 367.5.'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test 1: Simple calculation\n",
    "run_tool_calling_flow(\"What is 15% of 2,450?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b860f081",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
