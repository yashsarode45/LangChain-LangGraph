{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "06e6a870",
   "metadata": {},
   "source": [
    "## 05 - Structured Output and Typing\n",
    "\n",
    "**Key Concept**: LLMs generate text by default. Structured output forces them to return validated Python objects or JSON that downstream systems can reliably consume.\n",
    "\n",
    "**What this covers:**\n",
    "1. Why structured output matters for production systems\n",
    "2. Defining schemas with Pydantic, dataclasses, TypedDict\n",
    "3. Direct model-to-structured output (no agents)\n",
    "4. Combining structured output with runnables\n",
    "5. Structured output in agent workflows\n",
    "6. Error handling and validation strategies\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "15f52d4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yashsarode/Downloads/Personal Projects/Python/LangGraph-personal/.venv/lib/python3.13/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from langchain_groq import ChatGroq\n",
    "from langchain_core.messages import HumanMessage, SystemMessage\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "# For structured output schemas\n",
    "from pydantic import BaseModel, Field\n",
    "from typing import Optional, List, Literal, Union\n",
    "from dataclasses import dataclass\n",
    "from typing_extensions import TypedDict\n",
    "\n",
    "import json\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f7983f48",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatGroq(\n",
    "    model=\"openai/gpt-oss-120b\",\n",
    "    temperature=0,  # Deterministic for consistent structured output\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "495ceee0",
   "metadata": {},
   "source": [
    "### Why Structured Output?\n",
    "\n",
    "**The problem with free-form text:**\n",
    "- Parsing is fragile: regex breaks on edge cases\n",
    "- Downstream systems (DBs, APIs) need predictable formats\n",
    "- Testing becomes harder without type guarantees\n",
    "\n",
    "**Structured output provides:**\n",
    "- Schema-enforced responses: model MUST return valid data\n",
    "- Automatic validation: Pydantic catches type errors\n",
    "- IDE support: autocomplete and type checking work\n",
    "\n",
    "Think of it as a contract between your LLM and the rest of your application.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db8865b9",
   "metadata": {},
   "source": [
    "### Defining Output Schemas\n",
    "\n",
    "Three common approaches, each with trade-offs:\n",
    "\n",
    "**1. Pydantic models** (recommended)\n",
    "- Rich validation, nested types, custom validators\n",
    "- Best IDE support and documentation\n",
    "\n",
    "**2. Dataclasses**\n",
    "- Simpler syntax, built into Python\n",
    "- Less validation power than Pydantic\n",
    "\n",
    "**3. TypedDict**\n",
    "- Lightweight, dict-like access\n",
    "- Good for simple key-value structures\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "13d37d38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Schemas defined:\n",
      "  - MovieInfo (Pydantic): ['title', 'year', 'genre', 'director', 'rating']\n",
      "  - TaskItem (dataclass): ['description', 'priority', 'due_date']\n",
      "  - ContactInfo (TypedDict): ['name', 'email', 'phone']\n"
     ]
    }
   ],
   "source": [
    "# Pydantic - the most powerful option\n",
    "class MovieInfo(BaseModel):\n",
    "    \"\"\"Information extracted from a movie description.\"\"\"\n",
    "    title: str = Field(description=\"The movie title\")\n",
    "    year: int = Field(description=\"Release year\")\n",
    "    genre: Literal[\"action\", \"comedy\", \"drama\", \"sci-fi\", \"horror\", \"other\"] = Field(\n",
    "        description=\"Primary genre of the movie\"\n",
    "    )\n",
    "    director: Optional[str] = Field(default=None, description=\"Director name if mentioned\")\n",
    "    rating: Optional[float] = Field(default=None, description=\"Rating out of 10 if mentioned\", ge=0, le=10)\n",
    "\n",
    "# Dataclass alternative\n",
    "@dataclass\n",
    "class TaskItem:\n",
    "    \"\"\"A task extracted from user input.\"\"\"\n",
    "    description: str\n",
    "    priority: str  # \"low\", \"medium\", \"high\"\n",
    "    due_date: Optional[str] = None\n",
    "\n",
    "# TypedDict alternative\n",
    "class ContactInfo(TypedDict):\n",
    "    \"\"\"Contact information extracted from text.\"\"\"\n",
    "    name: str\n",
    "    email: str\n",
    "    phone: Optional[str]\n",
    "\n",
    "print(\"Schemas defined:\")\n",
    "print(f\"  - MovieInfo (Pydantic): {list(MovieInfo.model_fields.keys())}\")\n",
    "print(f\"  - TaskItem (dataclass): {[f for f in TaskItem.__dataclass_fields__.keys()]}\")\n",
    "print(f\"  - ContactInfo (TypedDict): {list(ContactInfo.__annotations__.keys())}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b9007c0",
   "metadata": {},
   "source": [
    "### Direct Model to Structured Output\n",
    "\n",
    "The simplest pattern: call `model.with_structured_output(Schema)` and get back a Python object.\n",
    "\n",
    "**How it works:**\n",
    "1. LangChain converts your schema to JSON schema\n",
    "2. Model is instructed to return data matching that schema\n",
    "3. Response is parsed and validated automatically\n",
    "\n",
    "No agents, no tools - just direct extraction.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "393385fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Type: MovieInfo\n",
      "\n",
      "Extracted MovieInfo:\n",
      "  Title: Inception\n",
      "  Year: 2010\n",
      "  Genre: sci-fi\n",
      "  Director: Christopher Nolan\n",
      "  Rating: 9.0\n"
     ]
    }
   ],
   "source": [
    "# Bind schema to model\n",
    "structured_llm = llm.with_structured_output(MovieInfo)\n",
    "\n",
    "# Extract structured data from text\n",
    "movie_text = \"\"\"\n",
    "I just watched Inception (2010) directed by Christopher Nolan. \n",
    "It's a mind-bending sci-fi thriller about dreams within dreams.\n",
    "I'd give it a solid 9 out of 10.\n",
    "\"\"\"\n",
    "\n",
    "result = structured_llm.invoke(movie_text)\n",
    "\n",
    "print(f\"Type: {type(result).__name__}\")\n",
    "print(f\"\\nExtracted MovieInfo:\")\n",
    "print(f\"  Title: {result.title}\")\n",
    "print(f\"  Year: {result.year}\")\n",
    "print(f\"  Genre: {result.genre}\")\n",
    "print(f\"  Director: {result.director}\")\n",
    "print(f\"  Rating: {result.rating}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "18644932",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Partial extraction (missing director, rating):\n",
      "  Title: The Dark Knight\n",
      "  Year: 2008\n",
      "  Genre: action\n",
      "  Director: None\n",
      "  Rating: None\n"
     ]
    }
   ],
   "source": [
    "# Handling missing information gracefully\n",
    "# Optional fields stay None when data isn't present\n",
    "\n",
    "partial_text = \"The Dark Knight is an amazing action movie from 2008.\"\n",
    "\n",
    "result = structured_llm.invoke(partial_text)\n",
    "\n",
    "print(\"Partial extraction (missing director, rating):\")\n",
    "print(f\"  Title: {result.title}\")\n",
    "print(f\"  Year: {result.year}\")\n",
    "print(f\"  Genre: {result.genre}\")\n",
    "print(f\"  Director: {result.director}\")\n",
    "print(f\"  Rating: {result.rating}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6e5d505",
   "metadata": {},
   "source": [
    "### Validation in Action\n",
    "\n",
    "Pydantic validates data at parse time. If the model returns invalid data:\n",
    "- Type mismatches raise `ValidationError`\n",
    "- Constraint violations (ge, le, regex) are caught\n",
    "- Required fields must be present\n",
    "\n",
    "This catches errors early, before they propagate through your system.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "79ca780c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Product: Sony WH-1000XM5 headphones\n",
      "Rating: 4/5\n",
      "Sentiment: positive\n",
      "Key points:\n",
      "  - Incredible noise cancellation\n",
      "  - Great battery life\n",
      "  - A bit pricey\n"
     ]
    }
   ],
   "source": [
    "# Schema with strict constraints\n",
    "class ProductReview(BaseModel):\n",
    "    \"\"\"A product review with validated fields.\"\"\"\n",
    "    product_name: str = Field(description=\"Name of the product\")\n",
    "    rating: int = Field(description=\"Rating from 1 to 5\", ge=1, le=5)\n",
    "    sentiment: Literal[\"positive\", \"negative\", \"neutral\"] = Field(\n",
    "        description=\"Overall sentiment of the review\"\n",
    "    )\n",
    "    key_points: List[str] = Field(\n",
    "        description=\"Main points from the review, max 3 items\",\n",
    "        max_length=3\n",
    "    )\n",
    "\n",
    "review_llm = llm.with_structured_output(ProductReview)\n",
    "\n",
    "review_text = \"\"\"\n",
    "Just got the Sony WH-1000XM5 headphones. The noise cancellation is incredible,\n",
    "battery life is great, but they're a bit pricey. Overall very happy with the purchase.\n",
    "Would rate them 4 out of 5.\n",
    "\"\"\"\n",
    "\n",
    "review = review_llm.invoke(review_text)\n",
    "\n",
    "print(f\"Product: {review.product_name}\")\n",
    "print(f\"Rating: {review.rating}/5\")\n",
    "print(f\"Sentiment: {review.sentiment}\")\n",
    "print(f\"Key points:\")\n",
    "for point in review.key_points:\n",
    "    print(f\"  - {point}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59b9404a",
   "metadata": {},
   "source": [
    "### Combining Structured Output with Runnables\n",
    "\n",
    "Structured output fits naturally into LangChain's Runnable pipeline pattern.\n",
    "\n",
    "**Pipeline flow:**\n",
    "```\n",
    "Input text -> Prompt template -> Model (structured) -> Python object\n",
    "```\n",
    "\n",
    "The output object can then feed directly into:\n",
    "- Database writes\n",
    "- API calls\n",
    "- Further model calls\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8ce1d790",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Meeting: Q3 Planning Meeting\n",
      "Attendees: Sarah, Mike, Jennifer, David\n",
      "\n",
      "Action Items:\n",
      "  - Sarah will finalize the budget by Friday\n",
      "  - Mike to coordinate with engineering on the new feature timeline\n",
      "  - Jennifer will prepare the customer presentation for next week\n",
      "\n",
      "Next Meeting: July 22nd\n"
     ]
    }
   ],
   "source": [
    "# Schema for meeting notes extraction\n",
    "class MeetingNotes(BaseModel):\n",
    "    \"\"\"Structured meeting notes.\"\"\"\n",
    "    title: str = Field(description=\"Meeting title or topic\")\n",
    "    attendees: List[str] = Field(description=\"List of attendee names\")\n",
    "    action_items: List[str] = Field(description=\"List of action items\")\n",
    "    next_meeting: Optional[str] = Field(default=None, description=\"Next meeting date if mentioned\")\n",
    "\n",
    "# Build a reusable extraction pipeline\n",
    "extraction_prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"Extract structured meeting information from the provided notes. Be precise and only include information explicitly mentioned.\"),\n",
    "    (\"human\", \"{text}\")\n",
    "])\n",
    "\n",
    "# Chain: prompt -> structured model\n",
    "meeting_extractor = extraction_prompt | llm.with_structured_output(MeetingNotes)\n",
    "\n",
    "# Test the pipeline\n",
    "raw_notes = \"\"\"\n",
    "Q3 Planning Meeting - July 15th\n",
    "Present: Sarah, Mike, Jennifer, David\n",
    "\n",
    "Discussed roadmap priorities for Q3. Sarah will finalize the budget by Friday.\n",
    "Mike to coordinate with engineering on the new feature timeline.\n",
    "Jennifer will prepare the customer presentation for next week.\n",
    "\n",
    "Next sync scheduled for July 22nd.\n",
    "\"\"\"\n",
    "\n",
    "notes = meeting_extractor.invoke({\"text\": raw_notes})\n",
    "\n",
    "print(f\"Meeting: {notes.title}\")\n",
    "print(f\"Attendees: {', '.join(notes.attendees)}\")\n",
    "print(f\"\\nAction Items:\")\n",
    "for item in notes.action_items:\n",
    "    print(f\"  - {item}\")\n",
    "print(f\"\\nNext Meeting: {notes.next_meeting}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "435c159d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch extraction results:\n",
      "\n",
      "1. Sprint Retro - Team Alpha\n",
      "   Attendees: ['John', 'Lisa']\n",
      "   Actions: ['John to update docs']\n",
      "\n",
      "2. 1:1 with Manager\n",
      "   Attendees: ['You', 'Boss']\n",
      "   Actions: ['Submit self-review by Monday']\n"
     ]
    }
   ],
   "source": [
    "# Batch processing with structured output\n",
    "# The same pipeline works with .batch() for multiple inputs\n",
    "\n",
    "meeting_texts = [\n",
    "    {\"text\": \"Sprint Retro - Team Alpha. Attendees: John, Lisa. Action: John to update docs.\"},\n",
    "    {\"text\": \"1:1 with Manager. Present: You, Boss. Follow-up: Submit self-review by Monday.\"},\n",
    "]\n",
    "\n",
    "results = meeting_extractor.batch(meeting_texts)\n",
    "\n",
    "print(\"Batch extraction results:\")\n",
    "for i, notes in enumerate(results, 1):\n",
    "    print(f\"\\n{i}. {notes.title}\")\n",
    "    print(f\"   Attendees: {notes.attendees}\")\n",
    "    print(f\"   Actions: {notes.action_items}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "708cdaeb",
   "metadata": {},
   "source": [
    "### Structured Output in Agent Workflows\n",
    "\n",
    "Agents can return structured output as their final response. Two approaches:\n",
    "\n",
    "**1. Native structured output (response_format)**\n",
    "- Agent directly returns the schema\n",
    "- Requires model support for structured output\n",
    "\n",
    "**2. Two-step: Agent text -> Formatter model**\n",
    "- Agent returns free-form text\n",
    "- Second model converts to structured format\n",
    "- Works with any model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4bad835",
   "metadata": {},
   "source": [
    "### Response Format\n",
    "Controls how the agent returns structured data:\n",
    "- `ToolStrategy[StructuredResponseT]`: Uses tool calling for structured output\n",
    "- `ProviderStrategy[StructuredResponseT]`: Uses provider-native structured output\n",
    "- `type[StructuredResponseT]`: Schema type - automatically selects best strategy based on model capabilities\n",
    "- `None`: No structured output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "53e128f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Research agent created with structured output\n"
     ]
    }
   ],
   "source": [
    "from langchain.agents import create_agent\n",
    "from langchain.tools import tool\n",
    "\n",
    "# Define output schema for agent\n",
    "class ResearchResult(BaseModel):\n",
    "    \"\"\"Structured research findings.\"\"\"\n",
    "    topic: str = Field(description=\"The research topic\")\n",
    "    findings: List[str] = Field(description=\"Key findings from research\")\n",
    "    data_sources: List[str] = Field(description=\"Sources of data used\")\n",
    "    confidence: Literal[\"low\", \"medium\", \"high\"] = Field(\n",
    "        description=\"Confidence level in the findings\"\n",
    "    )\n",
    "\n",
    "# Simple research tools\n",
    "@tool\n",
    "def search_database(query: str) -> str:\n",
    "    \"\"\"Search internal database for information.\"\"\"\n",
    "    # Simulated database\n",
    "    data = {\n",
    "        \"sales\": \"Q3 sales: $2.4M, up 15% YoY. Top product: Widget Pro.\",\n",
    "        \"customers\": \"Active customers: 1,247. Churn rate: 3.2%. NPS: 72.\",\n",
    "        \"inventory\": \"Stock levels healthy. Widget Pro: 500 units. Widget Basic: 1200 units.\"\n",
    "    }\n",
    "    for key, value in data.items():\n",
    "        if key in query.lower():\n",
    "            return value\n",
    "    return \"No matching data found.\"\n",
    "\n",
    "@tool\n",
    "def get_market_report(sector: str) -> str:\n",
    "    \"\"\"Get market report for a sector.\"\"\"\n",
    "    return f\"Market report for {sector}: Growth rate 8%, competition increasing, favorable regulations.\"\n",
    "\n",
    "# Create agent with structured output\n",
    "research_agent = create_agent(\n",
    "    llm,\n",
    "    tools=[search_database, get_market_report],\n",
    "    system_prompt=\"\"\"You are a research assistant. Use the available tools to gather information,\n",
    "then return your findings in the structured format specified.\"\"\",\n",
    "    response_format=ResearchResult\n",
    ")\n",
    "\n",
    "print(\"Research agent created with structured output\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7d5d1c36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'messages': [HumanMessage(content='Research our current sales performance and customer metrics.', additional_kwargs={}, response_metadata={}, id='5caa90b6-b182-450e-8900-a6678a7d12ed'), AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 's5qx2p214', 'function': {'arguments': '{\"query\":\"current sales performance and customer metrics\"}', 'name': 'search_database'}, 'type': 'function'}]}, response_metadata={'token_usage': {'completion_tokens': 34, 'prompt_tokens': 894, 'total_tokens': 928, 'completion_time': 0.051710421, 'completion_tokens_details': None, 'prompt_time': 0.018556597, 'prompt_tokens_details': None, 'queue_time': 0.052474922, 'total_time': 0.070267018}, 'model_name': 'meta-llama/llama-4-maverick-17b-128e-instruct', 'system_fingerprint': 'fp_d2c1f7e199', 'service_tier': 'on_demand', 'finish_reason': 'tool_calls', 'logprobs': None, 'model_provider': 'groq'}, id='lc_run--fcc5683a-6943-4c11-9440-b938792ec7d5-0', tool_calls=[{'name': 'search_database', 'args': {'query': 'current sales performance and customer metrics'}, 'id': 's5qx2p214', 'type': 'tool_call'}], usage_metadata={'input_tokens': 894, 'output_tokens': 34, 'total_tokens': 928}), ToolMessage(content='Q3 sales: $2.4M, up 15% YoY. Top product: Widget Pro.', name='search_database', id='f8ff2c5d-8080-4a7f-8068-4c9359fcf875', tool_call_id='s5qx2p214'), AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'qp6z6ntew', 'function': {'arguments': '{\"confidence\":\"high\",\"data_sources\":[\"Internal sales database\"],\"findings\":[\"Q3 sales: $2.4M, up 15% YoY\",\"Top product: Widget Pro\"],\"topic\":\"Current sales performance and customer metrics\"}', 'name': 'ResearchResult'}, 'type': 'function'}]}, response_metadata={'token_usage': {'completion_tokens': 90, 'prompt_tokens': 971, 'total_tokens': 1061, 'completion_time': 0.11046404, 'completion_tokens_details': None, 'prompt_time': 0.020971525, 'prompt_tokens_details': None, 'queue_time': 0.052424345, 'total_time': 0.131435565}, 'model_name': 'meta-llama/llama-4-maverick-17b-128e-instruct', 'system_fingerprint': 'fp_d2c1f7e199', 'service_tier': 'on_demand', 'finish_reason': 'tool_calls', 'logprobs': None, 'model_provider': 'groq'}, id='lc_run--2c80bea8-bce1-4431-a623-d3733a15975c-0', tool_calls=[{'name': 'ResearchResult', 'args': {'confidence': 'high', 'data_sources': ['Internal sales database'], 'findings': ['Q3 sales: $2.4M, up 15% YoY', 'Top product: Widget Pro'], 'topic': 'Current sales performance and customer metrics'}, 'id': 'qp6z6ntew', 'type': 'tool_call'}], usage_metadata={'input_tokens': 971, 'output_tokens': 90, 'total_tokens': 1061}), ToolMessage(content=\"Returning structured response: topic='Current sales performance and customer metrics' findings=['Q3 sales: $2.4M, up 15% YoY', 'Top product: Widget Pro'] data_sources=['Internal sales database'] confidence='high'\", name='ResearchResult', id='f9a40e07-6587-49f1-81e6-c2c58fd45347', tool_call_id='qp6z6ntew')], 'structured_response': ResearchResult(topic='Current sales performance and customer metrics', findings=['Q3 sales: $2.4M, up 15% YoY', 'Top product: Widget Pro'], data_sources=['Internal sales database'], confidence='high')}\n",
      "Topic: Current sales performance and customer metrics\n",
      "\n",
      "Findings:\n",
      "  - Q3 sales: $2.4M, up 15% YoY\n",
      "  - Top product: Widget Pro\n",
      "\n",
      "Data Sources: ['Internal sales database']\n",
      "Confidence: high\n"
     ]
    }
   ],
   "source": [
    "# Run the agent - it will use tools and return structured data\n",
    "result = research_agent.invoke({\n",
    "    \"messages\": [{\"role\": \"user\", \"content\": \"Research our current sales performance and customer metrics.\"}]\n",
    "})\n",
    "print(result)\n",
    "# Access structured response\n",
    "if \"structured_response\" in result:\n",
    "    research = result[\"structured_response\"]\n",
    "    print(f\"Topic: {research.topic}\")\n",
    "    print(f\"\\nFindings:\")\n",
    "    for finding in research.findings:\n",
    "        print(f\"  - {finding}\")\n",
    "    print(f\"\\nData Sources: {research.data_sources}\")\n",
    "    print(f\"Confidence: {research.confidence}\")\n",
    "else:\n",
    "    # Fallback: check last message content\n",
    "    print(\"Agent response:\")\n",
    "    print(result[\"messages\"][-1].content)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b43e4670",
   "metadata": {},
   "source": [
    "### `ProviderStrategy[StructuredResponseT]`\n",
    "- ProviderStrategy uses the LLM provider’s native support for structured output. That means the provider/model API itself has some mechanism (e.g. JSON mode, function-calling, “structured response” mode) to generate a well-formed JSON (or other structured) output that matches a schema.\n",
    "- This is ideal if your chosen model/provider supports structured output natively\n",
    "\n",
    "### `ToolStrategy[StructuredResponseT]` \n",
    "- ToolStrategy uses tool-calling under the hood to enforce structured output. That means LangChain treats the structured response as if it were the “arguments” of a (virtual) tool call, even if no real external side-effect happens. The LLM is prompted to produce a “tool call” with arguments matching your schema, and LangChain captures the arguments as structured data.\n",
    "- Useful when the model/provider does not support native structured output. In that case, ToolStrategy gives you a fallback mechanism so that you still can get structured data, even though the model may only output free-form text — because you treat the output as a “tool call.”\n",
    "\n",
    "Note: If the provider natively supports structured output for your model choice, it is functionally equivalent to write response_format=ProductReview instead of response_format=ProviderStrategy(ProductReview). In either case, if structured output is not supported, the agent will fall back to a tool calling strategy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79c8f614",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ProductReview(rating=5, sentiment='positive', key_points=['fast shipping', 'expensive'])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pydantic import BaseModel, Field\n",
    "from typing import Literal\n",
    "from langchain.agents import create_agent\n",
    "from langchain.agents.structured_output import ToolStrategy\n",
    "\n",
    "\n",
    "class ProductReview(BaseModel):\n",
    "    \"\"\"Analysis of a product review.\"\"\"\n",
    "    rating: int | None = Field(description=\"The rating of the product\", ge=1, le=5)\n",
    "    sentiment: Literal[\"positive\", \"negative\"] = Field(description=\"The sentiment of the review\")\n",
    "    key_points: list[str] = Field(description=\"The key points of the review. Lowercase, 1-3 words each.\")\n",
    "\n",
    "agent = create_agent(\n",
    "    llm,\n",
    "    response_format=ToolStrategy(ProductReview)\n",
    ")\n",
    "\n",
    "result = agent.invoke({\n",
    "    \"messages\": [{\"role\": \"user\", \"content\": \"Analyze this review: 'Great product: 5 out of 5 stars. Fast shipping, but expensive'\"}]\n",
    "})\n",
    "result[\"structured_response\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "22b26e06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "Analyze this review: 'Great product: 5 out of 5 stars. Fast shipping, but expensive'\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  ProductReview (dr37ceyvg)\n",
      " Call ID: dr37ceyvg\n",
      "  Args:\n",
      "    key_points: ['fast shipping', 'expensive']\n",
      "    rating: 5\n",
      "    sentiment: positive\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: ProductReview\n",
      "\n",
      "Action item captured and sentiment updated!\n"
     ]
    }
   ],
   "source": [
    "agent = create_agent(\n",
    "    llm,\n",
    "    response_format=ToolStrategy(schema=ProductReview, tool_message_content=\"Action item captured and sentiment updated!\"),\n",
    ")   \n",
    "\n",
    "result = agent.invoke({\n",
    "    \"messages\": [{\"role\": \"user\", \"content\": \"Analyze this review: 'Great product: 5 out of 5 stars. Fast shipping, but expensive'\"}]\n",
    "})\n",
    "for msg in result[\"messages\"]:\n",
    "   msg.pretty_print()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79408f5a",
   "metadata": {},
   "source": [
    "\n",
    "### Multiple schema outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "1a946db5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ContactInfo(name='John Doe', email='john@email.com')"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pydantic import BaseModel, Field\n",
    "from typing import Union\n",
    "from langchain.agents import create_agent\n",
    "from langchain.agents.structured_output import ToolStrategy\n",
    "\n",
    "\n",
    "class ContactInfo(BaseModel):\n",
    "    name: str = Field(description=\"Person's name\")\n",
    "    email: str = Field(description=\"Email address\")\n",
    "\n",
    "class EventDetails(BaseModel):\n",
    "    \"\"\"Details of an event.\"\"\"\n",
    "    event_name: str = Field(description=\"Name of the event\")\n",
    "    date: str = Field(description=\"Event date\")\n",
    "\n",
    "agent = create_agent(\n",
    "    llm,\n",
    "    response_format=ToolStrategy(Union[ContactInfo, EventDetails])  # Default: handle_errors=True\n",
    ")\n",
    "\n",
    "result = agent.invoke({\n",
    "    \"messages\": [{\"role\": \"user\", \"content\": \"Extract info: John Doe (john@email.com) is organizing Tech Conference on March 15th\"}]\n",
    "})\n",
    "result[\"structured_response\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfebf847",
   "metadata": {},
   "source": [
    "### Error handling\n",
    "Models can make mistakes when generating structured output via tool calling. LangChain provides intelligent retry mechanisms to handle these errors automatically.\n",
    "\n",
    "- When structured output doesn’t match the expected schema, the agent provides specific error feedback\n",
    "- You can customize how errors are handled using the `handle_errors` parameter.\n",
    "- If `handle_errors` is a string, the agent will always prompt the model to re-try with a fixed tool message.\n",
    "- We can have a Custom error handler function as well in `handle_errors`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c2ab220",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
