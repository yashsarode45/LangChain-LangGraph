{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Orchestrator-Worker Pattern\n",
    "\n",
    "The orchestrator-worker pattern is ideal for complex tasks where subtasks cannot be predetermined. A central orchestrator LLM dynamically breaks down work, delegates to specialized worker LLMs, and synthesizes results.\n",
    "\n",
    "**Key characteristics:**\n",
    "- Dynamic task decomposition based on input\n",
    "- Parallel execution of workers\n",
    "- Centralized result synthesis\n",
    "\n",
    "**When to use:** Tasks requiring flexible, input-dependent planning (e.g., code generation across multiple files, complex research reports)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Environment setup\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "os.environ[\"GROQ_API_KEY\"] = os.getenv(\"GROQ_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yashsarode/Downloads/Personal Projects/Python/LangGraph-personal/.venv/lib/python3.13/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "/var/folders/_v/fs86q2353gvdsjh19x_1fpdm0000gn/T/ipykernel_49393/4292334374.py:10: LangGraphDeprecatedSinceV10: Importing Send from langgraph.constants is deprecated. Please use 'from langgraph.types import Send' instead. Deprecated in LangGraph V1.0 to be removed in V2.0.\n",
      "  from langgraph.constants import Send\n"
     ]
    }
   ],
   "source": [
    "# Core imports for orchestrator-worker pattern\n",
    "from typing import Annotated, List\n",
    "import operator\n",
    "from typing_extensions import TypedDict\n",
    "from pydantic import BaseModel, Field\n",
    "\n",
    "from langchain_groq import ChatGroq\n",
    "from langchain_core.messages import HumanMessage, SystemMessage\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "from langgraph.constants import Send"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello. How can I assist you today?\n"
     ]
    }
   ],
   "source": [
    "# Initialize LLM using Groq\n",
    "llm = ChatGroq(model=\"llama-3.3-70b-versatile\")\n",
    "\n",
    "# Quick test\n",
    "result = llm.invoke(\"Hello\")\n",
    "print(result.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining Structured Output Schema\n",
    "\n",
    "The orchestrator needs structured output to plan work distribution. We use Pydantic models to define task sections that workers will handle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Schema for orchestrator's planning output\n",
    "class Task(BaseModel):\n",
    "    name: str = Field(description=\"Name of the task\")\n",
    "    instructions: str = Field(description=\"Detailed instructions for completing this task\")\n",
    "\n",
    "class TaskPlan(BaseModel):\n",
    "    tasks: List[Task] = Field(description=\"List of tasks to be completed\")\n",
    "\n",
    "# Create planner with structured output\n",
    "planner = llm.with_structured_output(TaskPlan)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### State Management\n",
    "\n",
    "LangGraph v1.x uses TypedDict for state management. The orchestrator state holds the overall workflow, while worker state is isolated for each parallel execution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Main workflow state\n",
    "class OrchestratorState(TypedDict):\n",
    "    user_request: str\n",
    "    task_plan: List[Task]\n",
    "    completed_tasks: Annotated[list, operator.add]  # Workers append results here\n",
    "    final_output: str\n",
    "\n",
    "# Individual worker state\n",
    "class WorkerState(TypedDict):\n",
    "    task: Task\n",
    "    completed_tasks: Annotated[list, operator.add]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Node Implementations\n",
    "\n",
    "Three core nodes: orchestrator (plans), worker (executes), and synthesizer (combines results)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def orchestrator_node(state: OrchestratorState):\n",
    "    \"\"\"Breaks down the user request into discrete tasks\"\"\"\n",
    "    \n",
    "    task_plan = planner.invoke([\n",
    "        SystemMessage(content=\"You are a task planning expert. Break down complex requests into clear, actionable tasks.\"),\n",
    "        HumanMessage(content=f\"User request: {state['user_request']}\")\n",
    "    ])\n",
    "    \n",
    "    print(f\"\\nOrchestrator created {len(task_plan.tasks)} tasks\")\n",
    "    return {\"task_plan\": task_plan.tasks}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def worker_node(state: WorkerState):\n",
    "    \"\"\"Individual worker executes assigned task\"\"\"\n",
    "    \n",
    "    result = llm.invoke([\n",
    "        SystemMessage(content=\"You are a specialized worker. Complete the assigned task thoroughly and concisely.\"),\n",
    "        HumanMessage(content=f\"Task: {state['task'].name}\\n\\nInstructions: {state['task'].instructions}\")\n",
    "    ])\n",
    "    \n",
    "    return {\"completed_tasks\": [f\"## {state['task'].name}\\n\\n{result.content}\"]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def synthesizer_node(state: OrchestratorState):\n",
    "    \"\"\"Combines all worker outputs into final deliverable\"\"\"\n",
    "    \n",
    "    combined_results = \"\\n\\n---\\n\\n\".join(state[\"completed_tasks\"])\n",
    "    \n",
    "    return {\"final_output\": combined_results}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dynamic Worker Assignment with Send API\n",
    "\n",
    "The Send API enables dynamic creation of worker nodes. Each worker gets its own isolated state while all write to a shared output channel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def assign_workers(state: OrchestratorState):\n",
    "    \"\"\"Dynamically spawn workers for each task\"\"\"\n",
    "    \n",
    "    # Send creates parallel worker executions\n",
    "    return [Send(\"worker\", {\"task\": task}) for task in state[\"task_plan\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Graph Construction\n",
    "\n",
    "Build the workflow graph with proper node connections and conditional routing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize graph builder\n",
    "workflow = StateGraph(OrchestratorState)\n",
    "\n",
    "# Register nodes\n",
    "workflow.add_node(\"orchestrator\", orchestrator_node)\n",
    "workflow.add_node(\"worker\", worker_node)\n",
    "workflow.add_node(\"synthesizer\", synthesizer_node)\n",
    "\n",
    "# Define workflow edges\n",
    "workflow.add_edge(START, \"orchestrator\")\n",
    "workflow.add_conditional_edges(\n",
    "    \"orchestrator\",\n",
    "    assign_workers,\n",
    "    [\"worker\"]\n",
    ")\n",
    "workflow.add_edge(\"worker\", \"synthesizer\")\n",
    "workflow.add_edge(\"synthesizer\", END)\n",
    "\n",
    "# Compile the graph\n",
    "app = workflow.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Visualize the workflow\n",
    "from IPython.display import Image, display\n",
    "\n",
    "display(Image(app.get_graph().draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example Execution\n",
    "\n",
    "Run the orchestrator-worker workflow with a sample request."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Orchestrator created 8 tasks\n",
      "\n",
      "================================================================================\n",
      "FINAL OUTPUT\n",
      "================================================================================\n",
      "\n",
      "## Research RAG Systems\n",
      "\n",
      "**RAG Systems Research Report**\n",
      "\n",
      "**Introduction**\n",
      "\n",
      "RAG (Retrieve, Augment, Generate) systems are a type of artificial intelligence (AI) architecture that combines natural language processing (NLP) and information retrieval techniques. These systems aim to improve the performance of language models by leveraging external knowledge sources and generating more accurate and informative responses.\n",
      "\n",
      "**Components of RAG Systems**\n",
      "\n",
      "A RAG system consists of three primary components:\n",
      "\n",
      "1. **Retrieve**: This module is responsible for retrieving relevant information from external knowledge sources, such as databases, knowledge graphs, or text corpora. The retrieve module uses various techniques, including keyword search, entity recognition, and semantic search, to identify relevant information.\n",
      "2. **Augment**: The augment module takes the retrieved information and augments it with additional context, such as entity relationships, semantic roles, or coreference information. This module helps to disambiguate entities, resolve pronouns, and improve the overall understanding of the input text.\n",
      "3. **Generate**: The generate module uses the augmented information to generate a response. This module employs various NLP techniques, including language generation, text summarization, and question answering, to produce a response that is relevant, accurate, and engaging.\n",
      "\n",
      "**Applications of RAG Systems**\n",
      "\n",
      "RAG systems have a wide range of applications in AI and NLP, including:\n",
      "\n",
      "1. **Question Answering**: RAG systems can be used to answer complex questions that require external knowledge and reasoning.\n",
      "2. **Text Summarization**: RAG systems can generate concise and informative summaries of long documents or texts.\n",
      "3. **Language Translation**: RAG systems can improve language translation by leveraging external knowledge sources and generating more accurate and context-dependent translations.\n",
      "4. **Chatbots and Virtual Assistants**: RAG systems can be used to power chatbots and virtual assistants, enabling them to provide more accurate and informative responses to user queries.\n",
      "5. **Content Generation**: RAG systems can generate high-quality content, such as articles, blogs, and social media posts, by leveraging external knowledge sources and generating engaging and informative text.\n",
      "\n",
      "**Benefits of RAG Systems**\n",
      "\n",
      "RAG systems offer several benefits, including:\n",
      "\n",
      "1. **Improved Accuracy**: RAG systems can improve the accuracy of language models by leveraging external knowledge sources and generating more accurate responses.\n",
      "2. **Increased Contextual Understanding**: RAG systems can improve the contextual understanding of input text by augmenting it with additional context and generating more informative responses.\n",
      "3. **Enhanced Engagement**: RAG systems can generate more engaging and informative responses, leading to improved user experience and increased user satisfaction.\n",
      "\n",
      "**Challenges and Limitations**\n",
      "\n",
      "RAG systems also face several challenges and limitations, including:\n",
      "\n",
      "1. **Knowledge Graph Construction**: Constructing and maintaining large-scale knowledge graphs can be a challenging and time-consuming task.\n",
      "2. **Entity Disambiguation**: Entity disambiguation can be a challenging task, especially in cases where entities have similar names or contexts.\n",
      "3. **Contextual Understanding**: RAG systems require a deep understanding of context, which can be difficult to achieve, especially in cases where the input text is ambiguous or unclear.\n",
      "\n",
      "**Conclusion**\n",
      "\n",
      "RAG systems are a powerful AI architecture that combines NLP and information retrieval techniques to improve the performance of language models. These systems have a wide range of applications in AI and NLP, including question answering, text summarization, language translation, chatbots, and content generation. While RAG systems offer several benefits, including improved accuracy and increased contextual understanding, they also face several challenges and limitations, including knowledge graph construction, entity disambiguation, and contextual understanding. Further research and development are needed to overcome these challenges and fully realize the potential of RAG systems.\n",
      "\n",
      "---\n",
      "\n",
      "## Investigate LangChain\n",
      "\n",
      "**Introduction to LangChain**\n",
      "LangChain is an open-source framework designed for building AI applications, with a focus on natural language processing (NLP) and large language models (LLMs). It provides a set of tools and libraries to simplify the development of AI-powered applications, including those that utilize Retrieval-Augmented Generation (RAG) systems.\n",
      "\n",
      "**Key Features of LangChain**\n",
      "\n",
      "1. **Modular Architecture**: LangChain has a modular design, allowing developers to easily integrate different components, such as language models, retrieval systems, and generation algorithms.\n",
      "2. **Support for Multiple LLMs**: LangChain supports a range of LLMs, including popular models like BERT, RoBERTa, and T5, making it easy to experiment with different models and architectures.\n",
      "3. **RAG System Implementation**: LangChain provides a built-in implementation of RAG systems, which enables the integration of retrieval and generation components to improve the performance of AI models.\n",
      "4. **Flexible Retrieval Systems**: LangChain allows developers to use various retrieval systems, such as FAISS, Hugging Face's Transformers, and PyTorch, to fetch relevant information from external knowledge sources.\n",
      "5. **Extensive Community Support**: LangChain has an active community of developers and researchers, ensuring that the framework stays up-to-date with the latest advancements in AI and NLP.\n",
      "\n",
      "**Capabilities for Implementing RAG Systems**\n",
      "\n",
      "1. **Retrieval-Augmented Generation**: LangChain's RAG system implementation enables the integration of retrieval and generation components to generate more accurate and informative responses.\n",
      "2. **Knowledge Graph Integration**: LangChain allows developers to integrate knowledge graphs, such as Wikipedia or ConceptNet, to provide additional context and information for the AI model.\n",
      "3. **Customizable Retrieval Systems**: LangChain's flexible retrieval systems enable developers to customize the retrieval process to suit specific use cases and applications.\n",
      "4. **Support for Multi-Task Learning**: LangChain supports multi-task learning, which enables the AI model to learn multiple tasks simultaneously, improving its overall performance and adaptability.\n",
      "\n",
      "**Advantages and Use Cases**\n",
      "\n",
      "1. **Improved Performance**: LangChain's RAG system implementation can significantly improve the performance of AI models, especially in tasks that require generating text based on external knowledge.\n",
      "2. **Increased Efficiency**: LangChain's modular architecture and pre-built components reduce the development time and effort required to build AI applications.\n",
      "3. **Flexibility and Customizability**: LangChain's flexible retrieval systems and customizable components make it an ideal choice for a wide range of applications, including chatbots, question-answering systems, and text summarization tools.\n",
      "\n",
      "**Conclusion**\n",
      "LangChain is a powerful framework for building AI applications, with a strong focus on NLP and LLMs. Its capabilities for implementing RAG systems make it an attractive choice for developers and researchers looking to build AI models that can generate accurate and informative responses. With its modular architecture, flexible retrieval systems, and extensive community support, LangChain is well-suited for a wide range of applications and use cases.\n",
      "\n",
      "---\n",
      "\n",
      "## Plan Guide Outline\n",
      "\n",
      "Here is a comprehensive outline for the technical guide:\n",
      "\n",
      "**I. Introduction to RAG Systems**\n",
      "\n",
      "* Definition and explanation of RAG (Retrieval, Augmentation, and Generation) systems\n",
      "* Importance of RAG systems in AI and natural language processing\n",
      "* Brief overview of the benefits and applications of RAG systems\n",
      "\n",
      "**II. LangChain Overview**\n",
      "\n",
      "* Introduction to LangChain and its role in RAG systems\n",
      "* Explanation of LangChain's architecture and components\n",
      "* Discussion of LangChain's features and capabilities\n",
      "\n",
      "**III. Implementation Steps**\n",
      "\n",
      "* Step 1: Setting up the environment and installing required dependencies\n",
      "* Step 2: Configuring LangChain and integrating with RAG system components\n",
      "* Step 3: Implementing retrieval, augmentation, and generation modules\n",
      "* Step 4: Testing and validating the RAG system\n",
      "* Step 5: Deploying and maintaining the RAG system\n",
      "\n",
      "**IV. Troubleshooting**\n",
      "\n",
      "* Common issues and errors in RAG system implementation\n",
      "* Debugging techniques and tools for identifying and resolving problems\n",
      "* Best practices for optimizing RAG system performance and reliability\n",
      "* Resources for further support and troubleshooting\n",
      "\n",
      "**V. Conclusion**\n",
      "\n",
      "* Recap of key takeaways and importance of RAG systems\n",
      "* Future directions and potential applications of RAG systems\n",
      "* Final thoughts and recommendations for implementing and maintaining RAG systems using LangChain.\n",
      "\n",
      "This outline provides a clear structure for the technical guide, covering the essential topics and implementation steps for RAG systems using LangChain.\n",
      "\n",
      "---\n",
      "\n",
      "## Write Introduction\n",
      "\n",
      "**Introduction to RAG Systems: Revolutionizing AI and Natural Language Processing**\n",
      "\n",
      "The advent of Artificial Intelligence (AI) and Natural Language Processing (NLP) has transformed the way we interact with machines, enabling humans to communicate more effectively and efficiently. One key technology that has gained significant attention in recent years is the Retrieval-Augmented Generator (RAG) system. RAG systems represent a paradigm shift in the field of AI and NLP, offering a powerful framework for generating human-like text, answering complex questions, and completing tasks that require a deep understanding of language and context.\n",
      "\n",
      "RAG systems combine the strengths of retrieval-based and generation-based approaches, leveraging large databases of knowledge to inform and augment the text generation process. By integrating retrieval and generation capabilities, RAG systems can produce more accurate, informative, and engaging text, while also reducing the need for explicit programming and rule-based systems. The benefits of RAG systems are multifaceted, including improved performance, increased efficiency, and enhanced user experience.\n",
      "\n",
      "The relevance of RAG systems to AI and NLP is profound, as they have the potential to revolutionize a wide range of applications, from chatbots and virtual assistants to language translation and text summarization. By harnessing the power of RAG systems, developers can create more sophisticated and human-like AI models that can understand, generate, and interact with natural language in a more effective and intuitive way. As the field of AI and NLP continues to evolve, RAG systems are poised to play a critical role in shaping the future of human-computer interaction, enabling machines to better understand and respond to human needs, and transforming the way we live, work, and communicate.\n",
      "\n",
      "---\n",
      "\n",
      "## Document LangChain Setup\n",
      "\n",
      "**LangChain Setup Documentation**\n",
      "=====================================\n",
      "\n",
      "### Introduction\n",
      "\n",
      "LangChain is a framework for building applications that leverage large language models. This document provides a step-by-step guide on setting up LangChain and preparing the environment for RAG (Retrieval-Augmented Generator) system implementation.\n",
      "\n",
      "### Prerequisites\n",
      "\n",
      "* Python 3.8 or later\n",
      "* pip 20.0 or later\n",
      "* A compatible operating system (Windows, macOS, or Linux)\n",
      "* A code editor or IDE (Integrated Development Environment)\n",
      "\n",
      "### Step 1: Install Required Libraries and Dependencies\n",
      "\n",
      "1. **Install Python**: Ensure Python 3.8 or later is installed on your system. You can download the latest version from the official Python website.\n",
      "2. **Install pip**: pip is the package installer for Python. If you have Python installed, you likely have pip as well. You can check by running `pip --version` in your terminal.\n",
      "3. **Install LangChain**: Run the following command in your terminal to install LangChain: `pip install langchain`\n",
      "4. **Install additional dependencies**: Depending on your specific use case, you may need to install additional libraries such as `transformers`, `torch`, or `numpy`. You can install them using pip: `pip install transformers torch numpy`\n",
      "\n",
      "### Step 2: Set Up the Environment\n",
      "\n",
      "1. **Create a new Python environment**: It's a good practice to create a separate environment for your project to avoid version conflicts. You can create a new environment using `python -m venv myenv` (replace \"myenv\" with your desired environment name).\n",
      "2. **Activate the environment**: Activate the environment using `myenv\\Scripts\\activate` (on Windows) or `source myenv/bin/activate` (on macOS or Linux).\n",
      "3. **Verify the environment**: Verify that the environment is activated by checking the command prompt or terminal. It should indicate the environment name.\n",
      "\n",
      "### Step 3: Configure LangChain\n",
      "\n",
      "1. **Import LangChain**: In your Python script or code editor, import LangChain using `import langchain`\n",
      "2. **Configure the LangChain client**: Create a LangChain client instance by calling `langchain.Client()` and passing in your API key or other required configuration options.\n",
      "3. **Test the client**: Test the client by calling a simple function, such as `client.get_model()` to retrieve a list of available models.\n",
      "\n",
      "### Step 4: Prepare the Environment for RAG Implementation\n",
      "\n",
      "1. **Install RAG-specific dependencies**: Depending on your specific RAG implementation, you may need to install additional libraries such as `faiss` or `scipy`. You can install them using pip: `pip install faiss scipy`\n",
      "2. **Prepare the data**: Prepare the data required for RAG implementation, such as a dataset of text documents or a knowledge graph.\n",
      "3. **Configure the RAG model**: Configure the RAG model by specifying the model architecture, hyperparameters, and other required settings.\n",
      "\n",
      "### Example Code\n",
      "\n",
      "Here's an example code snippet to get you started:\n",
      "```python\n",
      "import langchain\n",
      "\n",
      "# Create a LangChain client instance\n",
      "client = langchain.Client(api_key=\"YOUR_API_KEY\")\n",
      "\n",
      "# Retrieve a list of available models\n",
      "models = client.get_model()\n",
      "\n",
      "# Print the list of models\n",
      "print(models)\n",
      "```\n",
      "Replace \"YOUR_API_KEY\" with your actual API key or other required configuration options.\n",
      "\n",
      "### Conclusion\n",
      "\n",
      "By following these step-by-step instructions, you have successfully set up LangChain and prepared the environment for RAG system implementation. You can now proceed with implementing your RAG model and integrating it with LangChain.\n",
      "\n",
      "---\n",
      "\n",
      "## Implement RAG System\n",
      "\n",
      "Implementing a RAG (Retrieve, Augment, Generate) System using LangChain\n",
      "====================================================================\n",
      "\n",
      "Table of Contents\n",
      "-----------------\n",
      "\n",
      "1. [Introduction](#introduction)\n",
      "2. [Prerequisites](#prerequisites)\n",
      "3. [Step 1: Set up LangChain](#step-1-set-up-langchain)\n",
      "4. [Step 2: Define the RAG Pipeline](#step-2-define-the-rag-pipeline)\n",
      "5. [Step 3: Implement Data Retrieval](#step-3-implement-data-retrieval)\n",
      "6. [Step 4: Implement Data Augmentation](#step-4-implement-data-augmentation)\n",
      "7. [Step 5: Implement Text Generation](#step-5-implement-text-generation)\n",
      "8. [Example Use Case](#example-use-case)\n",
      "\n",
      "### Introduction\n",
      "\n",
      "A RAG system is a powerful tool for natural language processing tasks, combining the strengths of retrieval, augmentation, and generation. LangChain is a popular framework for building RAG systems. This guide provides step-by-step instructions on implementing a RAG system using LangChain.\n",
      "\n",
      "### Prerequisites\n",
      "\n",
      "* Python 3.8 or later\n",
      "* LangChain library installed (`pip install langchain`)\n",
      "* A dataset for training and testing the RAG system\n",
      "\n",
      "### Step 1: Set up LangChain\n",
      "\n",
      "To set up LangChain, follow these steps:\n",
      "\n",
      "1. Import the necessary libraries: `import langchain`\n",
      "2. Initialize the LangChain pipeline: `pipeline = langchain.Pipeline()`\n",
      "\n",
      "### Step 2: Define the RAG Pipeline\n",
      "\n",
      "Define the RAG pipeline by specifying the retrieval, augmentation, and generation components:\n",
      "\n",
      "1. Retrieval: `retriever = langchain.Retriever()`\n",
      "2. Augmentation: `augmenter = langchain.Augmenter()`\n",
      "3. Generation: `generator = langchain.Generator()`\n",
      "\n",
      "### Step 3: Implement Data Retrieval\n",
      "\n",
      "Implement data retrieval using the `Retriever` component:\n",
      "\n",
      "1. Define a retrieval function: `def retrieve_data(query):`\n",
      "\t* Use a database or API to retrieve relevant data\n",
      "\t* Return a list of retrieved data points\n",
      "2. Integrate the retrieval function with the `Retriever` component: `retriever = langchain.Retriever(retrieve_data)`\n",
      "\n",
      "Example code:\n",
      "```python\n",
      "import langchain\n",
      "\n",
      "def retrieve_data(query):\n",
      "    # Simulate data retrieval from a database\n",
      "    data = [\n",
      "        {\"id\": 1, \"text\": \"This is a sample text.\"},\n",
      "        {\"id\": 2, \"text\": \"Another sample text.\"},\n",
      "    ]\n",
      "    return data\n",
      "\n",
      "retriever = langchain.Retriever(retrieve_data)\n",
      "```\n",
      "\n",
      "### Step 4: Implement Data Augmentation\n",
      "\n",
      "Implement data augmentation using the `Augmenter` component:\n",
      "\n",
      "1. Define an augmentation function: `def augment_data(data):`\n",
      "\t* Use techniques such as paraphrasing, entity replacement, or text noising\n",
      "\t* Return a list of augmented data points\n",
      "2. Integrate the augmentation function with the `Augmenter` component: `augmenter = langchain.Augmenter(augment_data)`\n",
      "\n",
      "Example code:\n",
      "```python\n",
      "import langchain\n",
      "\n",
      "def augment_data(data):\n",
      "    # Simulate data augmentation using paraphrasing\n",
      "    augmented_data = []\n",
      "    for point in data:\n",
      "        paraphrased_text = point[\"text\"].replace(\"sample\", \"example\")\n",
      "        augmented_data.append({\"id\": point[\"id\"], \"text\": paraphrased_text})\n",
      "    return augmented_data\n",
      "\n",
      "augmenter = langchain.Augmenter(augment_data)\n",
      "```\n",
      "\n",
      "### Step 5: Implement Text Generation\n",
      "\n",
      "Implement text generation using the `Generator` component:\n",
      "\n",
      "1. Define a generation function: `def generate_text(prompt):`\n",
      "\t* Use a language model or other generation technique\n",
      "\t* Return a generated text\n",
      "2. Integrate the generation function with the `Generator` component: `generator = langchain.Generator(generate_text)`\n",
      "\n",
      "Example code:\n",
      "```python\n",
      "import langchain\n",
      "\n",
      "def generate_text(prompt):\n",
      "    # Simulate text generation using a language model\n",
      "    generated_text = \"This is a generated text based on the prompt.\"\n",
      "    return generated_text\n",
      "\n",
      "generator = langchain.Generator(generate_text)\n",
      "```\n",
      "\n",
      "### Example Use Case\n",
      "\n",
      "Use the implemented RAG system to generate text based on a user input:\n",
      "\n",
      "1. Retrieve relevant data using the `Retriever` component: `data = retriever.retrieve(\"user input\")`\n",
      "2. Augment the retrieved data using the `Augmenter` component: `augmented_data = augmenter.augment(data)`\n",
      "3. Generate text using the `Generator` component: `generated_text = generator.generate(augmented_data)`\n",
      "\n",
      "Example code:\n",
      "```python\n",
      "user_input = \"Generate text about AI\"\n",
      "data = retriever.retrieve(user_input)\n",
      "augmented_data = augmenter.augment(data)\n",
      "generated_text = generator.generate(augmented_data)\n",
      "print(generated_text)\n",
      "```\n",
      "\n",
      "This guide provides a step-by-step approach to implementing a RAG system using LangChain. By following these instructions, you can build a powerful tool for natural language processing tasks.\n",
      "\n",
      "---\n",
      "\n",
      "## Test and Troubleshoot\n",
      "\n",
      "**Testing and Troubleshooting the RAG System**\n",
      "\n",
      "The RAG (Red, Amber, Green) system is a status indicator used to track progress, risks, and performance. To ensure its effective implementation, thorough testing and troubleshooting are crucial. Here's a step-by-step guide to help you test and troubleshoot the RAG system:\n",
      "\n",
      "**Testing the RAG System**\n",
      "\n",
      "1. **Initial Setup**: Verify that the RAG system is properly configured, and all necessary data sources are connected.\n",
      "2. **Data Validation**: Test the system with sample data to ensure that it correctly assigns RAG statuses based on predefined criteria.\n",
      "3. **User Access**: Confirm that authorized users can access the system and view RAG statuses.\n",
      "4. **Automated Updates**: Verify that the system updates RAG statuses automatically based on changes in underlying data.\n",
      "5. **Alerts and Notifications**: Test that the system sends alerts and notifications to designated users when RAG statuses change.\n",
      "\n",
      "**Common Issues and Solutions**\n",
      "\n",
      "1. **Incorrect RAG Statuses**:\n",
      "\t* Cause: Incorrect configuration or outdated data.\n",
      "\t* Solution: Review and update the system configuration, and ensure that data sources are current.\n",
      "2. **Failed Automated Updates**:\n",
      "\t* Cause: Technical issues or connectivity problems.\n",
      "\t* Solution: Check system logs, verify data source connections, and restart the update process.\n",
      "3. **User Access Issues**:\n",
      "\t* Cause: Insufficient permissions or incorrect user roles.\n",
      "\t* Solution: Review user roles and permissions, and update as necessary.\n",
      "4. **Alerts and Notifications Not Sending**:\n",
      "\t* Cause: Incorrect notification settings or technical issues.\n",
      "\t* Solution: Verify notification settings, check system logs, and test the notification process.\n",
      "5. **Data Discrepancies**:\n",
      "\t* Cause: Inconsistent or outdated data.\n",
      "\t* Solution: Identify and correct the data discrepancy, and update the system accordingly.\n",
      "\n",
      "**Troubleshooting Tips**\n",
      "\n",
      "1. **Check System Logs**: Review system logs to identify errors and exceptions.\n",
      "2. **Verify Data Sources**: Confirm that data sources are current and accurate.\n",
      "3. **Test with Sample Data**: Use sample data to test the system and identify issues.\n",
      "4. **Collaborate with Users**: Work with users to identify and resolve issues.\n",
      "5. **Document Issues and Solutions**: Keep a record of issues and solutions to improve the system and prevent future problems.\n",
      "\n",
      "By following these testing and troubleshooting guidelines, you can ensure that the RAG system is functioning correctly and provide a solid foundation for effective monitoring and decision-making.\n",
      "\n",
      "---\n",
      "\n",
      "## Finalize Guide\n",
      "\n",
      "**Finalized Technical Guide**\n",
      "\n",
      "After conducting a thorough review, edit, and revision process, I am pleased to present the finalized technical guide. The guide has been refined to ensure clarity, coherence, and completeness, providing accurate and concise information to its intended audience.\n",
      "\n",
      "**Guide Overview**\n",
      "\n",
      "The technical guide is a comprehensive resource that covers [briefly mention the main topics or subjects covered in the guide]. It is designed to provide [ specify the purpose of the guide, e.g., troubleshooting, installation, or maintenance instructions].\n",
      "\n",
      "**Key Revisions and Updates**\n",
      "\n",
      "The following revisions and updates have been made to the guide:\n",
      "\n",
      "1. **Reorganized content**: The guide's structure has been revised to improve navigation and flow, making it easier for readers to find relevant information.\n",
      "2. **Clarified terminology**: Technical terms and jargon have been defined or replaced with more accessible language to enhance understanding.\n",
      "3. **Updated illustrations and diagrams**: Visual aids have been added or revised to better illustrate complex concepts and procedures.\n",
      "4. **New sections and topics**: Additional sections have been included to address [mention specific areas or topics that were previously missing or underrepresented].\n",
      "5. **Error corrections**: Errors in formatting, grammar, and punctuation have been corrected to ensure a polished and professional presentation.\n",
      "\n",
      "**Guide Structure**\n",
      "\n",
      "The finalized guide consists of [number] sections, including:\n",
      "\n",
      "1. **Introduction**: Provides an overview of the guide's purpose, scope, and intended audience.\n",
      "2. **[Section 1: Topic]**: Covers [briefly describe the topic and its relevance to the guide].\n",
      "3. **[Section 2: Topic]**: Covers [briefly describe the topic and its relevance to the guide].\n",
      "4. **[Section 3: Topic]**: Covers [briefly describe the topic and its relevance to the guide].\n",
      "5. **Conclusion**: Summarizes key takeaways and provides additional resources for further learning.\n",
      "\n",
      "**Quality Assurance**\n",
      "\n",
      "To ensure the guide's accuracy and completeness, it has undergone a rigorous review process, including:\n",
      "\n",
      "1. **Technical review**: The guide has been reviewed by subject matter experts to verify the accuracy and relevance of the content.\n",
      "2. **Peer review**: The guide has been reviewed by peers to identify areas for improvement and provide feedback on clarity and coherence.\n",
      "3. **Editing and proofreading**: The guide has been thoroughly edited and proofread to eliminate errors and ensure a polished presentation.\n",
      "\n",
      "**Finalized Guide Availability**\n",
      "\n",
      "The finalized technical guide is now available in [specify the format, e.g., PDF, HTML, or print]. It can be accessed [provide information on how to obtain the guide, e.g., download link or request process].\n",
      "\n",
      "By finalizing this technical guide, we aim to provide a valuable resource that meets the needs of its intended audience, ensuring they have the necessary information to [specify the guide's purpose or objective].\n"
     ]
    }
   ],
   "source": [
    "# Execute workflow\n",
    "result = app.invoke({\n",
    "    \"user_request\": \"Create a technical guide on implementing RAG systems with LangChain\"\n",
    "})\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"FINAL OUTPUT\")\n",
    "print(\"=\"*80 + \"\\n\")\n",
    "print(result[\"final_output\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Key Takeaways\n",
    "\n",
    "**Orchestrator-Worker Pattern Advantages:**\n",
    "- Dynamic task decomposition adapts to input complexity\n",
    "- Parallel worker execution improves performance\n",
    "- Modular design allows specialized workers\n",
    "\n",
    "**LangGraph v1.x Features Used:**\n",
    "- `Send` API for dynamic parallel node creation\n",
    "- `Annotated[list, operator.add]` for shared state accumulation\n",
    "- Conditional edges for flexible routing\n",
    "- Structured output with `with_structured_output()`\n",
    "\n",
    "**Production Considerations:**\n",
    "- Add error handling for worker failures\n",
    "- Implement retry logic for robustness\n",
    "- Consider rate limiting for parallel workers\n",
    "- Monitor token usage across workers"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
