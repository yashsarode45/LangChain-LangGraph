{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Adaptive RAG\n",
        "\n",
        "Adaptive RAG dynamically chooses retrieval strategies based on query complexity. Unlike traditional RAG which always follows the same path, Adaptive RAG:\n",
        "- Routes queries to appropriate data sources (vectorstore vs web search)\n",
        "- Grades retrieved documents for relevance\n",
        "- Transforms queries when initial retrieval fails\n",
        "- Validates generated answers for hallucinations\n",
        "- Loops back for refinement when needed\n",
        "\n",
        "This implementation uses LangGraph v1.x with StateGraph, conditional edges, and structured outputs."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Setup Environment and LLM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "from dotenv import load_dotenv\n",
        "\n",
        "load_dotenv()\n",
        "os.environ[\"GROQ_API_KEY\"] = os.getenv(\"GROQ_API_KEY\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/yashsarode/Downloads/Personal Projects/Python/LangChain-LangGraph/.venv/lib/python3.13/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from .autonotebook import tqdm as notebook_tqdm\n"
          ]
        }
      ],
      "source": [
        "from langchain_groq import ChatGroq\n",
        "\n",
        "# Using Groq's llama-3.3-70b model for all LLM operations\n",
        "llm = ChatGroq(model=\"llama-3.3-70b-versatile\", temperature=0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Build Vector Store with Wikipedia Documents\n",
        "\n",
        "Load real documents from Wikipedia and create a vector store with ChromaDB. We'll use content about AI agents for our knowledge base."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loaded 6 documents\n"
          ]
        }
      ],
      "source": [
        "from langchain_community.document_loaders import WikipediaLoader\n",
        "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
        "from langchain_huggingface import HuggingFaceEmbeddings\n",
        "from langchain_chroma import Chroma\n",
        "\n",
        "# Load Wikipedia articles about AI agents and related topics\n",
        "topics = [\"Artificial intelligence\", \"Machine learning\", \"Natural language processing\"]\n",
        "documents = []\n",
        "\n",
        "for topic in topics:\n",
        "    loader = WikipediaLoader(query=topic, load_max_docs=2)\n",
        "    documents.extend(loader.load())\n",
        "\n",
        "print(f\"Loaded {len(documents)} documents\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Split into 38 chunks\n"
          ]
        }
      ],
      "source": [
        "# Split documents into manageable chunks for better retrieval\n",
        "text_splitter = RecursiveCharacterTextSplitter(\n",
        "    chunk_size=1000,\n",
        "    chunk_overlap=200\n",
        ")\n",
        "doc_splits = text_splitter.split_documents(documents)\n",
        "print(f\"Split into {len(doc_splits)} chunks\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create embeddings using HuggingFace's sentence transformer\n",
        "# This model provides quality embeddings without requiring API calls\n",
        "embeddings = HuggingFaceEmbeddings(\n",
        "    model_name=\"sentence-transformers/all-mpnet-base-v2\",\n",
        "    model_kwargs={\"device\": \"cpu\"},\n",
        "    encode_kwargs={\"normalize_embeddings\": True}\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Vector store created and documents indexed\n"
          ]
        }
      ],
      "source": [
        "# Create vector store with ChromaDB persisted locally\n",
        "vectorstore = Chroma(\n",
        "    collection_name=\"adaptive_rag\",\n",
        "    embedding_function=embeddings,\n",
        "    persist_directory=\"./chroma_adaptive_rag\"\n",
        ")\n",
        "\n",
        "# Add documents to the vector store\n",
        "vectorstore.add_documents(doc_splits)\n",
        "retriever = vectorstore.as_retriever(search_kwargs={\"k\": 3})\n",
        "\n",
        "print(\"Vector store created and documents indexed\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Define State Schema\n",
        "\n",
        "State holds all data that flows through the graph. Using TypedDict provides type safety and clear documentation of data structure."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [],
      "source": [
        "from typing import List\n",
        "from typing_extensions import TypedDict\n",
        "from langchain_core.documents import Document\n",
        "\n",
        "class GraphState(TypedDict):\n",
        "    \"\"\"State schema for Adaptive RAG workflow.\n",
        "    \n",
        "    Attributes:\n",
        "        question: User's original query\n",
        "        generation: Final answer generated by LLM\n",
        "        documents: Retrieved documents used as context\n",
        "    \"\"\"\n",
        "    question: str\n",
        "    generation: str\n",
        "    documents: List[Document]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Define Structured Output Schemas\n",
        "\n",
        "Pydantic models ensure LLM outputs are properly structured for downstream processing."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [],
      "source": [
        "from pydantic import BaseModel, Field\n",
        "from typing import Literal\n",
        "\n",
        "class RouteQuery(BaseModel):\n",
        "    \"\"\"Route query to appropriate data source.\"\"\"\n",
        "    datasource: Literal[\"vectorstore\", \"web_search\"] = Field(\n",
        "        description=\"Choose 'vectorstore' for AI/ML topics, 'web_search' for current events\"\n",
        "    )\n",
        "\n",
        "class GradeDocuments(BaseModel):\n",
        "    \"\"\"Grade document relevance to question.\"\"\"\n",
        "    binary_score: Literal[\"yes\", \"no\"] = Field(\n",
        "        description=\"'yes' if document is relevant, 'no' otherwise\"\n",
        "    )\n",
        "\n",
        "class GradeHallucinations(BaseModel):\n",
        "    \"\"\"Check if answer is grounded in retrieved facts.\"\"\"\n",
        "    binary_score: Literal[\"yes\", \"no\"] = Field(\n",
        "        description=\"'yes' if answer is grounded in facts, 'no' if hallucinated\"\n",
        "    )\n",
        "\n",
        "class GradeAnswer(BaseModel):\n",
        "    \"\"\"Check if answer addresses the question.\"\"\"\n",
        "    binary_score: Literal[\"yes\", \"no\"] = Field(\n",
        "        description=\"'yes' if answer addresses question, 'no' otherwise\"\n",
        "    )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Create Specialized LLM Instances\n",
        "\n",
        "Each LLM instance is bound with a specific structured output schema for its task."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [],
      "source": [
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "from langchain_core.output_parsers import StrOutputParser\n",
        "\n",
        "# Router LLM - decides data source\n",
        "router_llm = llm.with_structured_output(RouteQuery)\n",
        "\n",
        "route_prompt = ChatPromptTemplate.from_messages([\n",
        "    (\"system\", \"\"\"You route queries to the appropriate data source.\n",
        "Use 'vectorstore' for questions about AI, machine learning, or NLP.\n",
        "Use 'web_search' for current events, news, or topics outside the knowledge base.\"\"\"),\n",
        "    (\"human\", \"{question}\")\n",
        "])\n",
        "\n",
        "question_router = route_prompt | router_llm\n",
        "\n",
        "# Document grader LLM\n",
        "doc_grader_llm = llm.with_structured_output(GradeDocuments)\n",
        "\n",
        "grade_prompt = ChatPromptTemplate.from_messages([\n",
        "    (\"system\", \"\"\"Grade if the document is relevant to the question.\n",
        "Give a binary 'yes' or 'no' score. Use lenient grading.\"\"\"),\n",
        "    (\"human\", \"Document: {document}\\n\\nQuestion: {question}\")\n",
        "])\n",
        "\n",
        "retrieval_grader = grade_prompt | doc_grader_llm\n",
        "\n",
        "# Hallucination grader LLM\n",
        "hallucination_grader_llm = llm.with_structured_output(GradeHallucinations)\n",
        "\n",
        "hallucination_prompt = ChatPromptTemplate.from_messages([\n",
        "    (\"system\", \"\"\"Check if the answer is grounded in the provided facts.\n",
        "Give 'yes' if grounded, 'no' if it contains hallucinations.\"\"\"),\n",
        "    (\"human\", \"Facts: {documents}\\n\\nAnswer: {generation}\")\n",
        "])\n",
        "\n",
        "hallucination_grader = hallucination_prompt | hallucination_grader_llm\n",
        "\n",
        "# Answer grader LLM\n",
        "answer_grader_llm = llm.with_structured_output(GradeAnswer)\n",
        "\n",
        "answer_prompt = ChatPromptTemplate.from_messages([\n",
        "    (\"system\", \"\"\"Check if the answer addresses the question.\n",
        "Give 'yes' if it resolves the question, 'no' otherwise.\"\"\"),\n",
        "    (\"human\", \"Question: {question}\\n\\nAnswer: {generation}\")\n",
        "])\n",
        "\n",
        "answer_grader = answer_prompt | answer_grader_llm\n",
        "\n",
        "# Generator chain - creates final answer\n",
        "rag_prompt = ChatPromptTemplate.from_messages([\n",
        "    (\"system\", \"\"\"You are an assistant answering questions using the provided context.\n",
        "If you don't know, say so. Be concise and accurate.\"\"\"),\n",
        "    (\"human\", \"Context: {context}\\n\\nQuestion: {question}\")\n",
        "])\n",
        "\n",
        "rag_chain = rag_prompt | llm | StrOutputParser()\n",
        "\n",
        "# Query rewriter\n",
        "rewrite_prompt = ChatPromptTemplate.from_messages([\n",
        "    (\"system\", \"\"\"Rewrite the question to be more specific and optimized for retrieval.\n",
        "Focus on the core semantic intent.\"\"\"),\n",
        "    (\"human\", \"{question}\")\n",
        "])\n",
        "\n",
        "question_rewriter = rewrite_prompt | llm | StrOutputParser()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Define Graph Nodes\n",
        "\n",
        "Each node performs a specific task and returns state updates."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [],
      "source": [
        "def retrieve(state: GraphState) -> dict:\n",
        "    \"\"\"Retrieve documents from vector store.\n",
        "    \n",
        "    Uses semantic search to find relevant documents based on the question.\n",
        "    \"\"\"\n",
        "    print(\"---RETRIEVE---\")\n",
        "    question = state[\"question\"]\n",
        "    documents = retriever.invoke(question)\n",
        "    return {\"documents\": documents, \"question\": question}\n",
        "\n",
        "\n",
        "def generate(state: GraphState) -> dict:\n",
        "    \"\"\"Generate answer using retrieved documents as context.\n",
        "    \n",
        "    Creates a response grounded in the retrieved information.\n",
        "    \"\"\"\n",
        "    print(\"---GENERATE---\")\n",
        "    question = state[\"question\"]\n",
        "    documents = state[\"documents\"]\n",
        "    \n",
        "    # Format documents as context string\n",
        "    context = \"\\n\\n\".join(doc.page_content for doc in documents)\n",
        "    \n",
        "    generation = rag_chain.invoke({\"context\": context, \"question\": question})\n",
        "    return {\"documents\": documents, \"question\": question, \"generation\": generation}\n",
        "\n",
        "\n",
        "def grade_documents(state: GraphState) -> dict:\n",
        "    \"\"\"Filter documents based on relevance to question.\n",
        "    \n",
        "    Each document is evaluated independently. Only relevant docs proceed.\n",
        "    \"\"\"\n",
        "    print(\"---CHECK DOCUMENT RELEVANCE---\")\n",
        "    question = state[\"question\"]\n",
        "    documents = state[\"documents\"]\n",
        "    \n",
        "    filtered_docs = []\n",
        "    for doc in documents:\n",
        "        score = retrieval_grader.invoke({\n",
        "            \"question\": question,\n",
        "            \"document\": doc.page_content\n",
        "        })\n",
        "        if score.binary_score == \"yes\":\n",
        "            print(\"---GRADE: RELEVANT---\")\n",
        "            filtered_docs.append(doc)\n",
        "        else:\n",
        "            print(\"---GRADE: NOT RELEVANT---\")\n",
        "    \n",
        "    return {\"documents\": filtered_docs, \"question\": question}\n",
        "\n",
        "\n",
        "def transform_query(state: GraphState) -> dict:\n",
        "    \"\"\"Rewrite query to improve retrieval.\n",
        "    \n",
        "    Used when initial retrieval fails to find relevant documents.\n",
        "    \"\"\"\n",
        "    print(\"---TRANSFORM QUERY---\")\n",
        "    question = state[\"question\"]\n",
        "    documents = state.get(\"documents\", [])\n",
        "    \n",
        "    better_question = question_rewriter.invoke({\"question\": question})\n",
        "    return {\"documents\": documents, \"question\": better_question}\n",
        "\n",
        "\n",
        "def web_search(state: GraphState) -> dict:\n",
        "    \"\"\"Perform web search for queries requiring current information.\n",
        "    \n",
        "    Note: This is a placeholder. In production, integrate with a search API.\n",
        "    \"\"\"\n",
        "    print(\"---WEB SEARCH---\")\n",
        "    question = state[\"question\"]\n",
        "    \n",
        "    # Placeholder for web search results\n",
        "    # In production, use TavilySearchResults or similar\n",
        "    web_results = Document(\n",
        "        page_content=f\"Web search results for: {question}. This is a placeholder.\"\n",
        "    )\n",
        "    \n",
        "    return {\"documents\": [web_results], \"question\": question}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Define Routing Logic\n",
        "\n",
        "Conditional edges determine the next node based on current state."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [],
      "source": [
        "from typing import Literal\n",
        "\n",
        "def route_question(state: GraphState) -> Literal[\"web_search\", \"vectorstore\"]:\n",
        "    \"\"\"Route question to web search or vectorstore.\n",
        "    \n",
        "    LLM decides based on question content.\n",
        "    \"\"\"\n",
        "    print(\"---ROUTE QUESTION---\")\n",
        "    question = state[\"question\"]\n",
        "    source = question_router.invoke({\"question\": question})\n",
        "    \n",
        "    if source.datasource == \"web_search\":\n",
        "        print(\"---ROUTE TO WEB SEARCH---\")\n",
        "        return \"web_search\"\n",
        "    else:\n",
        "        print(\"---ROUTE TO VECTORSTORE---\")\n",
        "        return \"vectorstore\"\n",
        "\n",
        "\n",
        "def decide_to_generate(state: GraphState) -> Literal[\"transform_query\", \"generate\"]:\n",
        "    \"\"\"Decide whether to generate or transform query.\n",
        "    \n",
        "    If no relevant documents found, transform the query and retry.\n",
        "    Otherwise, proceed to generation.\n",
        "    \"\"\"\n",
        "    print(\"---ASSESS GRADED DOCUMENTS---\")\n",
        "    filtered_documents = state.get(\"documents\", [])\n",
        "    \n",
        "    if not filtered_documents:\n",
        "        print(\"---NO RELEVANT DOCS, TRANSFORM QUERY---\")\n",
        "        return \"transform_query\"\n",
        "    else:\n",
        "        print(\"---DOCS AVAILABLE, GENERATE---\")\n",
        "        return \"generate\"\n",
        "\n",
        "\n",
        "def grade_generation_v_documents_and_question(\n",
        "    state: GraphState\n",
        ") -> Literal[\"useful\", \"not useful\", \"not supported\"]:\n",
        "    \"\"\"Check if generation is grounded and addresses question.\n",
        "    \n",
        "    Two-stage validation:\n",
        "    1. Hallucination check - is answer grounded in documents?\n",
        "    2. Answer check - does answer address the question?\n",
        "    \"\"\"\n",
        "    print(\"---CHECK HALLUCINATIONS---\")\n",
        "    question = state[\"question\"]\n",
        "    documents = state[\"documents\"]\n",
        "    generation = state[\"generation\"]\n",
        "    \n",
        "    # Format documents for grading\n",
        "    docs_text = \"\\n\\n\".join(doc.page_content for doc in documents)\n",
        "    \n",
        "    score = hallucination_grader.invoke({\n",
        "        \"documents\": docs_text,\n",
        "        \"generation\": generation\n",
        "    })\n",
        "    \n",
        "    if score.binary_score == \"yes\":\n",
        "        print(\"---GROUNDED IN DOCUMENTS---\")\n",
        "        print(\"---GRADE GENERATION vs QUESTION---\")\n",
        "        \n",
        "        score = answer_grader.invoke({\n",
        "            \"question\": question,\n",
        "            \"generation\": generation\n",
        "        })\n",
        "        \n",
        "        if score.binary_score == \"yes\":\n",
        "            print(\"---ADDRESSES QUESTION---\")\n",
        "            return \"useful\"\n",
        "        else:\n",
        "            print(\"---DOES NOT ADDRESS QUESTION---\")\n",
        "            return \"not useful\"\n",
        "    else:\n",
        "        print(\"---NOT GROUNDED, RETRY---\")\n",
        "        return \"not supported\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Build the Adaptive RAG Graph\n",
        "\n",
        "Connect nodes with conditional edges to create the full workflow."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Adaptive RAG graph compiled successfully\n"
          ]
        }
      ],
      "source": [
        "from langgraph.graph import StateGraph, START, END\n",
        "\n",
        "# Initialize graph with state schema\n",
        "workflow = StateGraph(GraphState)\n",
        "\n",
        "# Add all nodes to the graph\n",
        "workflow.add_node(\"web_search\", web_search)\n",
        "workflow.add_node(\"retrieve\", retrieve)\n",
        "workflow.add_node(\"grade_documents\", grade_documents)\n",
        "workflow.add_node(\"generate\", generate)\n",
        "workflow.add_node(\"transform_query\", transform_query)\n",
        "\n",
        "# Build the graph structure\n",
        "# Entry point: route to web search or vectorstore\n",
        "workflow.add_conditional_edges(\n",
        "    START,\n",
        "    route_question,\n",
        "    {\n",
        "        \"web_search\": \"web_search\",\n",
        "        \"vectorstore\": \"retrieve\"\n",
        "    }\n",
        ")\n",
        "\n",
        "# Web search goes directly to generation\n",
        "workflow.add_edge(\"web_search\", \"generate\")\n",
        "\n",
        "# Retrieval goes to document grading\n",
        "workflow.add_edge(\"retrieve\", \"grade_documents\")\n",
        "\n",
        "# After grading, decide to generate or transform query\n",
        "workflow.add_conditional_edges(\n",
        "    \"grade_documents\",\n",
        "    decide_to_generate,\n",
        "    {\n",
        "        \"transform_query\": \"transform_query\",\n",
        "        \"generate\": \"generate\"\n",
        "    }\n",
        ")\n",
        "\n",
        "# Transformed query loops back to retrieval\n",
        "workflow.add_edge(\"transform_query\", \"retrieve\")\n",
        "\n",
        "# After generation, validate answer quality\n",
        "workflow.add_conditional_edges(\n",
        "    \"generate\",\n",
        "    grade_generation_v_documents_and_question,\n",
        "    {\n",
        "        \"not supported\": \"generate\",  # Retry generation\n",
        "        \"useful\": END,                # Success\n",
        "        \"not useful\": \"transform_query\"  # Transform and retry\n",
        "    }\n",
        ")\n",
        "\n",
        "# Compile the graph\n",
        "app = workflow.compile()\n",
        "\n",
        "print(\"Adaptive RAG graph compiled successfully\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Visualize the Graph\n",
        "\n",
        "Generate a visual representation of the workflow."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAi0AAAI5CAIAAADizJ2oAAAQAElEQVR4nOzdBXzTahcG8DftfEwYY2MwGAwd7n4ZMOziLsPdubj7kA93v7i7c3F3d2fokDF3a/udNlDKjA3WNWmf/+XXmyZpmnZpTt5z3iRGCoWCAQAA6IgRAwAA0B3EIQAA0CXEIQAA0CXEIQAA0CXEIQAA0CXEIQAA0CXEITF5cDH03bOw8BB5bHRcXLRqFMeYgnESppArH4lcoeAUnHKKaiSRSJlcRv9TMDn/AnpQsO/zqOfnF8VoIQoljkm+vSvHOE65KDlTSCScaiEa4+k/OfdtBC1NzjiNFeakCmMTqbGZJJOjae5iGXIUMGMAAD/jcP6Q8J3e4vv6aXh0hFwi5UzMJMYmnMSIk8WoA4I6DqlCgILxf9MfcciIk8cpmJRCiDJqKCdR/OAHJDRIwUOhsSjlJqFQharvo77FIeXrlMtUaIxXvqN6DCflFDJVWFN8C0ZSY1oMFxsll8kUUeEyCmNWGY1KVLMrXNGKAQCoIA4J2qF/P71/HmFiInXOb165oaOlDRO1V3cj75wP+OoTJZVyFetnRjQCAIY4JFjhAYotc95IjbhqLbLkKqxv6azT232f3wm1zmjsOSIHAwDDhjgkRJcOBdw7G1jcPWPFBnZMf+1e8MHXJ7r3zNwMAAwY4pDg+L6L2bPEp9eMXMwA3D4dcvXw1z5zEIoADBfikLCc2+P37HpIj/+5MoPx4Xn0gZUf+sxGKAIwUBIGgvHmUeTjK8EGFYSIcz7Tcn/brxjlzQDAICEOCciRdR+rtXBghqeUh03GzCZbZ75nAGB4EIeEYtvs9zZ2xgXKGmhX5paDnQO/xjy7GcYAwMAgDglCXDTz/xTddpRBd2LOUyzD+T1fGQAYGMQhQdi56INVRmNm2Gq1c4yJkb+8G8EAwJAgDglC4Ofo8n9nZuno1atX9evXZ6m3Y8eOCRMmMO2wz2p67agfAwBDgjikew8uhzCO5StlwdLR48eP2W/57RemRNFKNsF+MQwADAnikO69vBNmkUHKtCM0NHTWrFmNGjX666+/evbsuW/fPhq5fPnySZMmff78uXTp0ps3b6YxFy5cGDt2bL169SpXrtyrV6+bN2/yL9+2bVvt2rXPnj1btmzZ2bNn9+jR49ChQ4cPH6YXPn36lKU1t3JWjHF+7+MYABgM3PdB94L9Ym0dTJl2ULz58uXLqFGjcuXKRSm16dOnu7q6UqSJiYk5fvw4BRWaJyoqioIQRRqamZ6ePHly0KBBFLEyZcpkYmISHh6+a9euyZMnFyxYMEeOHJ06dXJxceHn1AYTU8mTmyF/ZdfnCxoBgCbEId2LjZFldDBh2nH79u0OHTqUL1+ehvv371+jRg1bW9t485iZmVG7x9zcnJ9UuHBhCjx379718PDgOI6iVMeOHcuUKcPShYmZJNAXqTkAA4I4pHsKGWdhyTHtKF68+KZNm4KCgkqWLFmhQgU3N7dEZ6NGz+LFi2/duuXn962bQGBgoHpqoUKFWLqRsKgIxCEAA4L6kO7JlTePY1oyceJET0/PK1euDB48uGbNmsuWLYuLi199oUJRt27dYmNjp02bRnNevXo13gyUnWPpRXlvPQU2SwADgvaQ7kmkkuhoOdMOa2vrLl26dO7c+d69e2fOnFm9erWVlVW7du005zlx4gSVi6jkQ6k59nNLKP3JYuVG1trqtQEAAoQ4pHtGxpLAL1rpIRYcHHz06NFGjRpRBai4yrNnzxL2c6PZKFzxQYicOnWK6U5MtMLG3tBP6QUwKEiA6F4GW6PAL1FMC4yMjFauXDlixAhqDPn7+x8+fJiCEEUjmpQjRw4qBZ09e/bt27d58+al4d27d1PK7vLly9evX7e1taVkXaLLzJ49+8OHD2/cuBEQEMC0IDZalqcY7hcOYECkVD9goFOR4fLXj8LL1kr7nspU1ylSpAil3dauXbtp06b379937969cePGVIOxt7d//PjxunXrKOS0atVKJpNt2bJl4cKFlJQbM2ZMRETExo0bKThlzpz5woULVD2SSL4dsmTMmJHGbN26tVy5cs7OzixNvX0S9fx2SM22jgwADAbugycIiwe/bNY/u1MubZ1FJBY75r0P8Y/tNsWw7sAEYOCQlxMEKzujc7u/MIPn9zGmuDvOYAUwLOinIAi12zntWpjcXeCOHDkyc+bMRCfZ2NgEBwcnOolScAMHDmTaQUu+e/duopOio6NNTRNv21EmMGfOnIlOunTAXyFXlK5pywDAkCAvJxRrJ7zJkNGoxcDEKy5UsAkKCkp0UmRkpLqrWzwWFhYJr56QVqh6FBOT+AmnISEh1tbWiU5ycHAwMkr86GfZsFdF/spYuSHaQwCGBXFIQKhK1Hmiq6W1ISZLD6z87Ps+qptXTgYABgb1IQEpVc1u68x3zPB8eRPz/lk4ghCAYUIcEpAKDezsspisn/yWGZjdS9437pWdAYBBQl5OcG6cCLp7NrD71FzMAIQHy9ZPftN+TE4rO1zLB8BAIQ4J0f7ln6hY0rh3tszO6XeB0fR3ervvo6shrQbmcHDR548JAMlDHBKoG8eCbpzwy5zNvMWgbEzvvH0cdWLrZ4Vc4eL+Yvny5ZMnTy5cuDADAIOEOCRom//3PsgvxjaTcSkPuwJlMzDxO7/L78Xd0Ogoec5ClnU7Z6Ex7969Cw4OLlKkyJIlSzJnztysWTOpFDk6AAOCOCR04cHs8OoP/p+jadjUXJrBxtjcSrmjlsl+ulWEsYkkNubHGP5qcHL5j6f8MD9eQX93ufLvzjHlvX4kqjk5CafcHlTzcTRKodw2JBKO5qOZ6YW0pdA/iRE95VRjOOUyaB4pk8uY6qlCuWipQiHjpEacLE4hlXAyGYuJlocHxkWEy2VxMmNTqUsBy9odHBJ+0vfv32/btq1hw4b58+c/c+ZMtWrVGAAYAMQh0Xh1P+L5zVD/L5EBfqFmZpay2J+mGhkr4mJ/3NRVFUiY+m9LTxWqOMR9m4VChuTbU5qJ41QPP43nlCGJU42kbUR1dzrl4jgKgXL5tzHK2en/nOqpMpox5RwSBQUqiVQhV0YjZYQzMeXMLY0cc5mXq2lnaZuiLpozZsw4cODApUuXoqKizMzMGADoL8QhkenWrVvXrl0rVKjADIOfn1+rVq169OhBjwwA9BHikDjs3LnT1NSUclbM8FD16Pbt25SmO3369MuXLykg2djYMADQFziPVQQoPeXt7d2gQQNmkCjq8LWicuXK0ePhw4fp8fr167q9fzkApBW0h4Tr48ePS5YsmTp1anh4uKWlJQMNx48fnzVr1oIFCwoWLCiTydDFDkC8EIeEiO8GMHjw4LZt25YqVYpBEihlR62l1q1b58qVa8qUKYhGAGKEOCQ4GzduNDExQVk+VU6cOFGlSpXY2NhFixY1bdo0f/78DABEAvUhYbly5UpAQACCUGrVrFnT1NQ0Q4YMFIG2b99OY96+fUtFNQYAgof2kCDQTnP27Nl0LJ/MnUwhVT58+ECJzXr16nXs2BEFNgAhQxzSsZiYGMrCjR8/vlmzZsWKFWOQpnx9fR0cHNasWXPjxo2xY8dmy6aHF+sDEDvEIV1auXIlpZI8PT0ZaBnFIQsLi0KFCi1fvrxAgQJVq1ZlACAMqA/pzO3bt+kRQSh9lClThoIQP3Do0KHPnz+z738CANAttIfS28uXL6dMmbJu3Tqc9aJDfM/4Hj16UEFu/fr1uIodgA6hPZR+qFpOj3v37h01ahQNIAjpEH8BV8qLzp07l6n6ibRp0+b8+fMMANId2kPpZNGiRXZ2dm3btmUgSC9evPD29q5du/axY8eoeVS/fn0cKACkD7SHtI7yb/fv37e2tkYQErK8efNSEKKBYsWK0d9r3759NPzgwQMGAFqG9pAWPXv2bMKECZs3b6YskESCkC8+GzZsWLFixZ49exwdHRkAaAfikFbw1z1bvHjx33//nTt3bgaiFR0dTWk6/ip2VatW7dWrFwOANIU4lPZmz56dKVOmzp07M9Aj/v7+VDry9PT8+PHjiRMnGjVqZGtrywDgjyFZlJZiY2OfPHni7OyMIKR/6NiCP9krc+bMISEh6o52ERERDAD+ANpDaYPCz8iRI3fs2IGrwxmUu3fvDhgwYMyYMXwfBwD4DYhDf8rPz8/e3n7dunU1a9bE5csME7WKXFxcvLy84uLiBg8ejNuWA6QK4tDvo69u6tSpFHuQhQOm2h6OHDmSJ0+e/Pnzr1mzpnz58gULFmQA8CuIQ78pMjLS19f3zp07jRs3ZgA/O3jw4M6dO1evXk0tpICAADSUAZKBOJRqDx48GDJkyL59+ywsLBhA0ujHRccrbdq0KVWq1Pjx4ykmGRkZMQD4WXrHofDwcPo1MnGKiIig2PPu3TtHR8c/7I9gbW3NX+IMDMGrV69y58596dKlHTt29O7du0CBAgwAvkvvOBQSEhITE8NEiNacDmbTqg1kZ2eHKywYIApFwcHBdevWPXbsGB2LVKhQgQEYPGQJfk0ul9OjqQoD+AOVKlXiB1xcXJYsWRIbG1ulShVvb29XV1cGYKjQHkoO7Sbo6FUbbRe0h4CpNjBjY2MvL687d+5s3rzZ3NycARgexKHE8SXlqKgoagNpo5CDOASaqOhob29PG1vXrl2bNWvWoEEDBmAwsCtMhDpYmpmZoTcBpIMcOXJQ6VEqlQ4bNoy/Z/nLly//++8/BmAA9CoOtW7d+tOnT+wPyFXosJR2Cm/evOnQoQMDSEeFChXq3r07U13F7vLly+PHj6fhDx8+MAD9pT9x6MuXL0FBQex3Uab+69evNEDpMr4/wvPnzxmAjtjY2FDdaPLkyTT8+PHj6tWr37t3jwHoI13WhyIiIlq2bNmuXTtqx/BjZDJZ8+bNKTnepUuXgICAlStX0i8wOjq6VKlSnp6ezs7O/Gzv379fsGDBw4cPnZycKlWqRK2WJ0+ejBgxgp9aoUKFCRMm0MCWLVtOnDjh7+9Ph5ZFixbt378/X5KhN6WlXbx4kZawc+dOelOa8/r16xTG8uXLRz/4OnXqbNiwgUbyC+zRo0fTpk1pbRctWkT7grCwMMqi1K5dm0/i79u3b/v27bTwKVOm0JjevXtTbWn9+vW0QF9fXzq8bdiwYdmyZeN9D6gPQarQD4eOk3Lnzk2RydHRkX4gxsbGDEAvSCdOnMjSEQUV2u/zw/RDevXqFYWQunXr8mNu3bp1/Pjxvn37WltbDxw4kNIR//zzT/v27b29vRcvXvzXX39ZWVlRu2fAgAEUfmh89uzZDx48+PHjx8aNG1MIOXPmzNq1a+vXr89Ud9I8fPgwRYU+ffrQ73bHjh1GRkb89b727t1LZWEa7tixIy2QQhoFtp49e9ICKfitW7euRIkSNWrUoFX18/PbvXu3m5sbvWrkyJG0Lxg6dCiFPQqlq1atKlOmDNWWad2uXbtGMYxeXrFiRVpzWlV6a4qvtPIUbObMmUMR1MXFRfN7WExewQAAEABJREFUMDc3R+UJUo7a6HTswlSJu2fPntEmTQ0m2jizZctGVUwGIGY6PiSn0EL1WL4wSyghTvtrV1fXR48eUWwYPnw47evp50cZc9q/U8uDqaII/SYpGBQvXrxevXoUSxIeGFKThRo6bdq0ocCQIUOGKlWqUKNk69atlHyjqRQAKPxQK4fiDQ1Qk6ty5crU5KJmEx1mzp8/P1OmTPEWSI0bWiUKjfnz5+dvzUm7g02bNvFLi4qKatGiRbVq1WinQNHr5MmT1OSidaN1pmZT1apV1U0rgD9Ehz70c6AWOQ1TNZS2fxoIDQ3lt20AMdJxHCpfvjwFlUuXLjHVxbgoV0Z7cxqmnT5FF4o0/Gy0r6fE2oMHD2j49evXefLkkUql/KRatWpR+yneYqkhRT9Lzaun5M2bNzw8nFpO/FNqSHEqJiYmFFH27NlD7ZurV6/Sq2hOOtiMt8A3b97QUWfOnDk1F/jixQv1U2qN8QM0klpLFNXUk2jNaZ2pLcUA0lS/fv34gzM6EqKDLcoGMwAR0vH1FGjnXq5cOWoGNWvWjGIPHdZReYapGjQUEqhOozkzfxtmCie/vL8LpdeYKpWhHsOfIRgZGck/pZaKujwzZMgQSqOdPXuWshyWlpbUcmrbtm2861HSAuNlP2iB6qURimf8AK0ev8x4qxQYGEhvygC0gJryV65cQUcGECndX9eHjuOowu/v70+NIarZODg4MFUZn/b7kyZN0pyTbwNRqPjlnZhpHqY6SFSP4V/CZ9jjodQc5dlatWpFgZAiIqXvKJVHcVFzHgsLC82l8QtMmL5jqrtH0yNVhrJmzao5nvYUDECb6Oczc+ZMymYzAFHRfZctag/RXv7GjRvnzp2jUgo/kkpEtN+nfXex7yg+8dfgogwYVXTUF+2mdsyoUaPUfR/UL6egRbOpx1Bpl6IL5dapmcVfL45H6bL9+/fTe1GOrnDhwlQ0oveiklW8laQ3pXk0x9MC43U94FH44dth6jWnVD6lAXGTCNA2+lEcPHiQAYiN7uMQ1YEqVKhw6NCh4ODgv/76ix9ZokSJ0qVLz58/39fXl8bTr2vAgAEnTpygSZSso1iycOHC27dvU2FpzZo11AShqMP36j5//vzTp0+piUP5vW3btlHJh3J9J0+ePHDgQNOmTSkXx5eF1O9O+bfNmzdPnTqVGkOUfKM5KdhQxYgmZcuWjcZQC4mqTbQyTk5O9KbPnz/n+9TRu8RrM/Eo3rRr146W+fDhQyoUXbhwYfTo0UuWLGEAWkY/JfXZCwAiIojry1G0mDhxItX2KR6oR1Krhco2p0+ffvLkCcWYkiVL9unTh5909+5dClGfP3+mlkeNGjU6d+5MbR0aP2fOnDNnzvDZCarTrFy5ktpYdJBIIYTCUosWLfiqD5V/+FfxS3vw4MGyZcu8vb1pOGfOnI0bN65VqxZFLEoV0nIo595O5c2bN//++++tW7eoFJQrV66WLVtWrFiRXvLff/8tWLCA4qhmSYlmo2YWrSdlCN3c3AYOHBivOITzhwAAeIZ4nVP6yDo/dwdxCNIc5QnmzZuH+hCIjsHtCql59CeX/wEQLNSHQKQM7j548epDAHoD9SEQKdx/SDeQlwMA4BnirlCz3zaA3qD60MyZMxmA2BhcHKIghPoQ6CXUh0CkDK4+xFQlIgagd1AfApFK7/oQcmI8dJcAAOCldxzSOfq8ISEhv7xSKoDo4PwhECmDqw+FhoY2adKEAegd1IdApAyuPkQ5dP4iQAB6BvUhECmDy8sBAICgGOL5Q8HBwQxA7+D8IRApg4tD1P6rUaMGA9A7qA+BSBlcHOI4zt7eHtlI0D+oD4FIoT4EAAC6ZIj1IX9/fwagd1AfApEyxDjUqFGjqKgoBqBfUB8CkTLE68s5ODjg8kKgf1AfApFCfQgAAHTJEPNygYGBaA+B/kF9CETKEONQmzZtAgICGIB+QX0IRMoQ60P29va45wLoH9SHQKRQHwIAAF0yxLxcUFCQTCZjAPoF9SEQKQNqD5UoUSJeOo4+e7169aZMmcIAxC8yMrJWrVoXLlxgAKJiQO2hAgUK0KNEg5OTU6dOnRiAXkB9CETKgOJQu3btLC0tNceULl06T548DEAvGBkZ1a9fnwGIjQHFIUrB5c2bV/3U3t6+TZs2DEBfoD4EImVY/RSoSWRubs4PFy5c2M3NjQHoC5w/BCJlWHGoevXq+fLlY6rGEMUkBqBHUB8CkdJ9f7nbp4L9PkZFR2l0pKbgqLrsDidhip8Hvk2XMqZg6kvzxJtNIuHkco0PxSlnVi8zICjg8aPHNtY2RYoUUb2EU34HMsZxjL4JiYTFv+KPRPXSnxerHqaX05vK4xTx1oSWys/LSbkMliaFK9vZZ8OZswAAidBlHDq/O+DJjSDalUulXEyUxu6fjxyaA9+jyLfpUgVTcD8i04/5leNpgYoEcYgPM/xTuVzOKXtwc9+mMuWrvs32c8Djl0nz0kjNST8iH02VSn7Eoe/v8mNAyhkbs5gYhaWVtMNYFwagNVQfmjdv3vDhwxmAqOgsDr1+EHF8q2+1Zlmd8pgwA3B80+fgL1FdJudkANqB84dApHRTH3p8JZz2y54jchpIECK12mWxzmy+buJbBqAdqA+BSOkmDl074Z81TwZmYGp3cKQymPdd3AoWtALnD4FI6SYORYXH5ittywyPqYX08Y1ABqAFOH8IREo3cUgWqzA1uOaQkixOFhkexwC0AOcPgUjp5v5Dyr4RBnm7CblMIovFrWBBK1AfApEyxPvgAegl1IdApAzx/kMAegn1IRAp3cQhTsEMNwTiugqgHagPgUjpJhgolPtiQyyTcJxCIkEgAq1AfQhECvWhdKVQcHKZQfbQAO1DfQhECvWh9IbWEGgJ6kMgUjrKyzGFRGGgO2S0hkBLUB8CkdJNXk55BWsGAGkJ9SEQKR3l5VT3bWCGR8GUt5xgAFqA+hCIlI76bXPKe/0ww8Mxic5vPAj6CvUhECkd1YeUUcgQd8fKu+9J0R4CrUB9CETKsPrL7d6zzaNmWaY7FIAV6LcN2oH6EIiUruKQQqK1vNykySOP/Lc/0UkF3Qq3b9eNAegj1IdApHQVhzi51vJyz549TmqSm1vhTh17MAB9hPoQiJQ48nKUT2vWovbFS2cpq7ZoyWymSoWvWLmwc9eW9RpUGTFqwNWrF/k5q3mU/vT546zZXg0aVaWnEyYOn+w1iuak8ecvnI6Xlzt67GCffp3+rleZHnft3sL3IOj/T9fhI/ppvvuoMQNphmTeNOWkRkxiLGUAWoD6EIiUjvrLMVXJPsVMTEwiIsIPHNg1auTkJo1a0piFi2ZS5GjSuNWWzQfdq3hMmDT83PlTNP7okUv0OGzouIP7zzJVxtz79Uv6N9VrbtEiJTSXefLU0RkzJ+XLW2DLpgPduvalpS1eOofGV3Oveev29fDwcH62qKiomzev1qheJ5k3TTlZHJPHyhiAFqA+BCKls+uccvJU5OU4jqN40Lp1xxoedZydc0RHRx87fsizTaeGDZrZWNvU/buRR/U6GzauSvSFnz9/nDRhZsWKVWxtM2pOOnJkX9GiJQb+MzJjRruSJcp07thr374dgYEB7u415HL5hYun+dmoEUZPq1atmfI3BdAJ1IdApHR4HitLrQL5C/EDz58/iYmJKVO6gnpS8WKlvL1fBocEJ3yVS45cZmZm8UZSaHn46J7mEkqUKEMj7z+4kymTPS3twsUz/PhLl86WKlnWzi5TUm9KAZIBCABtnytWrGAAYqOr6/pQKEh1IKLsHD8QFhbKVIWceDMEBvg7OWWL/ypT04SLol8sFXVXr1lK/35aQmAAPVLrZ/GS2RRgpFLplasXBvQfnsybhoeHJYxzAOlPJpNt2rSpZ8+eDEBUdBOHlB0CJL/fXy6TfWZ6HDJ4TLZs2TXHOzhkSeESKHJYWFjUqlmvShUPzfFZnZyZKg5RKejylfMU+ZRJOfeaybyplZU1SzGpkUJqgn4KoBWoD4FI6ez+Q39y9pBzthymqlZOieKl+THUjlEoFBRaqIqTwoXkzp0vNCxUvQRqHn365OPg4EjDVP6hXNz165ejo6MqVXSnxSbzpupWWkrI4jhZjCHeABDSAepDIFI6u67Pn1xljQJDp449N2xc9eDBXcqwnTt/aujwPvMX/I8mUajInNnh5s2rd+7ejIuLS2Yh3bv2o9rPkf/2U4uHljPZa9Tgob1oafxUd/ca9+/fvnXrGrWNfvmmAEKA84dApHRXH/qzyym0btWBGjRbtq27ffu6pWWGQgWLDhkylp/U1rPL2nXLr9+4vHXLoWSWUKRI8ZXLN2/esnbFyoVRUZG0hClec02/F5MoFzd33jR6Su2hlLwpgM7x5w8NHz6cAYgKp5PLPy8a9LJ+Lxf7LMbMwGyb+cbKlms9zIUBpDWKQ0ePHkVqDkRHZ9dTMMw74UmkCqkRrrcNWoH6EIiUzq5zaph34ZHLOFkcrrcNWoH6EIiUzq5ziruSAqQtXF8OREpn/bYBIG3h/CEQKcO6D57OKZjcIO+HDukB9SEQKR3ef8gQ98ccfeEoD4F2oD4EIqXD+7EaZn85+oc2KGgF6kMgUjqqDxlmbzllfzn6h+v6gFagPgQipaM4xEk4BZoFAGkJ9SEQKd2dP8QZZLOAUzAJOiqAVqA+BCKlszhkoF31FByTo6MCaAXqQyBSujp/SHljcAYAaQf1IRAp3Z3HilYBQJpCfQhESjfJMamUGUkM7mLbxNSCM7MwxA8O6QD1IRAp3cQhY2Ppx9dhzPDERClsHVNx/1aAlEN9CERKN3HILovJsxtBzMBEBrHYKHnV5vYMQAtQHwKR0k0cavZPtphI2bUjhhWK9i5/XdzdhgFoB+pDIFKcDm8EtGr0G9MM0hz5M2TKahoXE5fkfFIJS+YaBFRrkskSncJJJAqFTNlVOpFpyjtPKBLrQq0cz+SJv0rCKa8EoUj0vRJfGq2eIlb+9kmE77vwEtUzla2FOATaQvWhefPm4b7gIDqcbm9It3/Zp68+UbGxCllM0pGGS65zHcclfZEgTvm6xO/7mswy+QCUaLDhOLlckeidkzgJU8gTX5qxicTc0rhCg0x5i1swAK2JjIysVavWhQsXGICocIK6MerTp09fvHhx586dBw8ehIaG+vv7165de8qUKUwMunXr1rx58zp16jAAXYiLizt69ChScyA6QolDFGwePnwYEREREBBAjzRGIpE4OjpOnz69aNGiTCTGjh2bK1eurl27MgAASBmhXFxnz549z58///jxY1RUlESFAmTu3LlFFISYKprGxMRMnjyZAaQ7nD8EIiWUOHT79m0bm59q+BkzZmzSpAkTm969excvXrxnz54MIH3h/CEQKQFdbPTMmTPUDOKH5XK5nZ1dtWrVmAg1bNiwR48elKaXJdGRD0AbcP4QiJSA4lC7du0mTZrED5uYmNDenIlWqd2kJbwAABAASURBVFKlVq9eXalSpbdv3zKAdIHzh0CkBBGHfHx8aJc9bty4v//+++bNm9QYypIlS4MGDZiYOTo6Xr16dfDgwZcvX2YA2of6EIiU7uPQpUuX+vTpc/r06fz58/Nj7O3ty5UrF69cJFK7d+/etm3bzp07GYCWoT4EIqXjftsbN26kBtCCBQuYXpsxY4apqenAgQMZgNbg/CEQKV3GocmTJ1Oj559//mEGYNOmTffu3Zs1axYDAAANOsvLde7cuXjx4gYShJiqF0bdunU9PT0ZgHagPgQipYM49PXr16pVq1IBX9Q94n5DtWrVJk6c6O7uHhRkcPe8gHSA+hCIVHrHoevXr3fo0OHw4cNFihRhhidfvnxHjhxp3rz5o0ePGECawvlDIFLpWh/avn37+fPnlyxZwgxep06dKEdXq1YtBgBg2NKvPTR9+vR3794hCPHWrVt37ty5NWvWMIA0gvoQiFQ6xaGePXtSSmrYsGEMvps6dWpUVJSXlxcDSAuoD4FIaT0OBQcH16xZs0ePHs2aNWPwsz59+hQtWrRXr14M4I+hPgQipd360J07d6gNtHPnzowZMzJIws2bNydNmrR//371ZV4BAAyHFnd8e/bsWbp06cmTJxGEkle6dOmVK1eWL1/+/fv3DOB3oT4EIqWtODRnzpxnz56tWrWKQQo4OTldv359wIABV69eZQC/BfUhECmtxKG+fftmzZp11KhRDFJj7969mzZt2r17NwNIPdSHQKTSuD4UHh7esmXL8ePHlytXjsFvmT59uqWlJbWNGACAAUjL9tCjR4/q1q27Zs0aBKE/Qe1IW1tbHNhCaqE+BCKVZnHo4sWLs2bNOnfunKOjI4M/06FDh9q1a7dr144BpBjqQyBS0okTJ7I/9vLly3///XflypUM0kiuXLkyZcq0YcMGd3d3BpACEokkS5Ys+fLlYwCiYsTSwtevXzmOY5Cm7O3tX716xQBSRiqV1qtXjwGIDU6cFC4jIyOZTMYAUkahUEybNo0BiA3ikHBRHKKMPwNIGcpJ7Nu3Ty6XMwBRSZu8HGgD4hCk1rhx49LzTi4AaQJxSLgQhyC1GjRowADEBnk54UIcgtSaPXt2dHQ0AxAVxCHhQhyC1Dp+/Hh4eDgDEBXk5YQLcQhSa+jQoRYWFgxAVBCHhAtxCFKrVq1aDEBskJcTLsQhSK2lS5cGBgYyAFFBHBIuxCFIrbNnzyIOgeggLydcUqkU11OAVOnTp0+mTJkYgKggDgkahSJqElHDiAGkQNWqVRmA2CAvJ2hIzUGqrF271sfHhwGICuKQoBkbG8fGxjKAlLly5cqXL18YgKgg4SNoaA9BqnTq1Cl79uwMQFQQhwQNcQhSpWLFigxAbBCHhKh48eISiYTjOIVCUadOHXqUy+VVqlRZuHAhA0igZMmSTHXfB9pU6JG2FhrInz//9u3bGYDgoT4kRLlz5+bjkPrR0dGxa9euDCAx5cuXZ6o4xG8wUqnUwsKiffv2DEAMEIeEqHHjxvHus16wYMFixYoxgMR06NAhc+bMmmOoSlS/fn0GIAaIQ0LUtm1bFxcX9VPaxXh6ejKAJFB7yM3NTf3U1NS0WbNmDEAkEIeEiLIrFHgsLS35pxSTypQpwwCS1rFjRycnJ37Y2dkZjSEQEcQhgWratCntTWjA1ta2TZs2DCBZJUqUKFSoEFP1sWzQoAHu/gAiIu7+cj6vYkKDY5hMrjlSwUk4BT+GSiwK5f8lTCJnylESjsmVY5Q9i+hRQTPTLIpvr6SSDD/8fbYfY2hWTqIeqXrRzzNovko5TDPL4y9WXfH58Yac4vvLJYyTa64MYw2r9z4cccg+c2ZHi5JPb4T89F4ai/32KdQfVk29DuopCWbhF8KplhFvZX+eTflCzdniLezHJE41HG8RCd9XxdjIOHdRcyZlYvH5bUzo1xiZQmN7+/bRvn9C9R9F9ZeVcBL5TzOrpqrnVY1RfJtfc4oGiXKDjvd3V33XP83IqV5as1yHwLdmUiOjgs41aINRbW5cvDnjrxL/cuUvJv6WodwiFUyR2Can/oDxtp9vA5qzxdtmpFyWbBlsHDkGoCHBLuO3XLlyZcuWLYsWLWLp5dj6r2+ehNJuVkF7hZ9/QvzP4ie02cs1wsBPE1L08RWJvjqZBSQxXhUyUv0j5H/vv5ia4B3VQe6Xb6o5g2Zo1DYjEwn97SytjDqOd2HCdm6H//O7wbJY2oVz8rj4cejHJhfvr5DYZvDTn+PHDEluYin1J9tygtd+mymly1S/6hdbmsRIOdXEVFLKI1OJatYMQEWU7aHLBwPfPgsvX8/RtaglA5E7t8N32TDvHv9zlQq1YfT4SujT2yElqmV2K2/F4I/dOxN09T+/zNlNnPOYMQAxxqFDqz77fohuMyInA73g3tIh6FOmVaO9e81wZcJzZoef9/0wz1G5GKSRYtVs6d+2Ga/L1c5c1D0DA4Mnvn4K71+Ee7RxZqBHbJ2klrbGu+YL8ULRz2+HlKxhzyCt5S5mc/3EVwYgujh052yIRCqxcxJPaRtSxjlXhmA/wV1Z/PWDGCqW5SmBY/a0V6aOXUy0nMUwAJHFoaCv0amrnIJImNlKYmPkTGCC/CMV2Ny0R8E+f0QgArHVh2Sx8rgY7Bj0kUwRGye4OCSXy2TCWyu9IZPJ5Qx3vgdcbxuEQaE6ewoADBDiEAgCx0k4XNwDwCAhDoEgKBQJT/PXPdVZvQy0hFPd1YSBwUMcAoEQ4h5JdVs5BlqiUN6uD+U3QBwCgVAwIe6ROIYwBKBtIotDnJRJcO6QXhLm/l6BswQAtE5kcUghY3L089RHykqB8EKRco0QiLQJvVOAIS8HAiFX1gqY0Hy7pQNoB8fS7+LuIGSIQyAIHCeRSLHLNyzK2xuhvQnii0PYaPWUQiGXy4T316W0EaIjgJaJLQ5hn6CnlOexCvCPS+lCAUZHPYIOicBEd51TiTD6y505e6KaR+mgoECWRuYv+F/nri2ZAVMIsj6Uzry9X9J2df/+HSZ4Hz68o1W9cfMq+wOqIIQ4BGKLQ3L0lxOSSZNHHvlvP0sL1BwS5B4Je0ktUtWHcB4riPA+eCAcz549ZmmEmkOCLP4hKQegdfrfX04uly9YOOPipbMmxiYeHnUKFyo2aszA3TuP2dllmjBxuFQqdXR02rZ9w6SJM6v8VX3P3u1Xr1548uShialpsaIlu3btmy3rt3u/Ll+x4PiJwxbmFrQQZ2cXzbc4euzggYO7X79+mStXnurVajVr2uaX58JERERMnT72zp0b9JJGDZrHm7ph47/Hjh/y8/N1cMhSvFipQQNHSSTKI4aQ0JAVKxZQE8TGxrZ0qXLdu/V3dMzy5OmjPn07Ll2y3q1AIf7l7do3rljRvU/vQa9fv+rSrdXihWtW/ruIsj1ZHJ1at+5YonjpcROGUl6lQIFC/fsNK5C/IL0kLi5u9ZqlV69d9PX9XLhw8SaNWpYvX5lfWuOmNTp36hUcHLR+w0pzc/MypSv06zs0UyZ7SsvQ1FmzvZYtn3dw/9nQsNC165Zfu3oxMCggf76CNWr8Xa9uY5YKnAD3+amtWu3Yuenq1Ytz5yznn3bs3JySt/v3nuKfek0ZHR4R/r9pCwIC/Jcum/vw0b2oqKgyZSp0aNcte/YfW1R0TPTSZfPOnT+pUCiqV6vdvVs/2kqTeVOabfeerceOHXr/4a1LjlylS5fv0rk3/5JHj+7TX+3p00c2thkrlP+rY4celpaW/KuS2tQT/igS3erU7z5n7tRDh/fS9kBzDug/nKUS6kPADKE9tHPX5oOH9tAOd/nyTebmFrS3pZH8bt3Y2Nj79Uv6N9VrbtEiJR48uLto8axChYpNnjx75IhJgYEBU6eN5Rey/8Cu/Qd2/jNgxNKlG5ycsm3YuEq9/JOnjs6YOSlf3gJbNh3o1rXvrt1bFi+d88u1mj3HiyLB7FnLvCbNfv3mFQUA9STam+/bv6N3z4G7dh7r2qXP2XMn6CMwVagYOWqAn/9X2s3Rx/H9+mXk6AE0Mpl3oQ9Ij4uXzKYd0OmTNwoVLrbq30VUixoxfOKx/y6bmpguXDSTn5MGaM2bNG61ZfNB9yoeEyYNP3f+lHoh27dvoG9s395T69fufvDw7rr1K2j80SOX6HHY0HEUhGhg5sxJjx/dHzhw1Lo1u9zcCs+bP512gizlaIckvD2SQpG681tcXfM+efpQJlPmjmn7+fLlE1OVUvip9NXRfpymDhrS8+69W4MGjl7z7/aMtnZ0GOHz8YN6IfS3yJfPjbbAtp5dtu/Y+MvM55492zZtXtO8mee2LYcaNGh2+Mg+CiHK9/V5P3R4n6joqMWL1tJm5u39YtDgHvwGk8ymHu9HkfxWR9tq0aIlaVLLFu327ttx+sxxBpB6YmsPSZgklaGTGhZ0pFbVvQYNt/XsfP3GZfUkarV8/vxx+dKNZmZm9NTKynrt6h3OzjmMjJRfS1xs7Oixg4JDgm2sbfbs3eZepQbtoGl8ndoN6ChSvXM5cmRf0aIlBv4zkoYzZrTr3LHXzNmT23l2oeGkVsnP7+uZsydGDJ9Q0K0wPe3ZY8DlK+f5SdSq2Lptfe9egypXrkpPabVp97Fp8+qmTVpfu36J3nf92l05cuSkSXQETUffdGTNfoUacCVLlFEurUqNU6eONmzYnH/fKlU86KicdrQxMTH0LXm26dSwQTMaX/fvRg8f3qNYy39eki1b9nZtuyiHMlhRe+j58ycJ3+Xe/dutW3UoU7o8Dffo3t/dvYaNtS1LOYGe0Ji6lcqTOx81cWgnnjdPfoo0FJYyWGagb4Y2qs+fP3396luqZDmKAe/evZkzexn/R+nda+Cly+d2796ibkyUKlm2hkcdGqCWK/1dzpw53qB+02TelJafP3/B2rXr03D9ek1KlCgTGRFBwydP/mdsZEwRiNox9HTokHFt2jagxABtVAULFklqU4/3o6D5k9nqaA1r1vibH6DfyIMHdygfwFIBjSFQSpv2EG27JiYmLB3IKc+Wmtnl8jdvvAsVKqoeU+UvD80ZKI/B/94IpSM+fvwwavQ/9Ru6U9KJfpk0MigwgPaQPj7vc+Z0Vb+KDlfVy6fsCu2a1ZNoL0Aj7z9IrsvTp08+yrd2+bHA/KrkGHn//m1sbKybKk6o3yssLIxW4NWrFxYWFvzuQDk+b4Gxo6c4ODiyX8me/dtLLDNkoEfXXHn4p+Zm5vReFIQortCj5qegZKC390vaMcX7vEwVrcPDwxK+S5EixWkPtWz5/MuXz9Ni8+dzy5LFiaWYftx/yNY2Y9aszhRpmKr1Q0lg+lPy7cL7929T8ipXrtw0ntocfBBiqt8OfdsUS9QL0fxDFHQr8vHTh+TftHDhYrduXZs5azLlh+lPRum1PHnyMWVS7h6lXvkgROjPQevGb5lJber8nJo/iuS3uiKFi6tXgw47oqOjWergPFZQSpv2EH9MzYSHyjAOvrDaAAAQAElEQVS0bhYWluox6p8lj5Lj6uFLl86NHT+E2kw9e/yTO3fem7euDR/Rj8aHh4dTLoVyeuo5zczM+QH61LTPpVwfn+5TC/z+k05UcEgQPVpoLND8+wIDAvyUyzc1+zFJNVtkZATt/U01xqec5OcmpCRBizIsLJQe+//TNd74wAB/OkBmqn0l+xXK9R04sOv0mWMUjagR0KRJqw7tu/OH2ymhEOQdALjUly8owFAAaNqk1b17t6iuRn8yKk/SeAoAJVSxh75t2mb46poaBTD1sKVlBvUwxQCqzCX/jpSRoy2cGlWUH6YvvGrVmj27D7C3z0xv9PTZ43hvFKhqyiS1qfM0fxTJb3VSI1yQBdKA6M5jTd2OgT+so5+9ekxgYJKJrENH9tJBPdV4+Kf83pkp9wuWdPwYHR2lnpOignr5tKeoVbNelSo/NbOyOjmzpPEJqyiNBUZEhH9/L+U+KDIqMt4kOzt72tfQ+1JjS/Kr1GScLI6lRib7zPQ4ZPAYyr9pjndwyJLyhVhbWVPujnZtlNO7cPHMxk2rM2SworJBihcgzONiSWoDUalS5aiqT8GDGpQlS5TlWx70lJpBnq070QzUKjI3N586ZZ7mq6Qap8VFafz1wyPC4x05JbKKEgml4+gfNf1v376+bsNKCh7Tpsyzy2RP2zPFQs2Z+W0vqU09oZRvdb8H/RSAifC6Pqlrx9PhIeUQ3rx5pR5Dh41JzRwSEpzF8Ucq6cKF0/wAtQYcHZ2U2ZUW3yZpdivInTsfFXUoP84/pZhHabfk02VZsmSlR9pf51flu+gldEDKHxHT0mjPRQfU6s5vlJ23ymCVObNDgfwFqfbw7PkTfhLVGObOn9a/7zBTE+XRqzo0UhKP6k8sNZyz5TBVHQKrP0WgKhtJITaFS6B0EFWeqLBEgZl2cPTv5ctnz188ZSkmEeT1FH7j7Fr6Dj9/+XTq9DFqZ/BfICVdqVRDf6/SquIZ/YkjIyMpxqu7Yn785GNr86M9RN+burPis2ePs2XNnvw7Hjt2iBKnlPGj1DH9o63x8JG9yjdyzXv8xOFiRUuqQwgFKqoJsaQ39YSS3Oo02kwAf0hs11OQsNRe76tihSr0a7xx8yrtWHfu2hwaGpLUnFRkptnu3L0ZFxfHd1Ejn1VdnqpVrXn+wukzZ0/Q8NZt6x8/fqB+Vfeu/S5dOnvkv/10zEiFgcleowYP7ZV8lpKCCuX0161bTtUgSqlPmTpGnfiiVkXNGnU3bV5DVZaQ0JDjxw/v3be9efO2tCuhvRi1V1auXEitDVrP+Qv+99X3i4tLLiodU6CiFaAPSGv+v5kTqITDUoN2l5069tywcRWtP635ufOnhg7vQ8tP/lW0J6IPclP1jdHT9RtWTpw8goIrFbFptV+8fKpZPPglYV5v+zcK6dR8oSLK7t1bqDjEj6EBquG7uuahlhBTdUMoW7bi7NleX758pnbSvv07e/Vuf/ToAfUSKLd57bqyN82Jk//RUUi1X1X+T50+On7iMNpg6Gjg6tWLFy6e5t+aNhvaJhcvnUOBhLa0FSsXdunWyvv1S5bsph5PUlsdSwtoDAFPbNdTkLPUXu+rY4ceRYqUoPR3+w5N3r59Tcl0pmwnGSecs0uXPuXKVhw7bnCtOhVoHzFyxCQ6GBw5asDJU0fbte1ar27jRYtnUbb9ytULfXoPZt97eNGx/8rlm+/fv9OkWU3afVNKZIrX3F8eLY4aOZkq2D16ta3XoAqFDWpJqPuL9e0zpFJFd6+po5s1r7V561rPNp0923RSrbPR7JlLaX89fsIw+jhm5ubTpy2gkVT0Hjdu+tOnj6rXKNOmbYOq7jWdnLKltvdZ61Ydhg0dv2XbugaNqlI9g/KKQ4aM/eWr2np2uX3nxrjxQyhMTp44y8/Pl4pMzVrU3rZjQ6+eA5Pv5SUSvxMbqQ5ETRza6vinhQoVpaclipdRzzB96nx39xqTp4xq3LQGhagaNf5u2rQ1jY+NUyaQKV22ctVC2tJW/buI/i5/12mY/NsNGTw2p4vrmHGDGzfxmDXHizaewYPGMNUxzep/t1PpsWfvdh06Nbt779awoeMoRrJkN/V4C09qq2NpAdfbBl7a3P/jypUrW7ZsWbRoEdOyk1u+PLsV1mF87pS/hA4GfX0/qzv8bNu+YfPmNQcPnGUgJPcvB9096dd3Th4mJLfPBF464N9porDWSm+sm/ii2T/OWXOaMzBs+n8eKwUeanbs3rONciCnzxzfsXNTw4bNGQgMJ9TrnEr0/yeiS0jNARPjfR9SW83u1LFHcHDg8eOHKMuRObNjk8at2np2ZtrXoGHVpCaNGDGxcqWqDARPoSxc6T48btm6buvWdYlOcsnpunjhGgYgZgbR/f+fASNYulu5cktSkzLa2jH4Gae8ISsTHIVCCAfsDRo0S6q3gpFUxD9hDs0hUBHf/VjFcpcaJ1XnbEgh5WmsArwDACeIzuRWGazoH9M7CqYQ6OWcIH2JLA5xSthw9ZAwb4gm4XDADqB1IotDqusfY8eghxSCPL6Qy3GXWACtE18/BRyf6ifs7w0S2pvAxFgfwnlvkG5oL4nNTXuUXy/CEBhIfzmA30OFdJw+pD0KEfU7Am0SX14O5xXqJ04ixCNj9FMA0D7x5eWE2LsX/pxCLsQDY4VQ7xMLoEeQlwNIhgIdYwC0DXEIhEOALQ8O/WIAtE1kxRYjE6mxGQpEekhqRCSVK1desGABPQ0ODpbJZEzXJFKpkTG2N22RGkmMOSkDgyey31gmB1MF6kP6KPhrrLGp9NSpU7VqKS+k9u7du0qVKi1btoyGP336RGGJ6UKmLMY4UUCbuMwuJgwMnsjiUJEqVlQ3/vwihoF++fw6PFNWU+LmprxXepEiRa5evdqgQQMafv36ddOmTTds2MCU98l+5uPjw9JLjvzmdMz++EoIg7R2ab+/mQUaQ6AkvpxD3qLWZ/d9ZKBHHp4PjQqLa9zbKd54Z2dneqxYsSK1k+rXr0/DFIT69Omzf/9+Gr5+/fqLFy+YlhWtYnfvvD+DtPb2cXD1lg4MQIz9FDw87bPdNNvyvzf5SlqVrpqJoVkvZl9ex9w+7RfkF93jf67Jz2lnp7xZRnWVyMhIGvb39583b16vXr3c3d2PHz/u4OBQvHhxltbK1bFxzmOyaerr3EWtS9XOZILt7c/EhLFrx3zfPAnrMMYlgy3aQ6Akyv5yBUpnCPoU9/Ba0OPrQcr7lP3umScKBfu9y/qrXvd7b8r9Xr1BofjpQuMp7E0sV3CSX12YJuGiUvKq5FcvhSRG9DVKrDMZ95iWK1UvNDdX3kn6bxW+O0NUVNTixYsHDhxYuHDhrVu3uri4VKhQIa1u2pAtj3nlevbXT/m/uh+kfLfkTmH76e+rle1EkaKLDSX8iyS6zSSxhgnf/dfbbbxfU6JvJ5FImURhnsGoQTcnBCFQE2u/7fINbOkfU9a3U9qrSsEp4l/NKtEfV0oiBb8Yxa/mUSQ7Lvk3Uk2dNGlS8+bNCxUqFH/mJF6b3FxJvV2C8ZxqX/eLlY83lvudb0MilVr98R0BpVLl7qyhCj/GwsJi+/btefPmzZw584IFCwoUKFC7dm32Z4q4W9E/Ggj9KtOMQvE/FuW5401mP+b4NnOiO3kuwQsVCd5A46tOfFEc27hhfSa7THXr1VdP+jFLosvkVzjhdsN+GqMMVklsWKofFae5Dfy0bvGWLGU2dgg/EJ/ozx+yyazPm3VI1EfLjAr9/oxprpEKP5wzZ87z589THKIG07Rp06iRRE0o9geshP23iJT5Sy0yYIMBccF5rIK2ZMkSY2NjBr9LHZNMTU3Lly//6tUrGn7//v38+fNr1qxZp04dpl/i4uKMjPCjBpHBJitotPdkkBaoWlK3bl1+OFu2bJTE+/LlCw3fuHFj9erVjRs3ppgkl8slIr+MbmxsLOIQiA7OFRe0Tp06eXt7M0hTFGzc3d1btmxJw6VLl+7WrRu/7z569Gj79u1Pnz5Nw3yXPNFBewjECJusoIWFhfF1eNASaidRKOKHqcGUK1euiIgIGt63b9+OHTuGDh1aqVKlgIAAvte48CEOgRihPSRomzZtypEjB4P04ubmVqpUKRpo06bNwoULHR0daXjXrl21a9e+c+cODX/48IEJGOIQiBHikKCZmZml1UkwkFrZs2fPkycPDfTo0WPLli1OTsrLPezevbty5cr8dRyePHkihIuxakIcAjFCHBK0Jk2a+PvjojK6lylTpixZstDAP//8c+rUKb6dRLm7ihUr+vr60vCVK1d0dTFWTbGxsehgCaKDOCRooaGhOLwVGlNTU2traxoYNWrUtWvXbGxsaPj48ePNmjWjMCCXy48cOfL582emC2gPgRghDgnawYMH+d0cCBbft37ChAknT56kGEB5VApOw4YNo5FBQUE7d+58+/YtSy+IQyBG2GQFjb+QGogFX8ybNGkS/5RClLe3982bN2fMmPH69etz58799ddfuXPnZlqDOARihPaQoFWtWlWhwH3YxIoOI0aMGEFBiKkqTGFhYdTAZaqTZ5cuXfry5UuW1lAfAjHCoZNwUQQKDw9Hfzn9QCWlfv368cN58uR58OABtZNo4NChQ48ePWrevHmatJPQHgIxwiYrXBSBzp8/z0DvZMyYsUuXLvxw5cqVIyMjqYZEcWjNmjVv3rzp2rWri4sL+y2IQyBG2GQFDfUhvWdra9uiRQt+mAYuXLgQGBhIccjLyysoKGjIkCFZs2ZN+dIQh0CMUB8SrtDQUP5m2GAgrKys6taty99VdujQoQ0bNqR6Dw337Nmzd+/eFJ9oOCYmJpklIA6BGGGTFS7ap0RHRzMwSNQUdnd354eXLl16+/ZtvseKp6enmZnZ6tWrTU1NE174jrYZ9FMA0UEcEi6qIhw+fJiBwZNKpWXKlOGHd+3a9fTpU/7+FO3ataMm1Pbt2+l4xdfXN3v27GgPgRhhkxU0ExMTBvCzAgUK8ANHjhzx8fFhqmbQgAEDbGxsaIDSuZ8+fVLPAyB8qA8J1/v371u3bs0AkpYtWzZ6tLS03Lt374IFCygOyeXyKVOm9O/fn8a/ffv21q1bNIYBCBjaQ8KVfEUaIB5qD8XGxlJk2rRpE9/BgSLQypUrnZycJk6ceP/+/cDAwPLly+MmvyA0iEPC5erqunHjRgaQMgqFggIPf+NEvrdCrly5VqxYwU81Nzdfv3798+fPu3fvfu7cufDwcHd3d2pIMQBdQxwSLo7j0PcJUi75Tgp58+adM2cOP+zg4LBt2zaKW/Xq1du1axcN1K1bFzEJdCVt6kO09afqbDtIiUePHlGinwGkDMUh/mayv+Tm5jZp0iQKQvywt7f3kydPGICOpE0coh/Ax48fGaQpSvG/efOGAaSMmZnZtWvXWCoVKlRoxIgR1CTavXs3A9AF9JcTrmLFii1btowBpAwlck1MTH7v3OfVq1f/9kXtAP4QYVreZgAAEABJREFU6kPChfoQpJa5uXlUVFRqe8RRPmPgwIE45Qh0Be0h4bp//37v3r0ZQIpRao7iEEslqu8iCIEOIQ4Jl1wu588CAUghikORkZEslfr37+/t7c0AdAR5OeFCfQhSi/JyqY1DFIH8/f1dXV0ZgI4gDgkX6kOQWr+Rl6MItGXLFgagO8jLCRfqQ5Bav9Ee8vX1lclkDEB3EIeEC/UhSK3UtocePHgwYsQI/lJAALqCvJxwoT4EqcX32075/BSH2rdvzwB0CnFIuFAfgtRKbX85T09PBqBryMsJF+pDkFqpyst9/fr11q1bDEDXEIeEC/UhSK1U9VNYuHChr68vA9A1xCHhQn0IUitV7aEsWbLUqVOHAega4pBwoT4EqZWq9lDfvn1pG2MAuoY4JFyoD0Fqpby/3J49e169esUABABxSLhQH4LUSj4v17x5c34gPDycikO5c+dmAAKAftvChfoQpBAFmODgYJlMRkk5Onb577//KOFGMenSpUuas9GkkiVLUrLX1tZ29erVDEAY0B4SLtSHIIU8PDwCAgJCQkL4BrREIlEoFAkvXWphYUGPFK78/f1btGhRtmzZ2rVrMwBdQxwSLtSHIIU6d+4c726q1Bhq0qRJvNmcnZ3VHRMoVlHiNyYmZvTo0QxApxCHhAv1IUghijrUvjExMVGPoZBTr169eLNlyZKF2knqp+bm5o0aNZo2bRoD0CnEIeFCfQhSrk2bNjlz5uSHqdFDmbqEdwfPli0bNYP4YSsrq8aNGw8cOJAB6BrikHChPgSp0r17d4ouNJA1a1aKMQlnsLe3t7S0pAFra2tqPw0ZMoQBCADikHChPgSpUq1aNTc3NxooW7aso6NjwhlopIWFRebMmZs2bdqnTx8GIAzoty1cqA+Jzuntft4PQmOj5bI4OT+GqjHqKxaoh6lG8727AKdgih8zKKgNrPg+M82iSLiQeJPiPS1oOsitsoLz4xYPesESWaxZ3QILlYt6+WOGH2v182I1F55gBVhSl2GQGkmMjCVZ81jW6+LAAFIGcUi4UB8SlxMbfd89j8hdzDZ/cWvF9xvLUZCRyFWhRrXn5uTKAfn3/Tg9qod/POFUe3rFj5mUcev7LJpT+OcKVZxJZOr3MfFG0TrIuZ8DCfd9np/DkHKNOMYpEnzUBHOqSTjJm4fBz26F7Fr4ofkAZwaQAohDwoX6kIhsn+sTFSRvOTQnM3iFq9jSvwNLP26c8q792BwM4FdQHxIu1IfE4uOrmIDP0U2HZGfwXcM+WaPCZbdOBjOAX0EcEi7Uh8Ti+lE/S2u0XOOzsjd5cSeUAfwK4pBwoT4kFhFhMhMz/JTiM7OWRITGMIBfQX1IuFAfEovoSJlEKmfws7goeSzCEKQADuKEC/UhADAEaA8JF+pDIGocxzgc6EIKIA4JF+pDYsFJscNNFKd5WVWApCAOCRfqQ2KhkDHsbhNSnmCb5IUXAH7AUZxwoT4kGpz6Oj0AkGpoDwkX6kNiQUk5HPgnCmk5SAm0h4QL9SHRkNP+Fnvc+JThWYLwDL+G9pBwoT4kFlQHwYF/Qgo5/cP3Ar+G9pBwoT4EokYHUuhGCCmB9pBwoT4kFlIpk0gZAPwexCHhQn1ILGTot50o1IYgZRCHhAv1IbGg7BPq8YlQaN5sFiBJSN8KF+pDYoHeckni8MXAryEOCRfqQ6Kh0JMTZSZNHnnkv/0sjSjDM65CDimAOCRcqA+JhkRPri/37NljlnYkuM4ppAzqQ8KF+pBYKGsgqWwPBQYGTP/f+EeP7+fInrNRoxYfPry7cPHM+rW7aFJcXNzqNUuvXrvo6/u5cOHiTRq1LF++Mo1//fpVl26tli5Zv2XL2ouXzmbO7FCtaq0e3ftLpcq+egEB/kuXzX346F5UVFSZMhU6tOuWPbsLjd+9Z9uWrWsHDRw1YeLwxo1b9u87lJZz4OCu23dufP78MaeLa926jRs1bE5zVvMoTY+zZnstWz7v4P6zNHz02MEDB3e/fv0yV6481avVata0DZea6xdRbUiO86ogBXC4IlyoD4mF8oTNVO5vZ86e/O79m1kzl07xmnvt2iX6J5F8+zEuXDRz1+4tTRq32rL5oHsVjwmThp87f4rG8wclc+ZO8fCoc/zolTGjpuzYuenM2RNM2WFPNmhIz7v3bg0aOHrNv9sz2tr16dvR5+MHmmRiYhIREX7gwK5RIydTSKMxS5bOuXHjyj8DRvxv+kIKQgsWzrh67RKNP3pE+Ths6Dg+CJ08dXTGzEn58hbYsulAt659aZUWL53DUoO+Fg79FCAFEIeEC/Uh0Ujl1eWCg4OuXr3YskX7gm6FM2WyHzJ4LDVN+EnR0dHHjh/ybNOpYYNmNtY2df9u5FG9zoaNq9Svda9So6p7DYpJxYqVzOqU7fnzJzTywYO77969GT3Kq1zZinZ2mXr3GmhtY7t79xamalVTC6l16441POo4O+egMePGTZ81a2nJEmVKFC9NLaH8+dyu37iccCWPHNlXtGiJgf+MzJjRjmbu3LHXvn07goICWYrhPFZIobTZTGh7s7KyYpCmUB8SC+XeNjUJq1feL+ixcOFi/NMMGTKULFmWH6a4EhMTU6Z0BfXMxYuV8vZ+GRwSzD/Nl89NPSlDBquwsFAaePDwLkUmihbf1ofj6FX37t9Wz1kgf6Efb69Q7NmzrUOnZpSIo39Pnz0OCgyIt4Z0DEQpPs3VKFGiDI2kN2IppiDopwApkDb1IdreQkNDGaQp1IfEQrm3NUpFYi40NIQeLS0zqMdYW9vwA3xc6f9P13gvCQzwNzJS/lrV6TtN9CpqOvMFHjVb24zqYcrO8QMUS0aO/ic2NqZ7t37Fi5e2ymCV8L0IxUJaIJWp6N9Pq5EgYgH8OfRTEC6qDy1TYSB4qTrwNzU1o8fYmBj1mMCgb/v3TPaZ6XHI4DHZsmXXfImDQ5aAAL+kFkjJPXNz86lT5mmOlCZ2raHnL54+ffpo9qylpb63wCiGZbZ3iDebmZmZhYVFrZr1qlTx0ByfLWt2lmIcp8DpvZASiEPChfqQiKRqf8v3ZHv95lXOnK5MGQnCbt++7ujoRMPO2XKYmprSABVv+JmpCUL5BooKAUk3RXLnzhcZGUmxKltWZ37Mx08+tjYZE85JpSl6VAeeN2+86V+unLkTXWZoWKh6NWhT/PTJJ3NmB5ZiCgWHy21DSqCMKFyoD4lGKq+nQNHCxSXX+g0rfT5+oCA0f8F0J6ds/CSKN5069tywcdWDB3cpOXbu/Kmhw/vMX/C/5BdIjZuyZSvOnu315ctnijT79u/s1bv90aMHEs6Z08WV8nvbd2wMCQ159+7NosWzypQu//nLJ6ZspZlSmLl58+qduzfj4uK6d+136dLZI//tV5aFHtyd7DVq8NBeMRptOIC0gvaQcKE+JBrK+4KnLgM1fOj42XOntO/QJLdr3po161Kt6MmTh/yk1q06UFtky7Z11Eii8YUKFh0yZOwvFzh96vwDB3dPnjLq8eMH1N6qUePvpk1bJ5zN0THLmNFTKAQ2alydUn9jRnn5B/iNGz+0Y+fm69fuauvZZe265ddvXN665VCRIsVXLt+8ecvaFSsXRkVF0mpM8ZrLt9UA0hanSIsTza5cubJly5ZFixYxSDuoD4nF2kmvpVJJk/4uKX8JtVqioqIoKvBPR40ZaCQ18po8m+mRoxt8Anyie/7PlQEkC3k54UJ9SCyUd79OZUF+0uSRgwb3uHDxDAWkjZtW37p1raHqogb6hFNmK9FRAX4NeTnhQn1INBSpvq7PhAkzZs2evOrfxV+/fnHJkWvCuP9RnYbpF45JOFxvG1IAcUi4UB8Sk1Qe99tY20yZnLrL5IiO8irkCEOQAsjLCReuLycWygsHYIcL8LvQHhIu1IfEQnkhNRRCEqCsnFTKAH4JcUi4UB8SFTSI4pMrFDIZA/glxCHhQn1ILJCUSxyH+4JDiqA+JFyoD4kJ9rcJKVT3wgP4FcQh4UJ9SDwU2N8mxEmYRIrvBX4NeTnhQn1ILDgJ/YcdbnwKOZPL0E6EX0N7SLhQHxILhYwar9jhJkImk02bNu3Tp08MIGmIQ8KF+pBooNd2EqRSaYECBa5du0bD58+ff/v2LQNIAHFIuFAfEgupEZOY4qcUHwUhIyOuadOmjRs3pqdGRkZDhgyhoysaDg8PZwDfoT4kXKgPiYWZhUlsDPJy8SliFabmP/YwFVX4CNS3b18bG5u5c+dKcaYroD0kZKgPiYVrEcvwYNwgLr5A/2jHnGbxRlpaWtLjunXrWrZsSdWj4ODgyZMnP3r0iIEBQxwSLtSHxKJ0DRsjY8n5XV8ZfPfwUrgsjtVsmzmpGSpVqmRiYkKtouLFix86dIjGeHt7v3z5koHhQRwSLtSHRKTLJJcvbyP+W42OYUpnt3+9f863x7ScKZm5YcOGI0aMoAFq/Y8dO3bDhg00HBERwcBg4H6swkV/mri4OKTmRGTjtHehgbESKSdLrFzESZSn1PxMwZQnHik0rzvwbTZOYyQ/i8bNJfh5FJzyP34G7tvlhb7NFW8h8Z9yP2bmOP72Sd8WpbmS34cV399AuU1+u6YrLUr+fXUkcib/dkQrMVX2YrfMYNxxfA72W/z8/Ozt7VetWnX37l0KS05OTgz0HfopCBfqQ6JTqXVc5869JvRbaWZmnXAqxaf453Vy/H8KzfgkkUioKczv97+PUsUNjZdyEk4hVzCNmWgW5Yhv/1MHnm/Tg0NCHty7X7nKX3z8+TYX9z1sqV7B/0/CcXKaR/WMkyqDyo/ZeApV7NJYZ5ptx7ZdNCCVSDipLFryxtbM9N9/c9ja2jZvnuqbzFIQosfu3btfv349MDCQ4tDy5cuLFClCeTwGegpxSLioPrRMhYHgPXz4sHDhwgEBAUeO7ONL8QJjP2dtjx6jq1JsYFrgJ8s2e/bs8PBwajBREJVKpfRI3wPlSM6dO8d+S9myZfmBokWLbt++3c3NjYpJz58/pwEG+gVxSLhQHxKLCRMmUCOG4lDp0qWZUG3btk17zesGDRocOXKEWjCc8p5Dyq7Y9IVQWLp9+zb7Y3yHbz7CTZs2zc7ObsGCBTExMSYmJgz0AvopCBfOHxI4qt49efKEBurWrUuhiAkb5bu02lAbNGiQg4OD5hhHR0eWdvgIt3HjxuHDh9PTx48f9+jRI03iHOgc4pBwoT4kZC9fvqxcuXKGDBlouFy5ckzwQkNDmzZtyrQmX758Hh4e6qe09c6YMUMb3d6yZctGj8WLF+/Vq9fnz59p+OTJk2fPnmUgWohDwoXzh4Tp4sWL9BgdHX316tXs2bMzkbCysqKoSc0IpjWDBw/mu7dRAu3GjRtZs2atU6fOu3fvmHaULFmSWqI04OrqeujQof/++4+pTkJiIDaIQ8KF+pAA0a6WqiA0UKhQISY2GzZsKFiwINMaqgl1797dzMzM2lrZXZAygefPn6d2GA1r9QtlFBkAABAASURBVJLbFIdmz55dq1YtGt61a1ejRo2Cg4MZiAfOHxIunD8kHH5+fm/fvi1VqtSzZ8/y58/PxEkmk0VGRvK5RO3x9PSkvUG8ka1bt+7cuXPt2rWZ9vn4+FDjj2Jht27dGjduXL9+fQbChvaQcKE+JBBPnjxp164dn3ESbxBiqgtg005Z29e6ThiEmKq3Hh1U0QBf0dEqKiDxDbKBAwe+f/+eBugY4sSJEwyECnFIuFAf0rkjR47Qo4mJydGjR6nawcSPclb37t1julCvXj16pG+ScmgsXRQuXJj/BWXMmPH06dPjxo2j4S9fvjAQGMQh4UJ9SLf69OnD19hz587N9MWgQYMqVqzIdKdTp07Ozs4BAQFhYWEsvVDzaPr06RMnTmSqw7u6devyt0ECgUB9SLhQH9KJly9f+vr60s6aMkhZsmRh+oWObLy9vXWeXaRtm2L8ihUrpkyZIpGk99Ew/X0pEBYoUGDOnDn0J6baFW6DpFtoDwkX6kPpjw6Tx44dmzdvXhrWvyDEVNe0njBhwqtXr5hO0bbt4uJStWrVzZs3s3Tn4OBAQYgGWrVqRTHpzZs3THUSEgMdQRwSLtSH0hO/Q8yUKRNV1DNnzsz0l6enJ9XtmQDUqlWrffv2THVhpMDAQJbuKENIiUo+73r9+vVq1aox3HJCFxCHhAv1oXTTsWNH5SWuv5+rr98aNmxYvXp1JiQtW7YcPXo00ylagTNnztBAcHBwzZo19+/fzyC9oD4kXKgPadutW7eCgoI8PDzoENjCwoIZjCNHjtSpUyf9CzO/tHfv3sKFC/N5UR2ixhllI9zd3U+cOOHj49OiRQtBXkNdf6A9JFyoD2kV7WhWrlzJXyHboIIQU9VC+KsTCQ1VjMaPH6/zrtUZM2akIMRUVw4MCwvjrxhERy3IT2gJ4pBwoT6kJUuWLKFHJyenFStW2NjYMMOjzkMKDQWArVu3GhkZ+fn58ddP0i1ra+t+/frxd/OjolqVKlX4Tg2QthCHhAv1IW1o164dXwTS784IyStWrBi1PJhQZcqUyc7Obv369fx5xALRtGlTKkBQpGSqgtaMGTMYpBHEIeHC/YfS0KlTp/jK86ZNmxo3bswMHn0PVBtjQkW1K2q2uri40PDNmzeZYPAN6LVr17q6ujLVqUirVq2i1huDP4A4JFyoD6WVO3fuHD9+nL8eM/A+f/589OhRJmz8Rc0fPHig89508VhaWrZo0YKpmm6Ut5g/fz5TJe7S8yIR+gRxSLhQH/pDISEhkydPZqr7AlAWxdzcnMF37du3z5EjBxODzp07N2zYkAYEWJuRSqU9e/acMmUKDYeHh9evX5/v1ACpgjgkXKgP/SE6iK5UqRL7nksBTY6Ojrq90FyqlC9fnh6ptdGpU6fIyEgmSAULFjx79qybmxsNT58+3cvLi46EGKQAzh8SLpw/9Hv27NkTHR3dpk0bBslas2YNxWlx3cni4cOHERERZcuWZcImk8kOHTqUJ08eSi3SvpHiKF9PgkQZMRAqndeHhNm1N3lUS6A0fb9+/VK18gI8o/OXFCrsD1hZWZ0+fVobJ41yKkwLChcuzA80atRo4cKFfEcGAaJ8Ha0hP0wJ4ZEjR27cuJGpLhrE97gDTWgPCRfVh5apMF2gDcPf35+JBB1+UtKG8m+02qndAxoZGdna2jKxobbyH3Z4o++Kvjf6+CytmZqaUpBj2uTj47N371464GAiQQdGMTExDRo0qF279tChQxloQH1IuFAfSjkqEfPdELR0GK6X6LvSRhBKH9myZeODEFVizp8/zwSP2txmZmYnTpzg+22eO3du/PjxArngrM4hDgkXzh/6pQgVpjrv3cTEhEEq0bdHtTQmZkOGDNm/fz81NdIktZMOihYtSo/u7u5UNOJPjaKY9OzZM2bAEIeEC+cPJY8ai7TrMbRLw6Utag+JPQ7R8cecOXOoHkP79AMHDjDxqFu3brNmzWggQ4YMXl5e165do+GAgABmeBCHhAvnDyVKXRehII2rIP8h2onTTpCJH8WhMmXK3Lt37+zZs0xsSpUqtWnTJr4LxuTJk3v27Cn2g4PUQhwSLtSH4uETL1FRUYnuOi9fvtynT586deo8fvw4mYW0atVqy5YtDL5Lqq/g69evx44dW79+/W3btiXz8qlTp44aNYoJw7hx4woWLEgDO3fuZGLDH1TNnz+/R48edLBFmcaRI0feunWLGQDEIeHSj/oQpUpmz57N/lhYWBhFIKZKYiRaXed3PTNmzBBsX15hUtfY4qGGxcOHDykU8XcpFQsHBwem6rcitEsBpRw1jygmUVO1Ro0ax48fZ6orBj148IDpL5w/JFz6UR968eIF+2PULqTES/IX5qGdaZEiRSh4M0gN2t9RjE9YZqNduaOjI38hA9Hp1KmTj48PU7WSRXTZiHhqqNCAmZnZxIkTy5YtS4n6kJAQa2trpl8Qh4RLt+cPJUQZGAqN1atXp7JwZGRkgQIFunXrRo/81CtXrlCO+/379/QjyZ07d9++fenIdNiwYfxx3MmTJxcvXpwnTx7NBTZu3Lht27b89SLJ3Llzvb29aTYavn79+q5du549e2Zra0vRpUuXLnZ2dkxVxV25ciVl3iiBToeNnp6ezs7OlMSg9BFTHTYeOnSIlsOnkviLy5ETJ07QOu/Zs0e/OzWMHz+eJfGp6e+yYcMG+ltQbtPNza158+Z8NYK+uvXr19O37evrW6hQoYYNG/KXKhgyZMijR49ogPKctE+ng4DNmzfv27ePXzLN3KFDhwkTJlSoUIEJFX93D2pY1KxZkxrlor66IB0QrF27lu/CQFv4qVOn6G+tT+1+5OWES2j1IcqGPXnyhH4DCxcupF2SqampOuF2+/ZtLy8vOnbbuHEj5UNoP8WHk1mzZlGgovFHjx6NF4SS8fLlS/qZFS9enN6ISj4UnGh/ylQnq44YMYLCc//+/Sk8U4j6559/Pn78SCtGy6efJUUjGuArBKBGlYbhw4dTLJkyZcr06dPp66KDaz7JuXTp0r179zZo0GDdunV//fUXzXDhwgUaT184fZn0ldL32bp1ayZa1D7esWMHtSH04NYM/KEYHXsNGDCAv3Id/QpOnz7NxA9xSLgEWB+iZtCgQYOcnJxoX1a1atUPHz7wpQU61q5UqVKTJk1sbGwoDFChlQ6xnz9/zn4L1WYpyNHuj/aD5cqVo11ny5YtaTwdodNxPe1Sy5QpQ7/J7t27U9tLfZAOSaE/U2BgILU+6VDA1dWVDhSonk9BndqU1E6l75ZaDNTSrV27Nv1N9a8TR8aMGak9Qe0h2mz04zQd2jNQkoAGKOV47NgxPgNJx4JMtNImDtEBF98KhjREuwZKmzAhyZ49uzq1xXda42+48vr1a83LZebLl48ef+83Tx+ZfmO0i6QmEeWU6DdGsY2v+lAcooIZtZP4Oen7KVq0qH7Xb9ME/Tap7UhNHEpX0ncokUjo+6SEFZXu6JdL6U0qEfF9Een7pD+lXl4lmj7vjRs33r17x/QI/R1nzJiRNWtWGl61ahXlCfhmruikTX3I3d2dojEdSVGbkUEaoUoMHewLKq+daB9fKmhT2KAWjHoMv86J9sJKCr8Qpsr+UYuKsnwXL15cs2YNVYNKlCjRrl07ql5QzKNEJVUsNF8oxkvDpTP601CClDJslIKj/Bs1Z+n79PDwoO+cqUpB8eanxpP+VcJ5tKcSdc+FRPHXsqLcCRWQzMzMmAilWT8FStdQ3fLw4cP16tVj8MeOHDlCQUgUuwM+AmkeiPERiE9nJ4+yQ3RITsfjxirq8WVUqBhOxzf0PdCmRcfytED6mU2aNElzCVT2+OW7iPHC4X9O81NTQ5bSmO3bt7979+7x48cpLFHOM1OmTDSJamx0QE1/CPU3mTlz5uSXTDMzcQoNDaXth3JZTB/RURplzsXYIyMt60P0B6Z0M1/nhD9BB6q1atUSyzEptWDy5s375MkT9Rj+TNJcuXIl/0IKPLRf4E8GolBEZQx+/P379ymFwlQ3XabSRa9evagl9OXLF6ptULSjvWSx7xwcHBK9rQstTbM1pl6yfkvqU1NRjd/zUhQvX778mDFj6DunpByFH/4Ygr7JHDlyUFKOHjVTr2r0l6LWqjpLTAtk4kSfV88aQ5qmTp16584dJkJp3E9h3rx5a9eupf0Ig99Fx/5nz54V14WQGzZsSOkOarhQXLl37x4l06iKw3eQo53d06dP6TCcsj38zLSv5CsQbm5uFG/422tu3bpV3aOJwhj9oqhFGBQURK/dv38/BSQqNVOCrnTp0vPnz/f19Q0ODj548OCAAQNOnDiRcH2oWPX8+XMqdTBV/ZbWjRmApD41fdv0w6T6ARXbKDht376dIgolPyneUIJu8+bNDx8+pPoQJUJHjx69ZMmShEumvxTNwH/V9OXTEpg4UVGTfl9MT9FvRKRnJqT9zo5y+s2aNZs7dy5Oa/8NtEdo27YtX+cXkRo1avj7++/atWv58uXURilZsmTnzp35SXXr1qVDb9rBUcmHxvN3b+NvTkMNnQULFtDWQkGXHqtVq8YfzTVt2pQiEC1q4cKFdIxPOf2ZM2fygXny5MmU+50+fTo1v5ydnekl6ruNaWrQoAEds/fr148ySPTy1q1b8z2/9VtSn5pKaxSwN27cuHv3bnpKfwX1VSdatGhBDcodO3bQgQJV8ineUJou4ZIpwlFab/Xq1fT3onm6dOkybNgwsVzfWhMlgW/evKmvTSJq6TJx4rS0MdGOifZKqCGnCiWdaA8ikGt3pu198KgNRO0eKvAI8P5ABnsfvHhLS8MmeDrcB+/30Cbt6empr/Uhyl1TMt/Q60OaqFBEmX0xHjHpyunTpyljoGcXkKbDT3UvOMqt4SZ1gkV5TkPozUEBskqVKkxPoT6UiFOnTnl4eDBIgYCAANpTU7aE6RGKQNQG4nvB4SZ1AifeG7OmCtWHxJu8+iXx1oc4rTZZqChK2Wqc8Z48ysVRuoC/TrBw/HZejmIPNYNsbGzo+DqpewoICvJyaU6weTnaMq9du/bXX38xEBLt7iaokkxNxU6dOjFIAjUaKFEgtCD0G+QqFL0orPL7IFEEIeBRVDOELHpoaOiUKVOYnqL6EN/7VHS0vqcoVKhQjx49Eu2EA+T8+fPnzp1jIhcVFcV3y6YKEKU+EIFEJyQkBPUhsRNvfSg9ksIVK1akKui4ceO8vLwYaPDx8alataowU/MUUX5Z1Pn69Ssdf+XIkYP+vk5OTkycUnJFBgGiYJ+GVTdvb+8SJUqk1QIFe98s1IeEiUu3xvi2bduoXDR06FAGKn369KGMJX+7FzG6e/fu8uXLR48eTXGIAYgB6kPCxKVnUnjFihV0ENe9e3dm8B49epQpU6YsWbIwsdm9e/ehQ4fWrl0bFhbGX3Ib9MCrV6+yZ8+u990acf6QMKVrHr9nz55BQUE7duxghs3Pz4+yWOIKQuH2tUJvAAAQAElEQVTh4Z8/f6aBT58+8be/QxDSJ6NGjTKEq/ChPiRM6V1PHjZs2L179/T1eCQltm7dun79+pRci1o4jh8/Xq9ePf4s1H79+vHXaQZ9kjdvXsEWddIQ6kPCxOmksybty9q1a1e+fHlmYKglRJkBzVvGCRlVgF6+fNm8eXM6dODvRAcgaqgPCZNu+tcuXrx46dKl/N0BDEdkZCRlt8QShKhgQH8mPvwgCOm9169fi/RWnqmC84eESWfneWzYsIFS0vyd1Q0BfdLWrVsL/xrk//33H60nDVAF699//6V0DQMDMHHiRDryYPoO9SFh0uX5hvv372/bti1/c2L9RsnP9+/f0+dlQkWHUfx9a2g9582bRwMiTTTD73F1dRXpLaVTBfUhYeJ0ezEPmUxWsWJFytgyvfbw4UM3NzfBni958eJFapuuX78+0XubAugN1IeEScfXX6FdMyWCatWqxfRXixYtLC0tBRiEKDpSdpQG7OzsLly4gCBkyN6+fat5T3F9hfqQMOn+OmC0E1yxYgXtrJk+ev78+Zo1a3LlysWEhJqhvr6+s2fPLlGiBD0tWLAgA8M2ffp0Q+g3hPqQMAniepS0mx47dmy3bt2YfvH29s6UKZOgLoB//vz55s2bx8XF2djYrFu3rkiRIgxA9RsU43n4qYX6kDBxwrnYO+0iqZI/Z84cphcWLVpE+/oOHTowAYiNjaWgmD9//rVr11avXl343fYAtAH1IWESUBwiBw4cuHv37vjx45nI+fv70xYvkEtQU1O9T58+//77b6FChRhAYt6/f58xY0a9v1YTri8nTMK6T0zDhg2pWj5//nwmZn5+fl+/ftV5EHr06BEV3miAEoNXrlxBEIJkzJs37/bt20zfoT4kTIK7X1m7du2MjY0pfcTE6d69eyNGjChQoADTnejo6IiIiJkzZ5YqVYqe5smThwEkK0eOHIZw4VrUh4RJWHk5tWnTptGuvGnTpkxUqAzz9u1bHe73b9y4QeGHmkFUmhLp7d0AtAf1IWES6P2bR48eTZvLqVOnmLD17NmzZs2a/LBcLr969apOghC9NbXDmOoqYRSH7OzsEIQgVXx8fEJCQpi+w/lDwiTQOERmzJixc+fOmzdvMqGiv7qvr29gYKCHhwc9rVGjhk6uB/ry5cvy5cvHxcXRcMuWLYV2rhKIwtKlS6mIyPQd6kPCJNw4RJYvXz5nzpwXL14wQaImiL+/Pw0EBwe7u7sfPXrU2tqaacHHjx/r168fL5nw6tWrRYsW0QCV065fv86XggB+T/bs2QV1opuWoD4kTAKtD2mqV6/emjVr6CtmAkMN/L179/J3h2OqQ61Lly4xLWjVqhU1emjg1q1bTHVrVEtLy44dO3bt2lWPD+4A0hzqQ8Ik6PYQ7/Dhw82aNYuOjmYC8+TJE3UQYqpeauXKlWNpbfjw4VT14VTo99OmTRu+EbZ+/XoEIUgr1OamZj3Td6gPCZMI4hA5deoUX4MRjqdPnwYEBKifyuVySmukeW1m2bJllLWnhfNPqSU0efLkHDlyMIA0tXr16nPnzjF9h/qQMIkjDtHWs2fPnrp16zLBuH//vp+fH0UIiUSSLVu2atWqUYTYtm0bSzsnTpzYt2+f5gEOvVe/fv0YQFpzdnZGfUjs9LY+9P5Z5Pm9XyNCZDFRykNyBZNzfOji+FdxNIpSU6qFcN/GKzjlID9donoFp3qpQvU/Tvmfak45U0h+WqbyNZxqaYyTMIX8xxL4kcp3U+33VcPKBdJ4Ofu+QKZaE6axAurVIFLGZD/G/FiNb69STfnxTahGfJ+ZU35J3E/fmoSTy2TflkRPvr/g23p+X4Tk+9Pv479/S2r89xOPaoRCRXO0QkFfhPKLknA/jh6MTTgjU0kWF/O6XQRXPwMQGtSHhCm5OPT8ZviZXV/sHEwdclooZDLlKNqzylU7VI7feyt3rcqYwb6NZ1KO0f6Z+xZ1+KfKWemZKq7QTlvBz/l9UeoBdbBRhhIJx30bqQoCqrDEB49vIYrj31q1/t8/AU2Sq95cGdfkP3b/P9bk+7v/WA2mWpTybdiPr4L7Fjf5aMtR5PueGfv+RsqgoJ5TPfDzYlWR7Ntn5NdHIy7ys0g5hUyR8G+ifGdFgvn5UPozqYk0PFD26W0ErVCXiTkZQGrUqVPn69ev1KznC5D80Q8lfoV87+A/gevLCZNRUhNObf366n6Y5yjcG00czu/0XTXmdfepOHkIUoHyydu3b1ef9UyhiPINzZs3Z3pK7+tDrVu3rlixIhObJOtDz26HtBmGnZpoVGnhYGFltGOuDwNIMdptUWVIc4yLi4u+3pSSoT4kVInHoWPrvphZSBkuDSMqxf6yD/wiuN7tIGQUddzd3dVPjYyM6tWrZ2ZmxvQU1YcuXLjA9BSF2OLFizMRSjwOBfnHmlkaMRAVFzdzWZycAaSGZpOIBvS4McRw/pBQJR6HoiLioiPjGIiLlMkRhiCVsmXL5uHhwfdToMaQpaUl0184f0iY0OjRK0K/RhOkhZd3I3zfR0RHKWSxCY474vWx5E8KSGyzUHcHJa5WjWoVzyyXyx1Z5ZNbviS1TL5XqepUjV+c72FsIjUxN7LPapy3hLCiGupDwoQ4pF8Ef7VA+D2vH0ZcPxYQ+DU6LlZ5+sG3+JKgH3+8OKR5nlxyOOZkVVr1LrFMEcuSWKbi+6mACc9AiDdGaqw8GUIukx/bxIyMORt747I1M+UupvtdpH6fPyTeEJt4HJJIUrDtgvBoXu8O9MOdsyG3TvpHRcpMzU1ss9pkcc0opg5EMvblVVCwb9jRDZ+MTCXlamYsXs2W6Q5fH8L5Q0KTeBySyxWoNIgRWkN6Zu3EN5ERcmt7yzyV7JkYSZljPlv6R4MfHvhdOux/53xw5wkuTEdw/pAwJd5PgZPgyFqU8DfTG28fRy0d+ooZmRas5uJcRJxB6Gf0KQp55GRGJvS5KM3IdAH1IWFK4jxWufJqZgzEBu0h/RASIDu8xse1bLZcpRyYfslV0sG1rPORdZ9DA2Qs3eH8IWGSJDUaJSIAnXh4KWTj1NcFPXKaWRkzfWRmZVTIw2X91NcPL4Wy9IXzh4Qp8ThEbSHUh8QIxw5iF/RFdm7P10I19P+SWoVr5Dq3xzf4a7ruaHD+kDCJ4/5DkELCv8s7JG/b3LeO+fShGpQSTvntt8x6zdIR6kPClHgcoqQc8nJihN4lorZj3gepidQ+RwZmGOyyZzA2M9k++wNLL6gPCVMSeTlUvMUJfzXxigxjXz9E563ozAxJngpZv36Kos+ePkJRHxKkpOpDih/3cwPxQGtIvPYte29qqZ8dE5JnZmW6b/l7li5QHxKmZM4fEm4c2rDx3+Yt69SqU4HBzxRoEYlWoG9M1vyZmFDtPjhz1qI2TAuy5bcP/BzD0gXqQ8KUZH85hSJ1x9Z79+2YPmMC077o6Oi165aXLl1+5v8WM/gZhxaRON04Hkh/PQs7vb3xTzLMbU04CXf1SCDTPtSHhCnN+ss9e/aYpYvISOWZ2OXKVipevBQD0AveD8KMzQz3osP02d88To8aEepDwpR4HJIacfSPpdigwT2PHT90/Pjhah6ln794unvPtmYtal+8dNajZtlFS2bTDFeuXJg6bWyrNvX+rld58JBed+7e5F/4+vUresmTp4/GjR9KAy1b1122fL5MpjzRWqFQ7Nq9pXsPzzp1K/Xs1W7Vv4tp/I2bV5s0q0lTJ3uNUuflKE3Xtn3j2n9XbN+x6Zy5U+XfT31q1MRj9+6t/wzqTksOCQ2ZNHkkverEiSP0QloNWufg4KD1G1ZVr1GmcdMa9L4p6fR86vSxdu0b0wL79Ov06fNHGjh56iiNHzVmIP1Tz3bs2CGaFBHx7eIlR48dpPnpTemRPpT6jSZMHE6rtGLlQpp53fqV9Pjw4T31Ql6+fE5jrl69yFIMWTmRCgmIozIJ05obtw8tXNF11GR3ejx/eeuPLXB67cvXd584u3rY+Apjp1TfuH10SIgfPyk6OmLN5qGjvaouWtnt5p0jTJtMM5iEBqbHDc9QHxKmxOOQLE5B/1iKzZu7ws2tcK1a9c6cupkvbwETE5OIiPADB3aNGjm5SaOWUVFRU6ePpXzayBGTpk2dnyNHzjFjBwUE+NMLjY2Vhdk5c6d4eNQ5fvTKmFFTduzcdObsCRq5Z8+2TZvXNG/muW3LoQYNmh0+sm/b9g1lSpffu1s5dfy46TQ/DVCObt/+Hb17Dty181jXLn3Onjuxc9dmfq1o4YeO7M2TJ/+smUsszC2MjIwePrpH/3Zu/2/50o00QCFKLpcdOnBuwvj/0fteu3Yp+Y/57t0biqa0qvv3ne7Sufe06eOY6lbKyb+KAtWMmZPoa9my6UC3rn0pDi1eOke9ht6vX9K/qV5zGzdq4eiY5eSp/9QvPHf+pI2NbZkyqSiDISsnUnGxcksbbSXlbt87tn2vl3PW/KMH7/27Zu/zl7ftPzKPnySVGp+9uInjJJNHHR8+YMfrt/eOnVnFT9qxb6qf//uenRZ3bDPjs6/30+eXmNZY2pjHxqTHQRTqQ8KU+D6U4/7oTBR6LcWe1q07lixRhh/z78pt5ubmtFelYbcChfcf2PXg4V33Kh78VPcqNaq616CBYsVKZnXK9vz5kxoede7dv50/f8HatevT+Pr1mpQoUSYyIv61EUPDQrduW9+716DKlavSU1qIt/eLTZtXN23SmnbxtBrW1jb9+w5Vz0/Z4X59h9IkWhPXXHniZHGdO/Wi8SWKl7a1zfjK+0X58pWT+VzU5qPZOrTvLpVKS5cqF+Dvp9l8ScqRI/uKFi0x8J+RNJwxo13njr1mzp7czrMLDdMafv78kYKimZlyH9SgfrPt2zf07zeMlk9PKR7XrlWfH04h9FMQKZlMYWJhwrTj+q39ri4lmjYYTsNWGexqe/TYsXeKh3snGqYx9nbONdw704C5uVX+POU/+Dyl4eCQr/cenmzVZJxL9sL0tH7tfo+farGsYmJlwmdBtA33HxKmJPrLcWlwQmSB/IXUw9Q8WrR4VvOWdSjRROkpGhMU9KMsmS+fm3o4QwarsDDlVacKFy5269a1mbMmU1IrOCQ4W1bnPHnyxXuL9+/fxsbGUlNMc1FhYWE+Pt+6gebPV1Bz/mzZsvMtMGJuYZHTxVU9ydLCkn/fZLx8+YxCozowFCpcjP3qEgaUJKSGV5nSP9o0FFBp5P0H35rPLjly8UGI1KvbOCw8jG+WeXu/pE9R9+9GLDXQT0GslBuRVq5wQxvb63f38+Utpx6T17W0QiF//eYu/9Q5249fn7m5dVS0sk4TEOhDj44OPy4vlF1jtjQnlXLps+nSzmHbtm1MT23YsOHFixdMhLR4/yHKzvEDX758/mdQt5Ilyo4bM61gwSIU4mrWLq85p0SSSDikjJyFheWly+coqUW5r6pVa/bsPsDePrPmPAEByly2memPhIa5ubJZizo/cwAAEABJREFUyvdl0FyHRN8o0fdNBsVOimQ/3svs1/ebouMvipSr1yylf5rjAwMDvq2h6Y+qADW2KlV0P3X6aMWKVSgpR6k8Fxf9v84YKCmYXKaVOBQXFyOTxR49uZz+aY4PDQ/4PphIAAiPCKZHU5MfSR4TEy3eXS0uOj2KQ0y1Q8iaNSvTUzdv3syTJ0/evHmZ2CRxP1YjjsnSLMNDNRvaHVNxiL9RoGZLKBkUJCgdR//evPG+ffv6ug0rw8PDpk2ZpzmPpaXyCiiRUT+6iFDDix7t7LRyhS4rK+vomOgf7xWZ5D1UZPJvSQZq61DGtlbNelW+JyF5WZ0SP22emkSTvEaGhIZcvHS27t+NWSohKydS9IuLDI6xdkz75L6JiRmFk1LF6xYtVF1zfCa7bMm8ytLChh5jYqPUY6Kiw5nWhAdFsXSh3/WhDh065MyZk4lQEu2huLS8H2tISDDtwdV3qz13/lRKXnXs2CFKsuXKlTtnTlf6R6Wgw0f2xpsnd+58lCV79OieW4FvOcAnTx5aZbDKnFkrd23JkiXrteuXKNHBN6Tu3bulnmRibBIU/CO+UsJQcyVp5akExT+l5tGnTz4ODo6JvkW5cpWopkVVordvX1ORjKUSsnIiZWIqiQjR1r44q1O+yKjQPK7fznOIi4v1D/SxtXFM5iUZbZWNhjfv7vPpOHrJi1fXLS0zMu2ICokxz5AedzvX7/pQ6dKlmTgldT2FVBeIKGFFMeD2nRvqjJOaq2tef3+/Awd3x8XFXbt+mRo3Nja2vr6fk18gpafGTxx2+fJ5Kg5dvXrxwsXThQsVizePtZV1zRp1N21eQ7NRG+L48cN7921v3rxtahNuKeTuXsPP7+vSZfPog9Aq7di5ST2JalRPnz6iog4N37x1jVoz6kndu/a7dOnskf/2UwB78ODuZK9Rg4f2ot9Dom9BX/vfdRru3rO1YoUqfLcOMASZnEyjw7R1TYG6NXs/fHLu2q0DylrR27ubdoxZsbYv5euSeYmtjUPOHMWOnV7p+5VKsNGbd45j2ryEblRYtG3m9LimkX6fPyTe+lAS+2tFqq902qBeU9qHDhve95V3/C/Co3rt9u26bti4ispCu3dvGdB/OAWPLVvXzZ03LZkFDhk8NqeL65hxgxs38Zg1x4sKJ4MHJdKg7ttnCE3ymjq6WfNam7eu9WzT2bNNJ6YdZUqX79ljwJUr5+mDTJ02lu9rx2vcqKVH9To9erWt5lH6v//2t/Pswr53YShSpPjK5Zvv37/TpFnNocP7UHZxitdcU9MkTxapWNE9OjqaUnks9ZCXE6lyte3j4rTVYSyXS/FBvTe8fnN34ow6K9b1j4wK69x2lrHxL05XatNsQg7nQvOXdRgzpZqFuXXZkg2Z1u4qIouVlaqRmWmffp8/RPWhr1+/MhHiEu3utd7rDeXlmg/MySBpVOii0DJ+3PRqVWuytLNt+4YDB3Zt2rjvN1p16ye+7DcvDwMRWjbCO6OTdZb82sp9CdaXl0GBH4J6zcjN4M9QHKL6kL29+O5fleT9hzjcfyjd3b17i9J36zes/OefkVpKLYJg5SpoEfApve+TLQSBPiG5CqbTLZf0+/pyVB8SYxBiSfVTUKgwwzNqzMCHD+4mOqlu3ca9ew1k2jR8ZD+pVNq1S59yZSuy34K8nHjV6Zhl6VDvgPfhdtktE51h1/7/3X14ItFJMlmcVJr4b7l10/GF3dxZGjl9fv3pCxsSnWRumiEyOvFrxLVvOTV/3vKJTgr4ECqLk9XumFyniTTE14eOHTvG9BHVhypUqKA//bY5ZXPIENtDI0dMiouNTXSSqWn8y67Y2mY8c+omSzv8lYr+BNqwolayWsbbZ74mFYfq1e5Xq1q3RCfFymKMpYlfjsHcwpqlnUrlWpQunnjlMi4uxsgo1evw6Zl/cff0S0XqfX1Ir84fSpPzWMXIxtqGAehI+XoZn90J9b7yybWCU8Kp5mYZ6B/TKVNTC/rH0oj3tY9WtkaVGqTfXZdw/pAwJX29bSmOrcUHeTmx6zg2R3RU9Mcn/kzf+TwJio6K7TDWhaUj1IeEKfE4JJdRewj7NPHBsYMe6D0zd5hf2If7ouyAm0Lv7/mF+4X0/p8rS184f0iY0CkLQHB6THMND4zwvvGJ6aM3Nz9HBIf3mKaDayfi/CFhQhwCEKKe/3M1lsqfnH4b8C49blSaPuizPD79xkgq6zk9vVtCPL2vD+XLl4+JUBL3cEN+R5yQS9Un7cfkuHQo4P55/6+vA2ydrBzzifgU18/PA4M+hioUiuJVMlZsYMd0BNeXE6Ykrrct5Qzz/CGxw/GDnqlU347+Hdvo+/pRqN+7YCNTqamFiYW1mZm1OWesYIofvVo5/ihEwTFO9cvluB+X4VEwjhIfck7BT+LnVc2pnkvx08bzbWHKF6hewk9SfFs4p5pbwQ/Kv79AcwUkHBcXq4gOi4kMiY4Oi4qJlhkZS3IVtEy384SSgvOHhCnxOCSLNdB+2wACVLu98vrxH19G3zwd4P8pOvBjlOJ9kEyhkMdpHCxy34OJRqxRT6Jgw3E/t5dVsUWhii3qpz8tQTlSFa5+TFVNUy6N4/iZ1LFL8dMKcBKFRCqRGklMLSSOOcxKedg659Xi7YtSDucPCVMS57FKcGQNICxZ85g2zOPE4A/g/CFhSuK+D8jJiRP+bgDJwPlDwpR4HDK3NDY2MmIgKmEhzMgIHSABkoTzh4Qp8d2WU94MEeHpdMd4SCsvrgYamyIOASQJ5w8JU+K7rUr1bZhc8fBiMAPxeHYv2K2MFQOAJOD8IWFKrn/2suGvCpXPWMJDZ539IaVi2Pb5b3MXs6jWMj1uagkgUvp9/pB4JXuekIz9O+G1TMbMzKXRUb9502JOonmSQ7JzUpVdwv2YmUu67J7EJM1TJpJcDeU5E9p5l5/nl0iYXJ7ccpJ76xS/qbEZJ49jMZGynAWt/u7swAAgaf7+/p6enjh/SGiS7YwgZd2m5Lp3IfTd07DwkCQ7ciez92eau+NfvZDvLK6eObmgksSkZF6iXg2ah/790bskEVnjfVKplMlUsVtCb5fitU3qTZP6Gs3MpFb2xh7NM9MfCwCSh/OHhAnXTQAA0AcUh3LmzCnGrtuIQwBgKFAfEiZ08wUAQ4Hzh4QJcQgADAXOHxIm5OUAAPQB6kMAAEKH+pAwIS8HAIYC9SFhQhwCAEOB+pAwIS8HAKAPUB8CABA61IeECXk5ADAUqA8JE+IQABgK1IeECXk5AAB9gPoQAIDQoT4kTMjLAYChQH1ImBCHAMBQoD4kTMjLAQDoA9SHAACEDvUhYUJeDgAMBepDwoQ4BACGAvUhYUJeDgBAH6A+BAAgdKgPCRPycgBgKFAfEibEIQAwFKgPCRPycgAAKRIZGRkeHs6EKjY2ViqVSiTCbV3Y2NgYGxsnHI/2EAAYCqoPXbhwgekp2sULOQglA3EIAAyFfteHIiIi4uLimAghDgGAodDv+hDl5eRyORMh1IcAAFIE9aE/hPoQABg61IfSTc+ePRcvXpzCmRGHAMBQCKQ+NHXq1GPHjrG0pqX6UOvWrT99+sS0CXEIAAyFQOpDWjrbVBv1oS9fvgQFBTEtQ30IACBF4tWH3rx506tXrwULFmzfvv3y5cv29vbu7u5dunShIg1TtU4WLVp07969sLCwHDly1K5du0GDBjS+Tp06/MstLS13796tuXzaG+/bt+/EiRM+Pj7Zs2cvVapUhw4daGk7d+7cvHkzTeJn8/X1pfETJkyoUKECLWHHjh3//PMPvRcFDCcnJ09Pzxo1atBsEydOpEwdLWfXrl0Un3LmzDlo0KDcuXPzC7ly5cqmTZvev39vbW1NI/v27evg4EDjqb1IyT1HR0d603bt2tE8/Pz0XvSO1N5av3799evXaR0KFSrUsGHDsmXL8jO8fft29uzZtMCiRYvSOsybN69IkSL9+vXT/ICoDwGAoUvb+hC/S6U4VLVq1YMHD44YMYKiwvnz5/mp48aNo3QW7bs3btxYuXLlJUuWPHv2jMbv37+fHikkxAtC/KRt27Y1adKE9vX16tU7evQoBYPk14GiFIXGM2fOrFmzhgISrcmcOXM+fPhAk4yMjCgK8otdtWqVnZ3dpEmTZDIZjbl9+7aXlxeFK1q30aNHU1BR13LoVRRfX79+TWGsfv36kydPppFr166lD0IDS5cu3bt3L4UfWsO//vqLghb/fVJTbOzYsZkzZ165cmXXrl0p8gUEBLAUQxwCAEOhjfoQ7Y4p10cxiQ7/qTnC59yoxfDo0aOBAwfmz5+fGgFUYqHWg7ptkZQHDx7kzZu3Zs2atra2f//9NzUpypQp88sVoDZKo0aNzM3NKSa1adPGwsLi7Nmz/CSKu9Q04TiOVoyaUBRvaK2Y6kp0lSpVooBH61awYMEePXrQCj9//pwm0cyUi6OgUr58eVoNzTeKjo4+efJky5YtKUZSK4paeBT2tmzZQpMuXbr09evXnj17UqPKxcWlT58+1ApkKYY4BACGQhv1oTx58qiHKdXG73+pSWFmZkapMPUkCjC/LAtRSLhz587cuXOPHz8eEhKSNWtWdRotebRwpgpI9Egh5927d/x4WgFq3/DDtDR65CdRc4cCpPrl+fLlo0e+uUYolUcrn/BdaP0psFG2UD2GUnC0KFrVjx8/0ksom8ePp7YXtY1YihkxAADDkCFDhjFjxrA0lWhXacpKxduVU3uFykssWdRAodYMVW4oFFH8oJBJOa5MmTKxX6H4yr8FNctomEpTmuN5/PqEq1DLRnMSvZCpCloJX6WJr40NGTIk3vjAwEAKRfxC4q1SCiEOAYABoWBANQwq7DNtonASFRWlOYb28r+MKBTS/lahmv/du3cpj0e7firqxJuNr/FookIUNYP4ehXFmIwZM/LjNXtV8OtjqqJ+ql43pmrEsGTx609fHd+0UqOmD6Xp4kVZdVRLCeTlAMCA0GE77U/nz5/PtIkyXbSjf/nypXoMZb2ocJL8q06cOEEJPRqgOank07hx41evXjFVhwiKLupzg96/fx/vhd7e3vwAzfbhwwf1G1HSLDg4mB/mVyZXrlzU0qI83pMnT9Qvf/z4MT+JJYvCDx/Din2XI0cOSuJR0KWyEH1eejt+Tlptf39/lmKIQwBgWNq1a9e5c+eErYo0VLp0aWqgLFy4kIr/lKNbt27d06dPmzVrxlQtEnt7+1u3bt27dy/eaadnz5718vK6evUqpbmuX79OxX+qGNF4Nzc3hUJBUYqpOm1v376dn59v01Ar6sCBAxSc6BNt2LCBQlG1atX4GaiZsnTp0lCVzZs3U7QoXLgwjW/YsOHly5f37dtH42k1qIFYvHhxzUKXmrOzMz2eP3+e1p/iDX11tJyHDx/yPQ9Hjx69ZMkSpurVbWJismDBAlolikDTp0+nt2YphrwcABgcKpbQwXuie940QW2OCRMm/Pvvv1gSva0AAAQeSURBVJTFoh00NTXGjx/PxwCmukLBxo0bb968SWGDSlbqV9HMy5cvnzhxIg1Tbo0SdHzoyp8/f/fu3VevXk07eopJXbp0GTZsGMUqvg8Cx3E024gRI/iiFNVv+ODBVP0UCAUPCk5ZsmShVeLPbapRowZFi127dtHbUXAqWbIkBeZEPwi1gWrWrElrS4Fz5syZLVq0cHV13bFjB6UNLS0taWX4DCcNU/6Q1pDWhAItlbVOnz7NUgznsQKAIaLUHLVLaB+d8pcI5Dqn1IqiCES7bopA1Kah1syRI0cSzjZlypSwsLD//e9/TDBwHisAwA8DBw7k6y5MVKjewzceKAgxfYG8HAAYqFatWjHxoPBDFSC+czbTL8jLAYDhmjdvXrly5SpWrJiSmXWYl4uIiKC6C1/dES/k5QAA4uvfv7+2+3D/OUoeUoNB7EEoGWgPAQCkSPq3h2JjY6kBIZfLhXyX1ZRDewgAIHHHjx/39fX95Wzp3DWAwh5/7x/9CELJQHsIAAydj49P37591Tf40Tm+GXT27NmqVasyA4A4BADAPn/+TM0d9RWjdejWrVtr165V3xDIECAvBwDAsmTJYm5unub31f4NR48eNaggxBCHAAB4r1+/7tGjB9ORkJAQ/sJxaX5nCuFDHAIAUCpWrFijRo1u377N0h0VhBo3bly9enVmkFAfAgDQpWfPnjk7O1taWjJDhfYQAMAP9+7d27hxI0sXMTExzZs3t1RhBgxxCADgB8rO3bp16+LFi0zLoqKiHjx4MHv2bPVtGgwW8nIAAOlt0qRJgwYNStXN4vQY2kMAAPF9+PCBvye3NmzdurVkyZIIQmqIQwAA8VGubPz48c+ePWNp6tixY/RYv379Bg0aMPgOcQgAIBHLly///PkzSzsbN258/vw5DVhZWTHQgPoQAIB2UTzLkiXL7du3KR3HIAG0hwAAktS8efPg4GD2B/bv379p0yYaQBBKCuIQAECSJkyYsH79evYH3r9/P3ToUAZJQ14OACDtPXr06N69e56engx+Be0hAIDkyOXyRYsWpeoloaGhM2fObNGiBYMUQBwCAEiORCLJkSOHl5dXCud//vw5hS7K5iV6D2xICHk5AIBf8/X1tbGxMTU1TWae4ODg2rVrnzhxAj2zUwXtIQCAX7Ozs0v+dKK4uLhnz55dunQJQSi1EIcAAH7NyMjo2LFjK1euTDiJsko9e/akx7Jly0qlUgaphDgEAJAiPXr0MDMzS3g60fz582kSqkG/DfUhAIDftGXLFvTM/nNoDwEApML69evPnTtHA15eXhkyZGDwx9AeAgBInUaNGu3YscPHx8fV1ZXBH0McAgAAXTJiAAAAuoM4BAAAuoQ4BAAAuoQ4BAAAuoQ4BAAAuoQ4BAAAuoQ4BAAAuvR/AAAA//8tOwXLAAAABklEQVQDADncuR5w2jiDAAAAAElFTkSuQmCC",
            "text/plain": [
              "<IPython.core.display.Image object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "from IPython.display import Image, display\n",
        "\n",
        "try:\n",
        "    display(Image(app.get_graph().draw_mermaid_png()))\n",
        "except Exception as e:\n",
        "    print(f\"Could not display graph: {e}\")\n",
        "    print(\"Graph structure is still functional\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Test Case 1: Vectorstore Query\n",
        "\n",
        "Test with a question that should route to the vectorstore (AI/ML topic)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "---ROUTE QUESTION---\n",
            "---ROUTE TO VECTORSTORE---\n",
            "---RETRIEVE---\n",
            "---CHECK DOCUMENT RELEVANCE---\n",
            "---GRADE: RELEVANT---\n",
            "---GRADE: RELEVANT---\n",
            "---GRADE: RELEVANT---\n",
            "---ASSESS GRADED DOCUMENTS---\n",
            "---DOCS AVAILABLE, GENERATE---\n",
            "---GENERATE---\n",
            "---CHECK HALLUCINATIONS---\n",
            "---GROUNDED IN DOCUMENTS---\n",
            "---GRADE GENERATION vs QUESTION---\n",
            "---ADDRESSES QUESTION---\n",
            "\n",
            "============================================================\n",
            "FINAL RESULT\n",
            "============================================================\n",
            "\n",
            "Question: What is machine learning and how does it work?\n",
            "\n",
            "Answer:\n",
            "Machine learning (ML) is a field of study in artificial intelligence that involves the development of statistical algorithms that can learn from data and generalize to unseen data, allowing them to perform tasks without explicit instructions. It works by using statistical algorithms, such as neural networks, to analyze data and make predictions or decisions, with the goal of improving performance over time. The foundations of ML are based on statistics and mathematical optimization methods.\n",
            "\n",
            "Number of documents used: 3\n"
          ]
        }
      ],
      "source": [
        "# Question about AI/ML - should route to vectorstore\n",
        "inputs = {\"question\": \"What is machine learning and how does it work?\"}\n",
        "\n",
        "result = app.invoke(inputs)\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"FINAL RESULT\")\n",
        "print(\"=\"*60)\n",
        "print(f\"\\nQuestion: {result['question']}\")\n",
        "print(f\"\\nAnswer:\\n{result['generation']}\")\n",
        "print(f\"\\nNumber of documents used: {len(result['documents'])}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Test Case 2: Web Search Query\n",
        "\n",
        "Test with a question requiring current information (should route to web search)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "---ROUTE QUESTION---\n",
            "---ROUTE TO WEB SEARCH---\n",
            "---WEB SEARCH---\n",
            "---GENERATE---\n",
            "---CHECK HALLUCINATIONS---\n",
            "---GROUNDED IN DOCUMENTS---\n",
            "---GRADE GENERATION vs QUESTION---\n",
            "---DOES NOT ADDRESS QUESTION---\n",
            "---TRANSFORM QUERY---\n",
            "---RETRIEVE---\n",
            "---CHECK DOCUMENT RELEVANCE---\n",
            "---GRADE: NOT RELEVANT---\n",
            "---GRADE: NOT RELEVANT---\n",
            "---GRADE: NOT RELEVANT---\n",
            "---ASSESS GRADED DOCUMENTS---\n",
            "---NO RELEVANT DOCS, TRANSFORM QUERY---\n",
            "---TRANSFORM QUERY---\n",
            "---RETRIEVE---\n",
            "---CHECK DOCUMENT RELEVANCE---\n",
            "---GRADE: NOT RELEVANT---\n",
            "---GRADE: NOT RELEVANT---\n",
            "---GRADE: NOT RELEVANT---\n",
            "---ASSESS GRADED DOCUMENTS---\n",
            "---NO RELEVANT DOCS, TRANSFORM QUERY---\n",
            "---TRANSFORM QUERY---\n",
            "---RETRIEVE---\n",
            "---CHECK DOCUMENT RELEVANCE---\n",
            "---GRADE: NOT RELEVANT---\n",
            "---GRADE: NOT RELEVANT---\n",
            "---GRADE: NOT RELEVANT---\n",
            "---ASSESS GRADED DOCUMENTS---\n",
            "---NO RELEVANT DOCS, TRANSFORM QUERY---\n",
            "---TRANSFORM QUERY---\n",
            "---RETRIEVE---\n",
            "---CHECK DOCUMENT RELEVANCE---\n",
            "---GRADE: NOT RELEVANT---\n",
            "---GRADE: NOT RELEVANT---\n",
            "---GRADE: NOT RELEVANT---\n",
            "---ASSESS GRADED DOCUMENTS---\n",
            "---NO RELEVANT DOCS, TRANSFORM QUERY---\n",
            "---TRANSFORM QUERY---\n",
            "---RETRIEVE---\n",
            "---CHECK DOCUMENT RELEVANCE---\n",
            "---GRADE: RELEVANT---\n",
            "---GRADE: RELEVANT---\n",
            "---GRADE: RELEVANT---\n",
            "---ASSESS GRADED DOCUMENTS---\n",
            "---DOCS AVAILABLE, GENERATE---\n",
            "---GENERATE---\n",
            "---CHECK HALLUCINATIONS---\n",
            "---GROUNDED IN DOCUMENTS---\n",
            "---GRADE GENERATION vs QUESTION---\n",
            "---ADDRESSES QUESTION---\n",
            "\n",
            "============================================================\n",
            "FINAL RESULT\n",
            "============================================================\n",
            "\n",
            "Question: To optimize our conversation, I'll rephrase your question to focus on the core semantic intent: \n",
            "\n",
            "\"What specific subject, from science and technology, history and culture, language and linguistics, environmental sustainability, or philosophy and ethics, would you like to discuss or learn more about?\"\n",
            "\n",
            "Answer:\n",
            "I'd like to discuss Artificial General Intelligence (AGI) from the science and technology category.\n"
          ]
        }
      ],
      "source": [
        "# Current events question - should route to web search\n",
        "inputs = {\"question\": \"What are the latest developments in quantum computing this year?\"}\n",
        "\n",
        "result = app.invoke(inputs)\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"FINAL RESULT\")\n",
        "print(\"=\"*60)\n",
        "print(f\"\\nQuestion: {result['question']}\")\n",
        "print(f\"\\nAnswer:\\n{result['generation']}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Test Case 3: Complex Query with Transformation\n",
        "\n",
        "Test with an ambiguous query that may require transformation for better retrieval."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "---ROUTE QUESTION---\n",
            "---ROUTE TO VECTORSTORE---\n",
            "---RETRIEVE---\n",
            "---CHECK DOCUMENT RELEVANCE---\n",
            "---GRADE: RELEVANT---\n",
            "---GRADE: RELEVANT---\n",
            "---GRADE: RELEVANT---\n",
            "---ASSESS GRADED DOCUMENTS---\n",
            "---DOCS AVAILABLE, GENERATE---\n",
            "---GENERATE---\n",
            "---CHECK HALLUCINATIONS---\n",
            "---GROUNDED IN DOCUMENTS---\n",
            "---GRADE GENERATION vs QUESTION---\n",
            "---DOES NOT ADDRESS QUESTION---\n",
            "---TRANSFORM QUERY---\n",
            "---RETRIEVE---\n",
            "---CHECK DOCUMENT RELEVANCE---\n",
            "---GRADE: RELEVANT---\n",
            "---GRADE: RELEVANT---\n",
            "---GRADE: RELEVANT---\n",
            "---ASSESS GRADED DOCUMENTS---\n",
            "---DOCS AVAILABLE, GENERATE---\n",
            "---GENERATE---\n",
            "---CHECK HALLUCINATIONS---\n"
          ]
        },
        {
          "ename": "RateLimitError",
          "evalue": "Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01kbammze1e3a8dqwqf652gz64` service tier `on_demand` on tokens per day (TPD): Limit 100000, Used 100000, Requested 1000. Please try again in 14m24s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mRateLimitError\u001b[39m                            Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[19]\u001b[39m\u001b[32m, line 4\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Vague question that may need transformation\u001b[39;00m\n\u001b[32m      2\u001b[39m inputs = {\u001b[33m\"\u001b[39m\u001b[33mquestion\u001b[39m\u001b[33m\"\u001b[39m: \u001b[33m\"\u001b[39m\u001b[33mHow do neural networks learn things?\u001b[39m\u001b[33m\"\u001b[39m}\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m result = \u001b[43mapp\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      6\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m + \u001b[33m\"\u001b[39m\u001b[33m=\u001b[39m\u001b[33m\"\u001b[39m*\u001b[32m60\u001b[39m)\n\u001b[32m      7\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mFINAL RESULT\u001b[39m\u001b[33m\"\u001b[39m)\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/Downloads/Personal Projects/Python/LangChain-LangGraph/.venv/lib/python3.13/site-packages/langgraph/pregel/main.py:3068\u001b[39m, in \u001b[36mPregel.invoke\u001b[39m\u001b[34m(self, input, config, context, stream_mode, print_mode, output_keys, interrupt_before, interrupt_after, durability, **kwargs)\u001b[39m\n\u001b[32m   3065\u001b[39m chunks: \u001b[38;5;28mlist\u001b[39m[\u001b[38;5;28mdict\u001b[39m[\u001b[38;5;28mstr\u001b[39m, Any] | Any] = []\n\u001b[32m   3066\u001b[39m interrupts: \u001b[38;5;28mlist\u001b[39m[Interrupt] = []\n\u001b[32m-> \u001b[39m\u001b[32m3068\u001b[39m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   3069\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   3070\u001b[39m \u001b[43m    \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3071\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcontext\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcontext\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3072\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstream_mode\u001b[49m\u001b[43m=\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mupdates\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mvalues\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[32m   3073\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mstream_mode\u001b[49m\u001b[43m \u001b[49m\u001b[43m==\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mvalues\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\n\u001b[32m   3074\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mstream_mode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3075\u001b[39m \u001b[43m    \u001b[49m\u001b[43mprint_mode\u001b[49m\u001b[43m=\u001b[49m\u001b[43mprint_mode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3076\u001b[39m \u001b[43m    \u001b[49m\u001b[43moutput_keys\u001b[49m\u001b[43m=\u001b[49m\u001b[43moutput_keys\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3077\u001b[39m \u001b[43m    \u001b[49m\u001b[43minterrupt_before\u001b[49m\u001b[43m=\u001b[49m\u001b[43minterrupt_before\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3078\u001b[39m \u001b[43m    \u001b[49m\u001b[43minterrupt_after\u001b[49m\u001b[43m=\u001b[49m\u001b[43minterrupt_after\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3079\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdurability\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdurability\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3080\u001b[39m \u001b[43m    \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3081\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m   3082\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mstream_mode\u001b[49m\u001b[43m \u001b[49m\u001b[43m==\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mvalues\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\n\u001b[32m   3083\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[43m==\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m2\u001b[39;49m\u001b[43m:\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/Downloads/Personal Projects/Python/LangChain-LangGraph/.venv/lib/python3.13/site-packages/langgraph/pregel/main.py:2643\u001b[39m, in \u001b[36mPregel.stream\u001b[39m\u001b[34m(self, input, config, context, stream_mode, print_mode, output_keys, interrupt_before, interrupt_after, durability, subgraphs, debug, **kwargs)\u001b[39m\n\u001b[32m   2641\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m task \u001b[38;5;129;01min\u001b[39;00m loop.match_cached_writes():\n\u001b[32m   2642\u001b[39m     loop.output_writes(task.id, task.writes, cached=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m-> \u001b[39m\u001b[32m2643\u001b[39m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m_\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mrunner\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtick\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2644\u001b[39m \u001b[43m    \u001b[49m\u001b[43m[\u001b[49m\u001b[43mt\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mloop\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtasks\u001b[49m\u001b[43m.\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m.\u001b[49m\u001b[43mwrites\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2645\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mstep_timeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2646\u001b[39m \u001b[43m    \u001b[49m\u001b[43mget_waiter\u001b[49m\u001b[43m=\u001b[49m\u001b[43mget_waiter\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2647\u001b[39m \u001b[43m    \u001b[49m\u001b[43mschedule_task\u001b[49m\u001b[43m=\u001b[49m\u001b[43mloop\u001b[49m\u001b[43m.\u001b[49m\u001b[43maccept_push\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2648\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m   2649\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# emit output\u001b[39;49;00m\n\u001b[32m   2650\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01myield from\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m_output\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2651\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstream_mode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprint_mode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msubgraphs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mqueue\u001b[49m\u001b[43m.\u001b[49m\u001b[43mEmpty\u001b[49m\n\u001b[32m   2652\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2653\u001b[39m loop.after_tick()\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/Downloads/Personal Projects/Python/LangChain-LangGraph/.venv/lib/python3.13/site-packages/langgraph/pregel/_runner.py:167\u001b[39m, in \u001b[36mPregelRunner.tick\u001b[39m\u001b[34m(self, tasks, reraise, timeout, retry_policy, get_waiter, schedule_task)\u001b[39m\n\u001b[32m    165\u001b[39m t = tasks[\u001b[32m0\u001b[39m]\n\u001b[32m    166\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m167\u001b[39m     \u001b[43mrun_with_retry\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    168\u001b[39m \u001b[43m        \u001b[49m\u001b[43mt\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    169\u001b[39m \u001b[43m        \u001b[49m\u001b[43mretry_policy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    170\u001b[39m \u001b[43m        \u001b[49m\u001b[43mconfigurable\u001b[49m\u001b[43m=\u001b[49m\u001b[43m{\u001b[49m\n\u001b[32m    171\u001b[39m \u001b[43m            \u001b[49m\u001b[43mCONFIG_KEY_CALL\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mpartial\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    172\u001b[39m \u001b[43m                \u001b[49m\u001b[43m_call\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    173\u001b[39m \u001b[43m                \u001b[49m\u001b[43mweakref\u001b[49m\u001b[43m.\u001b[49m\u001b[43mref\u001b[49m\u001b[43m(\u001b[49m\u001b[43mt\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    174\u001b[39m \u001b[43m                \u001b[49m\u001b[43mretry_policy\u001b[49m\u001b[43m=\u001b[49m\u001b[43mretry_policy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    175\u001b[39m \u001b[43m                \u001b[49m\u001b[43mfutures\u001b[49m\u001b[43m=\u001b[49m\u001b[43mweakref\u001b[49m\u001b[43m.\u001b[49m\u001b[43mref\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfutures\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    176\u001b[39m \u001b[43m                \u001b[49m\u001b[43mschedule_task\u001b[49m\u001b[43m=\u001b[49m\u001b[43mschedule_task\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    177\u001b[39m \u001b[43m                \u001b[49m\u001b[43msubmit\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43msubmit\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    178\u001b[39m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    179\u001b[39m \u001b[43m        \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    180\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    181\u001b[39m     \u001b[38;5;28mself\u001b[39m.commit(t, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[32m    182\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/Downloads/Personal Projects/Python/LangChain-LangGraph/.venv/lib/python3.13/site-packages/langgraph/pregel/_retry.py:42\u001b[39m, in \u001b[36mrun_with_retry\u001b[39m\u001b[34m(task, retry_policy, configurable)\u001b[39m\n\u001b[32m     40\u001b[39m     task.writes.clear()\n\u001b[32m     41\u001b[39m     \u001b[38;5;66;03m# run the task\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m42\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtask\u001b[49m\u001b[43m.\u001b[49m\u001b[43mproc\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtask\u001b[49m\u001b[43m.\u001b[49m\u001b[43minput\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     43\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m ParentCommand \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[32m     44\u001b[39m     ns: \u001b[38;5;28mstr\u001b[39m = config[CONF][CONFIG_KEY_CHECKPOINT_NS]\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/Downloads/Personal Projects/Python/LangChain-LangGraph/.venv/lib/python3.13/site-packages/langgraph/_internal/_runnable.py:658\u001b[39m, in \u001b[36mRunnableSeq.invoke\u001b[39m\u001b[34m(self, input, config, **kwargs)\u001b[39m\n\u001b[32m    656\u001b[39m                 \u001b[38;5;28minput\u001b[39m = context.run(step.invoke, \u001b[38;5;28minput\u001b[39m, config, **kwargs)\n\u001b[32m    657\u001b[39m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m658\u001b[39m             \u001b[38;5;28minput\u001b[39m = \u001b[43mstep\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    659\u001b[39m \u001b[38;5;66;03m# finish the root run\u001b[39;00m\n\u001b[32m    660\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/Downloads/Personal Projects/Python/LangChain-LangGraph/.venv/lib/python3.13/site-packages/langgraph/_internal/_runnable.py:400\u001b[39m, in \u001b[36mRunnableCallable.invoke\u001b[39m\u001b[34m(self, input, config, **kwargs)\u001b[39m\n\u001b[32m    398\u001b[39m         run_manager.on_chain_end(ret)\n\u001b[32m    399\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m400\u001b[39m     ret = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    401\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.recurse \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(ret, Runnable):\n\u001b[32m    402\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m ret.invoke(\u001b[38;5;28minput\u001b[39m, config)\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/Downloads/Personal Projects/Python/LangChain-LangGraph/.venv/lib/python3.13/site-packages/langgraph/graph/_branch.py:166\u001b[39m, in \u001b[36mBranchSpec._route\u001b[39m\u001b[34m(self, input, config, reader, writer)\u001b[39m\n\u001b[32m    164\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    165\u001b[39m     value = \u001b[38;5;28minput\u001b[39m\n\u001b[32m--> \u001b[39m\u001b[32m166\u001b[39m result = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    167\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._finish(writer, \u001b[38;5;28minput\u001b[39m, result, config)\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/Downloads/Personal Projects/Python/LangChain-LangGraph/.venv/lib/python3.13/site-packages/langgraph/_internal/_runnable.py:393\u001b[39m, in \u001b[36mRunnableCallable.invoke\u001b[39m\u001b[34m(self, input, config, **kwargs)\u001b[39m\n\u001b[32m    391\u001b[39m     \u001b[38;5;66;03m# run in context\u001b[39;00m\n\u001b[32m    392\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m set_config_context(child_config, run) \u001b[38;5;28;01mas\u001b[39;00m context:\n\u001b[32m--> \u001b[39m\u001b[32m393\u001b[39m         ret = \u001b[43mcontext\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    394\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    395\u001b[39m     run_manager.on_chain_error(e)\n",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[11]\u001b[39m\u001b[32m, line 54\u001b[39m, in \u001b[36mgrade_generation_v_documents_and_question\u001b[39m\u001b[34m(state)\u001b[39m\n\u001b[32m     51\u001b[39m \u001b[38;5;66;03m# Format documents for grading\u001b[39;00m\n\u001b[32m     52\u001b[39m docs_text = \u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m.join(doc.page_content \u001b[38;5;28;01mfor\u001b[39;00m doc \u001b[38;5;129;01min\u001b[39;00m documents)\n\u001b[32m---> \u001b[39m\u001b[32m54\u001b[39m score = \u001b[43mhallucination_grader\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[43m{\u001b[49m\n\u001b[32m     55\u001b[39m \u001b[43m    \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mdocuments\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mdocs_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     56\u001b[39m \u001b[43m    \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mgeneration\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mgeneration\u001b[49m\n\u001b[32m     57\u001b[39m \u001b[43m\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     59\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m score.binary_score == \u001b[33m\"\u001b[39m\u001b[33myes\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m     60\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33m---GROUNDED IN DOCUMENTS---\u001b[39m\u001b[33m\"\u001b[39m)\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/Downloads/Personal Projects/Python/LangChain-LangGraph/.venv/lib/python3.13/site-packages/langchain_core/runnables/base.py:3129\u001b[39m, in \u001b[36mRunnableSequence.invoke\u001b[39m\u001b[34m(self, input, config, **kwargs)\u001b[39m\n\u001b[32m   3127\u001b[39m                 input_ = context.run(step.invoke, input_, config, **kwargs)\n\u001b[32m   3128\u001b[39m             \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m3129\u001b[39m                 input_ = \u001b[43mcontext\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstep\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   3130\u001b[39m \u001b[38;5;66;03m# finish the root run\u001b[39;00m\n\u001b[32m   3131\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/Downloads/Personal Projects/Python/LangChain-LangGraph/.venv/lib/python3.13/site-packages/langchain_core/runnables/base.py:5534\u001b[39m, in \u001b[36mRunnableBindingBase.invoke\u001b[39m\u001b[34m(self, input, config, **kwargs)\u001b[39m\n\u001b[32m   5527\u001b[39m \u001b[38;5;129m@override\u001b[39m\n\u001b[32m   5528\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34minvoke\u001b[39m(\n\u001b[32m   5529\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m   5532\u001b[39m     **kwargs: Any | \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m   5533\u001b[39m ) -> Output:\n\u001b[32m-> \u001b[39m\u001b[32m5534\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mbound\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   5535\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   5536\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_merge_configs\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   5537\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43m{\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   5538\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/Downloads/Personal Projects/Python/LangChain-LangGraph/.venv/lib/python3.13/site-packages/langchain_core/language_models/chat_models.py:398\u001b[39m, in \u001b[36mBaseChatModel.invoke\u001b[39m\u001b[34m(self, input, config, stop, **kwargs)\u001b[39m\n\u001b[32m    384\u001b[39m \u001b[38;5;129m@override\u001b[39m\n\u001b[32m    385\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34minvoke\u001b[39m(\n\u001b[32m    386\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m    391\u001b[39m     **kwargs: Any,\n\u001b[32m    392\u001b[39m ) -> AIMessage:\n\u001b[32m    393\u001b[39m     config = ensure_config(config)\n\u001b[32m    394\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(\n\u001b[32m    395\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mAIMessage\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    396\u001b[39m         cast(\n\u001b[32m    397\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mChatGeneration\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m--> \u001b[39m\u001b[32m398\u001b[39m             \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mgenerate_prompt\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    399\u001b[39m \u001b[43m                \u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_convert_input\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    400\u001b[39m \u001b[43m                \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    401\u001b[39m \u001b[43m                \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcallbacks\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    402\u001b[39m \u001b[43m                \u001b[49m\u001b[43mtags\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtags\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    403\u001b[39m \u001b[43m                \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmetadata\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    404\u001b[39m \u001b[43m                \u001b[49m\u001b[43mrun_name\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mrun_name\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    405\u001b[39m \u001b[43m                \u001b[49m\u001b[43mrun_id\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpop\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mrun_id\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    406\u001b[39m \u001b[43m                \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    407\u001b[39m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m.generations[\u001b[32m0\u001b[39m][\u001b[32m0\u001b[39m],\n\u001b[32m    408\u001b[39m         ).message,\n\u001b[32m    409\u001b[39m     )\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/Downloads/Personal Projects/Python/LangChain-LangGraph/.venv/lib/python3.13/site-packages/langchain_core/language_models/chat_models.py:1117\u001b[39m, in \u001b[36mBaseChatModel.generate_prompt\u001b[39m\u001b[34m(self, prompts, stop, callbacks, **kwargs)\u001b[39m\n\u001b[32m   1108\u001b[39m \u001b[38;5;129m@override\u001b[39m\n\u001b[32m   1109\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mgenerate_prompt\u001b[39m(\n\u001b[32m   1110\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1114\u001b[39m     **kwargs: Any,\n\u001b[32m   1115\u001b[39m ) -> LLMResult:\n\u001b[32m   1116\u001b[39m     prompt_messages = [p.to_messages() \u001b[38;5;28;01mfor\u001b[39;00m p \u001b[38;5;129;01min\u001b[39;00m prompts]\n\u001b[32m-> \u001b[39m\u001b[32m1117\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprompt_messages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/Downloads/Personal Projects/Python/LangChain-LangGraph/.venv/lib/python3.13/site-packages/langchain_core/language_models/chat_models.py:927\u001b[39m, in \u001b[36mBaseChatModel.generate\u001b[39m\u001b[34m(self, messages, stop, callbacks, tags, metadata, run_name, run_id, **kwargs)\u001b[39m\n\u001b[32m    924\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m i, m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(input_messages):\n\u001b[32m    925\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    926\u001b[39m         results.append(\n\u001b[32m--> \u001b[39m\u001b[32m927\u001b[39m             \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_generate_with_cache\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    928\u001b[39m \u001b[43m                \u001b[49m\u001b[43mm\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    929\u001b[39m \u001b[43m                \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    930\u001b[39m \u001b[43m                \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrun_managers\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mrun_managers\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    931\u001b[39m \u001b[43m                \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    932\u001b[39m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    933\u001b[39m         )\n\u001b[32m    934\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    935\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m run_managers:\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/Downloads/Personal Projects/Python/LangChain-LangGraph/.venv/lib/python3.13/site-packages/langchain_core/language_models/chat_models.py:1221\u001b[39m, in \u001b[36mBaseChatModel._generate_with_cache\u001b[39m\u001b[34m(self, messages, stop, run_manager, **kwargs)\u001b[39m\n\u001b[32m   1219\u001b[39m     result = generate_from_stream(\u001b[38;5;28miter\u001b[39m(chunks))\n\u001b[32m   1220\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m inspect.signature(\u001b[38;5;28mself\u001b[39m._generate).parameters.get(\u001b[33m\"\u001b[39m\u001b[33mrun_manager\u001b[39m\u001b[33m\"\u001b[39m):\n\u001b[32m-> \u001b[39m\u001b[32m1221\u001b[39m     result = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_generate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1222\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\n\u001b[32m   1223\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1224\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1225\u001b[39m     result = \u001b[38;5;28mself\u001b[39m._generate(messages, stop=stop, **kwargs)\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/Downloads/Personal Projects/Python/LangChain-LangGraph/.venv/lib/python3.13/site-packages/langchain_groq/chat_models.py:590\u001b[39m, in \u001b[36mChatGroq._generate\u001b[39m\u001b[34m(self, messages, stop, run_manager, **kwargs)\u001b[39m\n\u001b[32m    585\u001b[39m message_dicts, params = \u001b[38;5;28mself\u001b[39m._create_message_dicts(messages, stop)\n\u001b[32m    586\u001b[39m params = {\n\u001b[32m    587\u001b[39m     **params,\n\u001b[32m    588\u001b[39m     **kwargs,\n\u001b[32m    589\u001b[39m }\n\u001b[32m--> \u001b[39m\u001b[32m590\u001b[39m response = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mclient\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcreate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmessage_dicts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    591\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._create_chat_result(response, params)\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/Downloads/Personal Projects/Python/LangChain-LangGraph/.venv/lib/python3.13/site-packages/groq/resources/chat/completions.py:464\u001b[39m, in \u001b[36mCompletions.create\u001b[39m\u001b[34m(self, messages, model, citation_options, compound_custom, disable_tool_validation, documents, exclude_domains, frequency_penalty, function_call, functions, include_domains, include_reasoning, logit_bias, logprobs, max_completion_tokens, max_tokens, metadata, n, parallel_tool_calls, presence_penalty, reasoning_effort, reasoning_format, response_format, search_settings, seed, service_tier, stop, store, stream, temperature, tool_choice, tools, top_logprobs, top_p, user, extra_headers, extra_query, extra_body, timeout)\u001b[39m\n\u001b[32m    244\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mcreate\u001b[39m(\n\u001b[32m    245\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m    246\u001b[39m     *,\n\u001b[32m   (...)\u001b[39m\u001b[32m    303\u001b[39m     timeout: \u001b[38;5;28mfloat\u001b[39m | httpx.Timeout | \u001b[38;5;28;01mNone\u001b[39;00m | NotGiven = not_given,\n\u001b[32m    304\u001b[39m ) -> ChatCompletion | Stream[ChatCompletionChunk]:\n\u001b[32m    305\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    306\u001b[39m \u001b[33;03m    Creates a model response for the given chat conversation.\u001b[39;00m\n\u001b[32m    307\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m    462\u001b[39m \u001b[33;03m      timeout: Override the client-level default timeout for this request, in seconds\u001b[39;00m\n\u001b[32m    463\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m464\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_post\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    465\u001b[39m \u001b[43m        \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m/openai/v1/chat/completions\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    466\u001b[39m \u001b[43m        \u001b[49m\u001b[43mbody\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmaybe_transform\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    467\u001b[39m \u001b[43m            \u001b[49m\u001b[43m{\u001b[49m\n\u001b[32m    468\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmessages\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    469\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmodel\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    470\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcitation_options\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mcitation_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    471\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcompound_custom\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mcompound_custom\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    472\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mdisable_tool_validation\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mdisable_tool_validation\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    473\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mdocuments\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mdocuments\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    474\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mexclude_domains\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mexclude_domains\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    475\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mfrequency_penalty\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfrequency_penalty\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    476\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mfunction_call\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunction_call\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    477\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mfunctions\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunctions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    478\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43minclude_domains\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43minclude_domains\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    479\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43minclude_reasoning\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43minclude_reasoning\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    480\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mlogit_bias\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogit_bias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    481\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mlogprobs\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogprobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    482\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmax_completion_tokens\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_completion_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    483\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmax_tokens\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    484\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmetadata\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    485\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mn\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    486\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mparallel_tool_calls\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mparallel_tool_calls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    487\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mpresence_penalty\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mpresence_penalty\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    488\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mreasoning_effort\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mreasoning_effort\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    489\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mreasoning_format\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mreasoning_format\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    490\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mresponse_format\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mresponse_format\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    491\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43msearch_settings\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43msearch_settings\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    492\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mseed\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mseed\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    493\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mservice_tier\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mservice_tier\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    494\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstop\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    495\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstore\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstore\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    496\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstream\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    497\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtemperature\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtemperature\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    498\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtool_choice\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtool_choice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    499\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtools\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtools\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    500\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtop_logprobs\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_logprobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    501\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtop_p\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_p\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    502\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43muser\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43muser\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    503\u001b[39m \u001b[43m            \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    504\u001b[39m \u001b[43m            \u001b[49m\u001b[43mcompletion_create_params\u001b[49m\u001b[43m.\u001b[49m\u001b[43mCompletionCreateParams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    505\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    506\u001b[39m \u001b[43m        \u001b[49m\u001b[43moptions\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmake_request_options\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    507\u001b[39m \u001b[43m            \u001b[49m\u001b[43mextra_headers\u001b[49m\u001b[43m=\u001b[49m\u001b[43mextra_headers\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_query\u001b[49m\u001b[43m=\u001b[49m\u001b[43mextra_query\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_body\u001b[49m\u001b[43m=\u001b[49m\u001b[43mextra_body\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\n\u001b[32m    508\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    509\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m=\u001b[49m\u001b[43mChatCompletion\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    510\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    511\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[43m=\u001b[49m\u001b[43mStream\u001b[49m\u001b[43m[\u001b[49m\u001b[43mChatCompletionChunk\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    512\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/Downloads/Personal Projects/Python/LangChain-LangGraph/.venv/lib/python3.13/site-packages/groq/_base_client.py:1242\u001b[39m, in \u001b[36mSyncAPIClient.post\u001b[39m\u001b[34m(self, path, cast_to, body, options, files, stream, stream_cls)\u001b[39m\n\u001b[32m   1228\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mpost\u001b[39m(\n\u001b[32m   1229\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   1230\u001b[39m     path: \u001b[38;5;28mstr\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1237\u001b[39m     stream_cls: \u001b[38;5;28mtype\u001b[39m[_StreamT] | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m   1238\u001b[39m ) -> ResponseT | _StreamT:\n\u001b[32m   1239\u001b[39m     opts = FinalRequestOptions.construct(\n\u001b[32m   1240\u001b[39m         method=\u001b[33m\"\u001b[39m\u001b[33mpost\u001b[39m\u001b[33m\"\u001b[39m, url=path, json_data=body, files=to_httpx_files(files), **options\n\u001b[32m   1241\u001b[39m     )\n\u001b[32m-> \u001b[39m\u001b[32m1242\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(ResponseT, \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mopts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[43m)\u001b[49m)\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/Downloads/Personal Projects/Python/LangChain-LangGraph/.venv/lib/python3.13/site-packages/groq/_base_client.py:1044\u001b[39m, in \u001b[36mSyncAPIClient.request\u001b[39m\u001b[34m(self, cast_to, options, stream, stream_cls)\u001b[39m\n\u001b[32m   1041\u001b[39m             err.response.read()\n\u001b[32m   1043\u001b[39m         log.debug(\u001b[33m\"\u001b[39m\u001b[33mRe-raising status error\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m-> \u001b[39m\u001b[32m1044\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m._make_status_error_from_response(err.response) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1046\u001b[39m     \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[32m   1048\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m response \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[33m\"\u001b[39m\u001b[33mcould not resolve response (should never happen)\u001b[39m\u001b[33m\"\u001b[39m\n",
            "\u001b[31mRateLimitError\u001b[39m: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01kbammze1e3a8dqwqf652gz64` service tier `on_demand` on tokens per day (TPD): Limit 100000, Used 100000, Requested 1000. Please try again in 14m24s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}",
            "During task with name 'generate' and id '7376b5e5-cf0b-ab16-1e78-2fa9fbe230db'"
          ]
        }
      ],
      "source": [
        "# Vague question that may need transformation\n",
        "inputs = {\"question\": \"How do neural networks learn things?\"}\n",
        "\n",
        "result = app.invoke(inputs)\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"FINAL RESULT\")\n",
        "print(\"=\"*60)\n",
        "print(f\"\\nOriginal Question: How do neural networks learn things?\")\n",
        "print(f\"\\nFinal Question (after any transformations): {result['question']}\")\n",
        "print(f\"\\nAnswer:\\n{result['generation']}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Key Takeaways\n",
        "\n",
        "This Adaptive RAG implementation demonstrates several LangGraph v1.x patterns:\n",
        "\n",
        "1. **StateGraph with TypedDict**: Clean state management with type safety\n",
        "2. **Conditional Edges**: Dynamic routing based on LLM decisions\n",
        "3. **Structured Outputs**: Pydantic models ensure reliable LLM responses\n",
        "4. **Self-Correction Loops**: Query transformation and regeneration cycles\n",
        "5. **Multi-Stage Validation**: Hallucination and answer quality checks\n",
        "\n",
        "The workflow adapts its strategy based on:\n",
        "- Query type (vectorstore vs web search)\n",
        "- Document relevance scores\n",
        "- Answer quality metrics\n",
        "\n",
        "This creates a robust RAG system that handles various query types and self-corrects when needed."
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
